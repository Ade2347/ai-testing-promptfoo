{"version":3,"sources":["../src/configs/chat-model/common.config.chat-model.google.ts","../src/configs/chat-model/base.config.chat-model.google.ts","../src/configs/chat-model/response-schema.config.chat-model.google.ts","../src/configs/chat-model/reasoning.config.chat-model.google.ts","../src/configs/embedding-model/base.config.embedding-model.google.ts","../src/configs/embedding-model/common.config.embedding-model.google.ts","../src/configs/configs.google.ts","../src/provider/provider.google.ts","../src/models/pricing.json","../src/models/chat-models/types/roles.chat-model.google.ts","../src/models/chat-models/types/modalities.chat-model.google.ts","../src/models/chat-models/types/response.chat-model.google.ts","../src/models/chat-models/types/request.chat-model.google.ts","../src/models/chat-models/base-chat-model.google.ts","../src/models/chat-models/gemini-1.5-flash-001.google.ts","../src/models/chat-models/gemini-1.5-flash-002.google.ts","../src/models/chat-models/gemini-1.5-flash-latest.google.ts","../src/models/chat-models/gemini-1.5-flash.google.ts","../src/models/chat-models/gemini-1.5-pro-001.google.ts","../src/models/chat-models/gemini-1.5-pro-002.google.ts","../src/models/chat-models/gemini-1.5-pro-latest.google.ts","../src/models/chat-models/gemini-1.5-pro.google.ts","../src/models/chat-models/gemini-2.0-flash-exp.google.ts","../src/models/chat-models/gemini-2.5-flash-preview-04-17.google.ts","../src/models/chat-models/gemini-2.5-pro-preview-03-25.google.ts","../src/models/embedding-models/types/modalitites.embedding-model.google.ts","../src/models/embedding-models/types/response.embedding-model.google.ts","../src/models/embedding-models/types/request.embedding-model.google.ts","../src/models/embedding-models/base-embedding-model.google.ts","../src/models/embedding-models/text-embedding-001.google.ts","../src/models/embedding-models/text-embedding-004.google.ts"],"names":["temperature","max","_default","RangeConfigItem","CHAT_CONFIG","maxTokens","maxOutputTokens","stop","maxSequences","MultiStringConfigItem","topP","topK","frequencyPenalty","presencePenalty","seed","toolChoice","SelectStringConfigItem","safetySettings","ObjectSchemaConfigItem","z","reasoningEnabled","SelectBooleanConfigItem","ChatModelBaseConfigSchema","maxTemperature","defaultTemperature","defaultTopP","ChatModelBaseConfigDef","responseSchema","ResponseSchema","responseFormat","GoogleChatModelResponseSchemaConfigDef","__spreadProps","__spreadValues","GoogleChatModelResponseSchemaConfigSchema","ChatModelReasoningConfigSchema","ChatModelReasoningConfigDef","dimensions","maxDimensions","EMBEDDING_CONFIG","EmbeddingModelBaseConfigSchema","EmbeddingModelBaseConfigDef","GoogleChatModelConfigs","GoogleEmbeddingModelConfigs","ProviderLiteral","Google","Gemini1_5Flash001Literal","Gemini1_5Flash001","Gemini1_5Flash001Options","Gemini1_5Flash001Schema","Gemini1_5Flash002Literal","Gemini1_5Flash002","Gemini1_5Flash002Options","Gemini1_5Flash002Schema","Gemini1_5FlashLatestLiteral","Gemini1_5FlashLatest","Gemini1_5FlashLatestOptions","Gemini1_5FlashLatestSchema","Gemini1_5FlashLiteral","Gemini1_5Flash","Gemini1_5FlashOptions","Gemini1_5FlashSchema","Gemini1_5Pro001Literal","Gemini1_5Pro001","Gemini1_5Pro001Options","Gemini1_5Pro001Schema","Gemini1_5Pro002Literal","Gemini1_5Pro002","Gemini1_5Pro002Options","Gemini1_5Pro002Schema","Gemini1_5ProLatestLiteral","Gemini1_5ProLatest","Gemini1_5ProLatestOptions","Gemini1_5ProLatestSchema","Gemini1_5ProLiteral","Gemini1_5Pro","Gemini1_5ProOptions","Gemini1_5ProSchema","Gemini2_0FlashExpLiteral","Gemini2_0FlashExp","Gemini2_0FlashExpOptions","Gemini2_0FlashExpSchema","Gemini2_5FlashPreview0417Literal","Gemini2_5FlashPreview0417","Gemini2_5FlashPreview0417Options","Gemini2_5FlashPreview0417Schema","Gemini2_5ProPreview0325Literal","Gemini2_5ProPreview0325","Gemini2_5ProPreview0325Options","Gemini2_5ProPreview0325Schema","Text_Embedding_001Literal","Text_Embedding_001","Text_Embedding_001Options","Text_Embedding_001Schema","Text_Embedding_004Literal","Text_Embedding_004","Text_Embedding_004Options","Text_Embedding_004Schema","acc","key","options","modelName","ProviderError","model","parsedOptions","pricing_default","GoogleChatModelRoles","SystemRoleLiteral","UserRoleLiteral","AssistantRoleLiteral","ToolRoleLiteral","GoogleChatAssistantRoleLiteral","GoogleChatToolRoleLiteral","GoogleChatModelRolesMap","GoogleChatModelModalities","TextModalityLiteral","ImageModalityLiteral","ToolCallModalityLiteral","ToolResponseModalityLiteral","GoogleChatModelModalitiesEnum","GoogleChatModelTextModalities","GoogleChatModelTextModalitiesEnum","GoogleChatModelTextVisionModalities","GoogleChatModelTextVisionModalitiesEnum","GoogleChatModelTextToolModalities","GoogleChatModelTextToolModalitiesEnum","GoogleCompleteChatTextResponse","GoogleCompleteChatToolResponse","GoogleCompleteChatResponse","GoogleStreamChatTextResponse","GoogleStreamChatToolResponse","GoogleStreamChatResponse","GoogleChatContentPartText","GoogleChatContentPartInlineData","GoogleChatContentPartFunctionCall","GoogleChatContentPartFunctionResponse","GoogleChatContent","GoogleChatSystemInstruction","GoogleChatTool","GoogleChatToolConfig","GoogleChatGenerationConfig","GoogleChatSafetySettings","GoogleChatRequest","BaseChatModelOptions","BaseChatModel","modelSchema","_a","urlWithoutTrailingSlash","responseHeaders","messages","message","content","request","safeRequest","InvalidModelRequestError","parsedRequest","systemInstruction","generationConfig","toolConfig","_config","config","Config","removeUndefinedEntries","part","role","_content","c","Base64ImageContentTypeLiteral","index","InvalidMessagesError","tools","tool","_toolChoice","_parsedConfig","InvalidConfigError","parsedConfig","transformedConfig","def","paramKey","paramValue","configToolChoice","responseSchemaConfig","stripBase64Prefix","data","prefixMatch","parsedMessages","parsedMessage","Message","nonSystemMessages","assistantContent","userContent","base64Data","toolResponseContent","getNextExpectedRoles","InvalidToolsError","parsedTool","Tool","__async","resolve","transformedMessages","transformedTools","response","safe","ModelResponseError","parsedResponse","usage","contentItem","createTextContent","createToolCallContent","safetyRatings","rating","chunk","buffer","__asyncGenerator","lines","line","completeLine","structuredLine","error","partialResponse","messagePart","createPartialTextMessage","toolCall","createPartialToolCallMessage","headers","query","__yieldStar","newData","newBuffer","currentIndex","newlineIndex","jsonStr","url","value","sanitizedHeaders","Gemini1_5Flash001Description","ChatModelSchema","Gemini1_5Flash002Description","Gemini1_5FlashLatestDescription","Gemini1_5FlashDescription","Gemini1_5Pro001Description","Gemini1_5Pro002Description","Gemini1_5ProLatestDescription","Gemini1_5ProDescription","Gemini2_0FlashExpDescription","Gemini2_5FlashPreview0417Description","Gemini2_5ProPreview0325Description","GoogleEmbeddingModelModalities","EmbeddingTextModalityLiteral","GoogleEmbeddingModelModalitiesEnum","GoogleGetEmbeddingsResponse","GoogleEmbeddingRequestInput","GoogleEmbeddingRequest","BaseEmbeddingModelOptions","BaseEmbeddingModel","requests","embeddingRequests","_parsedRequests","EmbeddingRequests","InvalidEmbeddingRequestsError","_requests","embeddings","embedding","FloatEmbeddingLiteral","Text_Embedding_001_Description","EmbeddingModelSchema","Text_Embedding_004_Description"],"mappings":";;;;2hDAWMA,IAAAA,EAAAA,CAAc,CAACC,CAAAA,CAAaC,CAChCC,GAAAA,eAAAA,CAAgB,CACd,KAAO,CAAA,aAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,WAAY,CAAA,KAAA,CAC/B,YAAaA,WAAY,CAAA,WAAA,CAAY,WACrC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAKH,EACL,IAAM,CAAA,GAAA,CACN,OAASC,CAAAA,CACX,CAAC,CAAA,CAEGG,EAAaC,CAAAA,CAAAA,EACjBH,eAAgB,CAAA,CACd,KAAO,CAAA,iBAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,WAAW,KAC9B,CAAA,WAAA,CAAaA,WAAY,CAAA,UAAA,CAAW,WACpC,CAAA,GAAA,CAAK,EACL,GAAKE,CAAAA,CAAAA,CACL,IAAM,CAAA,CAAA,CACN,OAAS,CAAA,CACX,CAAC,CAEGC,CAAAA,EAAAA,CAAQC,CACZC,EAAAA,qBAAAA,CAAsB,CACpB,KAAA,CAAO,eACP,CAAA,KAAA,CAAOL,WAAY,CAAA,IAAA,CAAKI,CAAY,CAAA,CAAE,KACtC,CAAA,WAAA,CAAaJ,YAAY,IAAKI,CAAAA,CAAY,CAAE,CAAA,WAAA,CAC5C,GAAKA,CAAAA,CACP,CAAC,CAAA,CAEGE,EAAQR,CAAAA,CAAAA,EACZC,eAAgB,CAAA,CACd,KAAO,CAAA,MAAA,CACP,MAAOC,WAAY,CAAA,KAAA,CAAM,KACzB,CAAA,WAAA,CAAaA,WAAY,CAAA,KAAA,CAAM,WAC/B,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,CACL,CAAA,IAAA,CAAM,GACN,CAAA,OAAA,CAASF,CACX,CAAC,CAAA,CAEGS,EAAQT,CAAAA,CAAAA,EACZC,eAAgB,CAAA,CACd,MAAO,MACP,CAAA,KAAA,CAAOC,WAAY,CAAA,KAAA,CAAM,KACzB,CAAA,WAAA,CAAaA,YAAY,KAAM,CAAA,WAAA,CAC/B,GAAK,CAAA,CAAA,CACL,GAAK,CAAA,EAAA,CACL,IAAM,CAAA,CAAA,CACN,OAASF,CAAAA,CACX,CAAC,CAAA,CAEGU,EAAmBT,CAAAA,eAAAA,CAAgB,CACvC,KAAO,CAAA,kBAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,iBAAkB,CAAA,KAAA,CACrC,WAAaA,CAAAA,WAAAA,CAAY,iBAAkB,CAAA,WAAA,CAC3C,GAAK,CAAA,CAAA,CAAA,CACL,GAAK,CAAA,CAAA,CACL,KAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKS,CAAAA,EAAAA,CAAkBV,eAAgB,CAAA,CACtC,KAAO,CAAA,iBAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,gBAAiB,CAAA,KAAA,CACpC,YAAaA,WAAY,CAAA,gBAAA,CAAiB,WAC1C,CAAA,GAAA,CAAK,CACL,CAAA,CAAA,GAAA,CAAK,EACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKU,GAAOX,eAAgB,CAAA,CAC3B,KAAO,CAAA,MAAA,CACP,KAAOC,CAAAA,WAAAA,CAAY,IAAK,CAAA,KAAA,CACxB,WAAaA,CAAAA,WAAAA,CAAY,IAAK,CAAA,WAAA,CAC9B,GAAK,CAAA,CAAA,CACL,IAAK,GACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKW,CAAAA,EAAAA,CAAaC,sBAAuB,CAAA,CACxC,KAAO,CAAA,YAAA,CACP,KAAO,CAAA,aAAA,CACP,YACE,uLACF,CAAA,OAAA,CAAS,MACT,CAAA,OAAA,CAAS,CAAC,MAAA,CAAQ,KAAO,CAAA,MAAM,CACjC,CAAC,CAEKC,CAAAA,EAAAA,CAAiBC,sBAAuB,CAAA,CAC5C,MAAO,gBACP,CAAA,KAAA,CAAO,iBACP,CAAA,WAAA,CAAa,yHACb,CAAA,YAAA,CAAcC,EAAE,KACdA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACP,SAAWA,CAAAA,CAAAA,CAAE,KAAK,CAChB,kCAAA,CACA,qBACA,CAAA,wBAAA,CACA,iBACA,CAAA,YAAA,CACA,KACF,CAAC,CACD,CAAA,QAAA,CAAUA,CAAE,CAAA,IAAA,CAAK,CACf,2BAAA,CACA,2BACA,2BACA,CAAA,iCAAA,CACA,iCACA,CAAA,+BACF,CAAC,CACH,CAAC,CACH,CACF,CAAC,CAEKC,CAAAA,EAAAA,CAAmBC,uBAAwB,CAAA,CAC/C,MAAO,kBACP,CAAA,KAAA,CAAO,mBACP,CAAA,WAAA,CACE,gLACF,CAAA,OAAA,CAAS,CACX,CAAA,CAAC,EClID,IAAMC,CAA4B,CAAA,CAChCC,CACAC,CAAAA,CAAAA,CACAlB,EACAE,CACAiB,CAAAA,CAAAA,GAEAN,CAAE,CAAA,MAAA,CAAO,CACP,WAAA,CAAanB,GAAYuB,CAAgBC,CAAAA,CAAkB,CAAE,CAAA,MAAA,CAC7D,SAAWnB,CAAAA,EAAAA,CAAUC,CAAe,CAAE,CAAA,MAAA,CACtC,IAAMC,CAAAA,EAAAA,CAAKC,CAAY,CAAA,CAAE,MACzB,CAAA,IAAA,CAAME,EAAKe,CAAAA,CAAW,CAAE,CAAA,MAAA,CACxB,UAAYV,CAAAA,EAAAA,CAAW,OACvB,cAAgBE,CAAAA,EAAAA,CAAe,MACjC,CAAC,CAEGS,CAAAA,EAAAA,CAAyB,CAC7BH,CAAAA,CACAC,CACAlB,CAAAA,CAAAA,CACAE,CACAiB,CAAAA,CAAAA,IAEC,CACC,WAAA,CAAazB,GAAYuB,CAAgBC,CAAAA,CAAkB,CAAE,CAAA,GAAA,CAC7D,SAAWnB,CAAAA,EAAAA,CAAUC,CAAe,CAAA,CAAE,GACtC,CAAA,IAAA,CAAMC,EAAKC,CAAAA,CAAY,CAAE,CAAA,GAAA,CACzB,KAAME,EAAKe,CAAAA,CAAW,CAAE,CAAA,GAAA,CACxB,UAAYV,CAAAA,EAAAA,CAAW,IACvB,cAAgBE,CAAAA,EAAAA,CAAe,GACjC,CAAA,EC7BF,IAAMU,EAAiBT,CAAAA,sBAAAA,CAAuB,CAC5C,KAAA,CAAO,kBACP,KAAOd,CAAAA,WAAAA,CAAY,eAAgB,CAAA,KAAA,CACnC,WAAaA,CAAAA,WAAAA,CAAY,eAAgB,CAAA,WAAA,CACzC,YAAcwB,CAAAA,cAChB,CAAC,CAAA,CAEKC,EAAiBb,CAAAA,sBAAAA,CAAuB,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAOZ,CAAAA,WAAAA,CAAY,2BAA4B,CAAA,KAAA,CAC/C,WAAaA,CAAAA,WAAAA,CAAY,2BAA4B,CAAA,WAAA,CACrD,OAAS,CAAA,MAAA,CACT,OAAS,CAAA,CAAC,OAAQ,aAAa,CACjC,CAAC,CAAA,CAEK0B,EAAyC,CAAA,CAC7CP,EACAC,CACAlB,CAAAA,CAAAA,CACAE,CACAiB,CAAAA,CAAAA,GACIM,CAAAC,CAAAA,CAAAA,CAAA,GACDN,EAAuBH,CAAAA,CAAAA,CAAgBC,CAAoBlB,CAAAA,CAAAA,CAAiBE,CAAciB,CAAAA,CAAW,CADpG,CAAA,CAAA,CAEJ,cAAgBI,CAAAA,EAAAA,CAAe,GAC/B,CAAA,cAAA,CAAgBF,EAAe,CAAA,GACjC,GAEMM,EAA4C,CAAA,CAChDV,CACAC,CAAAA,CAAAA,CACAlB,CACAE,CAAAA,CAAAA,CACAiB,CAEAH,GAAAA,CAAAA,CAA0BC,CAAgBC,CAAAA,CAAAA,CAAoBlB,CAAiBE,CAAAA,CAAAA,CAAciB,CAAW,CAAA,CAAE,OAAO,CAC/G,cAAA,CAAgBI,EAAe,CAAA,MAAA,CAC/B,cAAgBF,CAAAA,EAAAA,CAAe,MACjC,CAAC,ECnCH,IAAMO,EAAiC,CAAA,CACrCX,CACAC,CAAAA,CAAAA,CACAlB,EACAE,CACAiB,CAAAA,CAAAA,GAEAQ,EAA0CV,CAAAA,CAAAA,CAAgBC,CAAoBlB,CAAAA,CAAAA,CAAiBE,EAAciB,CAAW,CAAA,CAAE,MAAO,CAAA,CAC/H,gBAAkBL,CAAAA,EAAAA,CAAiB,MACrC,CAAC,CAAA,CAEGe,EAA8B,CAAA,CAClCZ,CACAC,CAAAA,CAAAA,CACAlB,CACAE,CAAAA,CAAAA,CACAiB,CAECM,GAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACIF,EAAuCP,CAAAA,CAAAA,CAAgBC,EAAoBlB,CAAiBE,CAAAA,CAAAA,CAAciB,CAAW,CAAA,CAAA,CADzH,CAEC,gBAAA,CAAkBL,EAAiB,CAAA,GACrC,CC5BF,ECEMgB,IAAAA,EAAAA,CAAcC,CAClBlC,EAAAA,eAAAA,CAAgB,CACd,KAAA,CAAO,sBACP,CAAA,KAAA,CAAOmC,gBAAiB,CAAA,UAAA,CAAW,MACnC,WAAaA,CAAAA,gBAAAA,CAAiB,UAAW,CAAA,WAAA,CACzC,GAAK,CAAA,CAAA,CACL,IAAKD,CACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAASA,CACX,CAAC,EDPGE,IAAAA,EAAAA,CAAkCF,CACtClB,EAAAA,CAAAA,CAAE,MAAO,CAAA,CACP,UAAYiB,CAAAA,EAAAA,CAAWC,CAAa,CAAA,CAAE,MACxC,CAAC,CAEGG,CAAAA,EAAAA,CAA+BH,IAClC,CACC,UAAA,CAAYD,EAAWC,CAAAA,CAAa,CAAE,CAAA,GACxC,CEFF,EAAA,IAAMI,CAAyB,CAAA,CAC7B,IAAM,CAAA,CAAClB,CAAwBC,CAAAA,CAAAA,CAA4BlB,EAAyBE,CAAsBiB,CAAAA,CAAAA,IAAyB,CACjI,GAAA,CAAKC,EAAuBH,CAAAA,CAAAA,CAAgBC,CAAoBlB,CAAAA,CAAAA,CAAiBE,CAAciB,CAAAA,CAAW,CAC1G,CAAA,MAAA,CAAQH,CAA0BC,CAAAA,CAAAA,CAAgBC,EAAoBlB,CAAiBE,CAAAA,CAAAA,CAAciB,CAAW,CAClH,CACA,CAAA,CAAA,cAAA,CAAgB,CAACF,CAAwBC,CAAAA,CAAAA,CAA4BlB,CAAyBE,CAAAA,CAAAA,CAAsBiB,CAAyB,IAAA,CAC3I,IAAKK,EAAuCP,CAAAA,CAAAA,CAAgBC,CAAoBlB,CAAAA,CAAAA,CAAiBE,CAAciB,CAAAA,CAAW,CAC1H,CAAA,MAAA,CAAQQ,EAA0CV,CAAAA,CAAAA,CAAgBC,CAAoBlB,CAAAA,CAAAA,CAAiBE,CAAciB,CAAAA,CAAW,CAClI,CACA,CAAA,CAAA,SAAA,CAAW,CACTF,CAAAA,CACAC,CACAlB,CAAAA,CAAAA,CACAE,CACAiB,CAAAA,CAAAA,IACI,CACJ,GAAA,CAAKU,EAA4BZ,CAAAA,CAAAA,CAAgBC,CAAoBlB,CAAAA,CAAAA,CAAiBE,EAAciB,CAAW,CAAA,CAC/G,MAAQS,CAAAA,EAAAA,CAA+BX,CAAgBC,CAAAA,CAAAA,CAAoBlB,CAAiBE,CAAAA,CAAAA,CAAciB,CAAW,CACvH,CACF,CAAA,CAAA,CAEMiB,CAA8B,CAAA,CAClC,KAAOL,CAA2B,GAAA,CAChC,GAAKG,CAAAA,EAAAA,CAA4BH,CAAa,CAAA,CAC9C,OAAQE,EAA+BF,CAAAA,CAAa,CACtD,CAAA,CACF,EC9BMM,IAAAA,EAAAA,CAAkB,SAClBC,CAAN,CAAA,KAAoI,CAApI,WAAA,EAAA,CACE,IAAS,CAAA,OAAA,CAAU,IACnB,CAAA,IAAA,CAAS,IAAOD,CAAAA,EAAAA,CAGhB,IAAiB,CAAA,kBAAA,CAOb,CACF,CAAQE,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAwB,EAAG,CACjC,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAA2B,EAAG,CACpC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAAqB,EAAG,CAC9B,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAsB,EAAG,CAC/B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAsB,EAAG,CAC/B,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAAmB,EAAG,CAC5B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAwB,EAAG,CACjC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAEA,CAAA,CAAQC,EAAgC,EAAG,CACzC,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAA8B,EAAG,CACvC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACF,CAAA,CAEA,IAAiB,CAAA,uBAAA,CAOb,CACF,CAAQC,EAAyB,EAAG,CAClC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACF,EAEA,CAAA,iBAAA,EAA8B,CAC5B,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,kBAAkB,CAC5C,CAEA,gBAAwD,EAAA,CACtD,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,kBAAkB,CAAE,CAAA,MAAA,CAC1C,CAACC,CAAAA,CAAKC,CACJD,IAAAA,CAAAA,CAAIC,CAAG,CAAA,CAAI,IAAK,CAAA,kBAAA,CAAmBA,CAAG,CAAA,CAAE,WACjCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,SAAA,CAAUE,CAAyB,CAAA,CACjC,IAAMC,CAAAA,CAAYD,CAAQ,CAAA,SAAA,CAC1B,GAAI,EAAEC,CAAa,IAAA,IAAA,CAAK,oBACtB,MAAM,IAAIC,aAAc,CAAA,CACtB,IAAM,CAAA,CAAA,mBAAA,EAAsBD,CAAS,CAAA,UAAA,CAAA,CACrC,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,mBAAA,EAAsBA,CAAS,CAAA;AAAA,WAAA,EAC3C,KAAK,iBAAkB,EAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC7C,CAAC,EAGH,IAAME,CAAAA,CAAQ,KAAK,kBAAmBF,CAAAA,CAAS,EAAE,KAC3CG,CAAAA,CAAAA,CAAgB,KAAK,kBAAmBH,CAAAA,CAAS,EAAE,YAAa,CAAA,KAAA,CAAMD,CAAO,CACnF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CAEA,sBAAA,EAAmC,CACjC,OAAO,MAAA,CAAO,KAAK,IAAK,CAAA,uBAAuB,CACjD,CAEA,qBAAA,EAAkE,CAChE,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,uBAAuB,CAAE,CAAA,MAAA,CAC/C,CAACN,CAAKC,CAAAA,CAAAA,IACJD,EAAIC,CAAG,CAAA,CAAI,KAAK,uBAAwBA,CAAAA,CAAG,EAAE,WACtCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,cAAeE,CAAAA,CAAAA,CAA8B,CAC3C,IAAMC,CAAAA,CAAYD,EAAQ,SAC1B,CAAA,GAAI,EAAEC,CAAa,IAAA,IAAA,CAAK,yBACtB,MAAM,IAAIC,cAAc,CACtB,IAAA,CAAM,2BAA2BD,CAAS,CAAA,UAAA,CAAA,CAC1C,MAAO,IAAI,KAAA,CAAM,2BAA2BA,CAAS,CAAA;AAAA,WAAA,EAChD,IAAK,CAAA,sBAAA,EAAyB,CAAA,IAAA,CAAK,IAAI,CAAC,CAAG,CAAA,CAAA,CAClD,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAQ,KAAK,uBAAwBF,CAAAA,CAAS,CAAE,CAAA,KAAA,CAChDG,CAAgB,CAAA,IAAA,CAAK,uBAAwBH,CAAAA,CAAS,CAAE,CAAA,YAAA,CAAa,KAAMD,CAAAA,CAAO,CACxF,CAAA,OAAO,IAAIG,CAAAA,CAAMC,CAAa,CAChC,CACF,EApJM3D,CAAAA,CAGY,OAAkB,CAAA,kDAAA,CCVpC,IAAA4D,CAAAA,CAAA,CACE,0BAAA,CAA4B,CAC1B,SAAA,CAAa,0BACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,CACxB,CAAA,qBAAA,CAAyB,CAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,oBAAA,CAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,uBAAyB,CAAA,CACvB,SAAa,CAAA,uBAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,uBAAyB,CAAA,CACvB,SAAa,CAAA,uBAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,gBAAkB,CAAA,CAChB,SAAa,CAAA,gBAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,sBAAwB,CAAA,CACtB,SAAa,CAAA,sBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,CAAA,MAAA,CAAU,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,IAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACA,CAAA,CACE,SAAa,CAAA,MAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,sBAAwB,CAAA,CACtB,SAAa,CAAA,sBAAA,CACb,QAAY,CAAA,KAAA,CACZ,YAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,KAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,KAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,EACA,CACE,SAAA,CAAa,MACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,IACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,yBAAA,CAA2B,CACzB,SAAA,CAAa,yBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,IAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACA,CAAA,CACE,SAAa,CAAA,MAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,qBAAwB,GACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,kBAAoB,CAAA,CAClB,SAAa,CAAA,kBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,KAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,IAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACA,CAAA,CACE,UAAa,MACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,qBAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,KAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,qBAAwB,IACxB,CAAA,qBAAA,CAAyB,CAC3B,CACF,CACF,CAAA,CACA,CACE,SAAA,CAAa,MACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,IACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,oBAAA,CAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,KACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,KACxB,qBAAyB,CAAA,CAC3B,CACF,CACF,CACA,CAAA,CACE,SAAa,CAAA,MAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,uBAAyB,CAAA,CACvB,UAAa,uBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,KAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,IAAA,CACxB,sBAAyB,CAC3B,CACF,CACF,CAAA,CACA,CACE,SAAA,CAAa,MACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,gBAAA,CAAkB,CAChB,SAAA,CAAa,gBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,KACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,IACxB,CAAA,qBAAA,CAAyB,CAC3B,CACF,CACF,CAAA,CACA,CACE,SAAA,CAAa,MACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,GAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,sBAAA,CAAwB,CACtB,SAAA,CAAa,uBACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,gCAAA,CAAkC,CAChC,SAAA,CAAa,iCACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,GAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,8BAAA,CAAgC,CAC9B,SAAA,CAAa,+BACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,GACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,IACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACA,CAAA,CACE,SAAa,CAAA,MAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,GAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,mBAAqB,CAAA,CACnB,SAAa,CAAA,mBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,YAAA,CAAc,CACZ,SAAA,CAAa,aACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACF,CAAA,CCvXA,IAAMC,CAAuBtF,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAACuF,kBAAmBC,eAAiBC,CAAAA,oBAAAA,CAAsBC,eAAe,CAAC,CAEzGC,CAAAA,EAAAA,CAAiC,OACjCC,CAAAA,EAAAA,CAA4B,WAE5BC,CAA0B,CAAA,CAC9B,MAAQL,CAAAA,eAAAA,CACR,IAAMA,CAAAA,eAAAA,CACN,SAAWG,CAAAA,EAAAA,CACX,IAAMC,CAAAA,EACR,ECTME,IAAAA,CAAAA,CAA+D,CACnEC,mBAAAA,CACAC,oBACAC,CAAAA,uBAAAA,CACAC,2BACF,CAAA,CAEMC,EAAgCnG,CAAE,CAAA,IAAA,CAAK,CAC3C+F,mBAAAA,CACAC,oBACAC,CAAAA,uBAAAA,CACAC,2BACF,CAAC,CAEKE,CAAAA,EAAAA,CAAmE,CAACL,mBAAmB,CAEvFM,CAAAA,EAAAA,CAAoCrG,CAAE,CAAA,IAAA,CAAK,CAAC+F,mBAAmB,CAAC,CAEhEO,CAAAA,EAAAA,CAAyE,CAACP,mBAAAA,CAAqBC,oBAAoB,CAAA,CAEnHO,EAA0CvG,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAAC+F,mBAAqBC,CAAAA,oBAAoB,CAAC,CAAA,CAE5FQ,GAAuE,CAC3ET,mBAAAA,CACAE,uBACAC,CAAAA,2BACF,CAEMO,CAAAA,EAAAA,CAAwCzG,CAAE,CAAA,IAAA,CAAK,CAAC+F,mBAAAA,CAAqBE,uBAAyBC,CAAAA,2BAA2B,CAAC,EC/BhI,IAAMQ,EAAiC1G,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC9C,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EACjB,CAAC,CAAA,CAEK2G,EAAiC3G,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC9C,aAAcA,CAAE,CAAA,MAAA,CAAO,CACrB,IAAA,CAAMA,CAAE,CAAA,MAAA,EACR,CAAA,IAAA,CAAMA,CAAE,CAAA,MAAA,CAAOA,CAAE,CAAA,GAAA,EAAK,CACxB,CAAC,CACH,CAAC,CAEK4G,CAAAA,EAAAA,CAA6B5G,CAAE,CAAA,MAAA,CAAO,CAC1C,UAAA,CAAYA,CAAE,CAAA,KAAA,CACZA,EAAE,MAAO,CAAA,CACP,OAASA,CAAAA,CAAAA,CACN,MAAO,CAAA,CACN,IAAMA,CAAAA,CAAAA,CAAE,QACR,CAAA,KAAA,CAAOA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,KAAA,CAAM,CAAC0G,EAAAA,CAAgCC,EAA8B,CAAC,CAAC,CAC1F,CAAC,CAAA,CACA,QAAS,EAAA,CACZ,aAAc3G,CAAE,CAAA,MAAA,EAChB,CAAA,KAAA,CAAOA,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAClB,CAAA,aAAA,CAAeA,CAAE,CAAA,QAAA,CACfA,CAAE,CAAA,KAAA,CACAA,CAAE,CAAA,MAAA,CAAO,CACP,QAAUA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACnB,WAAaA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACtB,OAASA,CAAAA,CAAAA,CAAE,OAAQ,EAAA,CAAE,QAAS,EAChC,CAAC,CACH,CACF,CACF,CAAC,CACH,CAAA,CACA,cAAgBA,CAAAA,CAAAA,CAAE,QAChBA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACP,aAAeA,CAAAA,CAAAA,CAAE,QACfA,CAAAA,CAAAA,CAAE,KACAA,CAAAA,CAAAA,CAAE,OAAO,CACP,QAAA,CAAUA,CAAE,CAAA,MAAA,EACZ,CAAA,WAAA,CAAaA,CAAE,CAAA,MAAA,EACjB,CAAC,CACH,CACF,CACF,CAAC,CACH,CAAA,CACA,cAAeA,CACZ,CAAA,MAAA,CAAO,CACN,gBAAA,CAAkBA,CAAE,CAAA,MAAA,EACpB,CAAA,uBAAA,CAAyBA,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACpC,CAAA,oBAAA,CAAsBA,CAAE,CAAA,MAAA,GAAS,QAAS,EAAA,CAC1C,eAAiBA,CAAAA,CAAAA,CAAE,MAAO,EAC5B,CAAC,CAAA,CACA,QAAS,EACd,CAAC,CAAA,CAGK6G,EAA+B7G,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC5C,KAAMA,CAAE,CAAA,MAAA,EACV,CAAC,CAEK8G,CAAAA,EAAAA,CAA+B9G,CAAE,CAAA,MAAA,CAAO,CAC5C,YAAcA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACrB,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACf,KAAMA,CAAE,CAAA,MAAA,CAAOA,CAAE,CAAA,GAAA,EAAK,CACxB,CAAC,CACH,CAAC,CAAA,CAEK+G,EAA2B/G,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACxC,UAAYA,CAAAA,CAAAA,CAAE,MACZA,CAAE,CAAA,MAAA,CAAO,CACP,OAAA,CAASA,CACN,CAAA,MAAA,CAAO,CACN,IAAA,CAAMA,CAAE,CAAA,MAAA,EACR,CAAA,KAAA,CAAOA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,KAAA,CAAM,CAAC6G,EAA8BC,CAAAA,EAA4B,CAAC,CAAC,CACtF,CAAC,CACA,CAAA,QAAA,EACH,CAAA,YAAA,CAAc9G,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACzB,CAAA,KAAA,CAAOA,EAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAC3B,aAAeA,CAAAA,CAAAA,CAAE,QACfA,CAAAA,CAAAA,CAAE,KACAA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACP,QAAUA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CACnB,YAAaA,CAAE,CAAA,MAAA,EACf,CAAA,OAAA,CAASA,CAAE,CAAA,OAAA,EAAU,CAAA,QAAA,EACvB,CAAC,CACH,CACF,CACF,CAAC,CACH,CAAA,CACA,eAAgBA,CAAE,CAAA,QAAA,CAChBA,CAAE,CAAA,MAAA,CAAO,CACP,aAAA,CAAeA,CAAE,CAAA,QAAA,CACfA,CAAE,CAAA,KAAA,CACAA,CAAE,CAAA,MAAA,CAAO,CACP,QAAA,CAAUA,CAAE,CAAA,MAAA,GACZ,WAAaA,CAAAA,CAAAA,CAAE,MAAO,EACxB,CAAC,CACH,CACF,CACF,CAAC,CACH,CACA,CAAA,aAAA,CAAeA,CACZ,CAAA,MAAA,CAAO,CACN,gBAAA,CAAkBA,EAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CACtC,uBAAyBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,UACpC,CAAA,oBAAA,CAAsBA,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACjC,CAAA,eAAA,CAAiBA,EAAE,MAAO,EAAA,CAAE,QAAS,EACvC,CAAC,CAAA,CACA,QAAS,EACd,CAAC,EC7GKgH,IAAAA,EAAAA,CAA4BhH,EAAE,MAAO,CAAA,CACzC,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACxB,CAAC,CAGKiH,CAAAA,EAAAA,CAAkCjH,CAAE,CAAA,MAAA,CAAO,CAC/C,WAAA,CAAaA,EAAE,MAAO,CAAA,CACpB,SAAWA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAC3B,CAAA,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,MAAA,EACnB,CAAC,CACH,CAAC,CAAA,CAGKkH,EAAoClH,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACjD,aAAeA,CAAAA,CAAAA,CAAE,MAAO,CAAA,CACtB,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,EACtB,IAAMA,CAAAA,CAAAA,CAAE,MAAOA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAClC,CAAC,CACH,CAAC,CAAA,CAGKmH,EAAwCnH,CAAAA,CAAAA,CAAE,OAAO,CACrD,iBAAA,CAAmBA,CAAE,CAAA,MAAA,CAAO,CAC1B,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,QAAUA,CAAAA,CAAAA,CAAE,MAAOA,CAAAA,CAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAC,CACtC,CAAC,CACH,CAAC,CAGKoH,CAAAA,EAAAA,CAAoBpH,CAAE,CAAA,MAAA,CAAO,CACjC,IAAA,CAAMA,CAAE,CAAA,IAAA,CAAK,CAAC,MAAQ,CAAA,OAAA,CAAS,UAAU,CAAC,CAC1C,CAAA,KAAA,CAAOA,CAAE,CAAA,KAAA,CACPA,EAAE,KAAM,CAAA,CACNgH,EACAC,CAAAA,EAAAA,CACAC,EACAC,CAAAA,EACF,CAAC,CACH,CACF,CAAC,CAAA,CAGKE,EAA8BrH,CAAAA,CAAAA,CAAE,MAAO,CAAA,CAC3C,KAAOA,CAAAA,CAAAA,CAAE,KAAMgH,CAAAA,EAAyB,CAC1C,CAAC,CAGKM,CAAAA,EAAAA,CAAiBtH,CAAE,CAAA,MAAA,CAAO,CAC9B,IAAMA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACtB,CAAA,WAAA,CAAaA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAC7B,UAAYA,CAAAA,CAAAA,CAAE,KAChB,CAAC,CAGKuH,CAAAA,EAAAA,CAAuBvH,CAAE,CAAA,MAAA,CAAO,CACpC,uBAAA,CAAyBA,CAAE,CAAA,MAAA,CAAO,CAChC,IAAA,CAAMA,CAAE,CAAA,IAAA,CAAK,CAAC,KAAA,CAAO,OAAQ,MAAM,CAAC,CACpC,CAAA,sBAAA,CAAwBA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,MAAA,EAAQ,CAAA,CAAE,QAAS,EACvD,CAAC,CACH,CAAC,CAAA,CAGKwH,GAA6BxH,CAAE,CAAA,MAAA,CAAO,CAC1C,aAAA,CAAeA,CAAE,CAAA,KAAA,CAAMA,CAAE,CAAA,MAAA,EAAQ,CAAA,CAAE,QAAS,EAAA,CAC5C,eAAiBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,UAC5B,CAAA,WAAA,CAAaA,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACxB,CAAA,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACjB,CAAA,IAAA,CAAMA,CAAE,CAAA,MAAA,GAAS,QAAS,EAAA,CAC1B,eAAiBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CACrC,gBAAkBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CACtC,IAAMA,CAAAA,CAAAA,CAAE,QAAS,CAAA,QAAA,EACnB,CAAC,CAGKyH,CAAAA,EAAAA,CAA2BzH,CAAE,CAAA,MAAA,CAAO,CACxC,QAAUA,CAAAA,CAAAA,CAAE,IAAK,CAAA,CACf,0BACA,CAAA,2BAAA,CACA,iCACA,CAAA,iCAAA,CACA,+BACF,CAAC,CAAA,CACD,SAAWA,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAChB,kCACA,CAAA,qBAAA,CACA,wBACA,CAAA,iBAAA,CACA,YACA,CAAA,KACF,CAAC,CACH,CAAC,CAAA,CAGK0H,GAAoB1H,CAAE,CAAA,MAAA,CAAO,CACjC,KAAA,CAAOA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAClC,QAAUA,CAAAA,CAAAA,CAAE,KAAMoH,CAAAA,EAAiB,EACnC,iBAAmBC,CAAAA,EAAAA,CAA4B,QAAS,EAAA,CACxD,kBAAoBA,CAAAA,EAAAA,CAA4B,QAAS,EAAA,CACzD,gBAAkBG,CAAAA,EAAAA,CAA2B,QAAS,EAAA,CACtD,iBAAmBA,CAAAA,EAAAA,CAA2B,QAAS,EAAA,CACvD,eAAgBxH,CAAE,CAAA,KAAA,CAAMyH,EAAwB,CAAA,CAAE,QAAS,EAAA,CAC3D,eAAiBzH,CAAAA,CAAAA,CAAE,KAAMyH,CAAAA,EAAwB,CAAE,CAAA,QAAA,EACnD,CAAA,KAAA,CAAOzH,CACJ,CAAA,MAAA,CAAO,CACN,qBAAuBA,CAAAA,CAAAA,CAAE,KAAMsH,CAAAA,EAAc,CAC/C,CAAC,CACA,CAAA,QAAA,EACH,CAAA,UAAA,CAAYC,EAAqB,CAAA,QAAA,EACjC,CAAA,WAAA,CAAaA,EAAqB,CAAA,QAAA,EACpC,CAAC,EC9CKI,IAAAA,CAAAA,CAAuB3H,CAAE,CAAA,MAAA,CAAO,CACpC,SAAA,CAAWA,CAAE,CAAA,MAAA,EACb,CAAA,MAAA,CAAQA,CAAE,CAAA,MAAA,EACV,CAAA,OAAA,CAASA,EAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,QAAS,EAAA,CACnC,eAAiBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,QAAS,EAAA,CAC3C,aAAeA,CAAAA,CAAAA,CAAE,QAAS,CAAA,GAAA,EAAM,CAAA,QAAA,EAClC,CAAC,CAGK4H,CAAAA,CAAAA,CAAN,KAAgE,CAU9D,WAAA,CAAYC,CAAkC7C,CAAAA,CAAAA,CAAmC,CATjF,IAAA,CAAS,OAAU,CAAA,IAAA,CA3ErB,IAAA8C,CAqFI,CAAA,IAAM1C,CAAgBuC,CAAAA,CAAAA,CAAqB,KAAM3C,CAAAA,CAAO,CACxD,CAAA,IAAA,CAAK,WAAc6C,CAAAA,CAAAA,CACnB,IAAK,CAAA,SAAA,CAAYzC,CAAc,CAAA,SAAA,CAC/B,IAAK,CAAA,MAAA,CAASA,EAAc,MAC5B,CAAA,IAAA,CAAK,OAAU2C,CAAAA,uBAAAA,CAAAA,CAAwBD,CAAA1C,CAAAA,CAAAA,CAAc,OAAd,GAAA,IAAA,CAAA0C,CAAyBrG,CAAAA,CAAAA,CAAO,OAAO,CAAA,CAC9E,IAAK,CAAA,eAAA,CAAkBsG,uBACrB3C,CAAAA,CAAAA,CAAc,iBAAmB,CAAG,EAAA,IAAA,CAAK,OAAO,CAAA,QAAA,EAAW,IAAK,CAAA,SAAS,CAAwB,qBAAA,EAAA,IAAA,CAAK,MAAM,CAAA,CAC9G,CACA,CAAA,IAAA,CAAK,aAAgB2C,CAAAA,uBAAAA,CACnB3C,CAAc,CAAA,aAAA,EAAiB,GAAG,IAAK,CAAA,OAAO,CAAW,QAAA,EAAA,IAAA,CAAK,SAAS,CAAA,2BAAA,EAA8B,IAAK,CAAA,MAAM,CAClH,CAAA,EACF,CAEA,iBAAA,EAA6B,CAC3B,OAAO,IAAK,CAAA,OACd,CAEA,iBAAiC,EAAA,CAC/B,OAAO,CACL,cAAgB,CAAA,kBAClB,CACF,CAEA,gBAA+B,EAAA,CAC7B,OAAO,EACT,CAGA,aAAc4C,CAAAA,CAAAA,CAAyE,CACrF,OAAO,CAAE,WAAa,CAAA,CAAA,CAAA,CAAO,OAAS,CAAA,CAAE,CAC1C,CAGA,aAAcC,CAAAA,CAAAA,CAAiC,CAC7C,OAAOA,CAAS,CAAA,MAAA,CAAO,CAACnD,CAAAA,CAAKoD,IACpBpD,CAAMoD,CAAAA,CAAAA,CAAQ,OAAQ,CAAA,GAAA,CAAKC,CAAaA,EAAAA,CAAAA,CAAQ,QAAa,GAAA,MAAA,CAASA,CAAQ,CAAA,KAAA,CAAQ,EAAG,CAAA,CAAE,IAAK,CAAA,GAAG,CAAE,CAAA,MAAA,CAC3G,CAAC,CACN,CAEA,qBAAsBC,CAAAA,CAAAA,CAKpB,CACA,IAAMC,CAAcX,CAAAA,EAAAA,CAAkB,UAAUU,CAAO,CAAA,CACvD,GAAI,CAACC,CAAY,CAAA,OAAA,CACf,MAAM,IAAIC,yBAAyB,CAAE,IAAA,CAAM,uBAAyB,CAAA,KAAA,CAAOD,CAAY,CAAA,KAAM,CAAC,CAAA,CAGhG,IAAME,CAAAA,CAAgBF,CAAY,CAAA,IAAA,CAE5BpD,CAAYsD,CAAAA,CAAAA,CAAc,KAEhC,CAAA,GAAIA,EAAc,kBAAsBA,EAAAA,CAAAA,CAAc,iBACpD,CAAA,MAAM,IAAID,wBAAAA,CAAyB,CACjC,IAAA,CAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,+EAA+E,CAClG,CAAC,CAAA,CAGH,GAAIC,CAAAA,CAAc,iBAAqBA,EAAAA,CAAAA,CAAc,gBACnD,CAAA,MAAM,IAAID,wBAAAA,CAAyB,CACjC,IAAA,CAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,MAAO,IAAI,KAAA,CAAM,6EAA6E,CAChG,CAAC,CAAA,CAGH,GAAIC,CAAAA,CAAc,WAAeA,EAAAA,CAAAA,CAAc,UAC7C,CAAA,MAAM,IAAID,wBAAAA,CAAyB,CACjC,IAAA,CAAM,sCAAsC,IAAK,CAAA,SAAS,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,iEAAiE,CACpF,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAoBD,CAAc,CAAA,kBAAA,EAAsBA,CAAc,CAAA,iBAAA,CACtEE,EAAmBF,CAAc,CAAA,iBAAA,EAAqBA,CAAc,CAAA,gBAAA,CACpEzI,CAAiByI,CAAAA,CAAAA,CAAc,eAAmBA,EAAAA,CAAAA,CAAc,cAChEG,CAAAA,CAAAA,CAAaH,CAAc,CAAA,WAAA,EAAeA,CAAc,CAAA,UAAA,CAE9D,GAAIG,CAAAA,GAAe,CAACH,CAAc,CAAA,KAAA,EAASA,CAAc,CAAA,KAAA,CAAM,qBAAsB,CAAA,MAAA,GAAW,CAC9F,CAAA,CAAA,MAAM,IAAID,wBAAAA,CAAyB,CACjC,IAAA,CAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,MAAO,IAAI,KAAA,CAAM,sDAAsD,CACzE,CAAC,CAAA,CAGH,IAAMK,CAAAA,CAAsB,EAExBD,CAAAA,CAAAA,GACEA,CAAW,CAAA,uBAAA,CAAwB,IAAS,GAAA,KAAA,EAE5CA,CAAW,CAAA,uBAAA,CAAwB,wBACnCA,CAAW,CAAA,uBAAA,CAAwB,sBAAuB,CAAA,MAAA,GAAW,CAErEC,CAAAA,CAAAA,CAAQ,UAAaD,CAAAA,CAAAA,CAAW,uBAAwB,CAAA,sBAAA,CAAuB,CAAC,CAAA,CAKlFC,CAAQ,CAAA,UAAA,CAAaD,CAAW,CAAA,uBAAA,CAAwB,KAAK,WAAY,EAAA,CAAA,CAI7EC,CAAQ,CAAA,IAAA,CAAOF,CAAA,EAAA,IAAA,CAAA,KAAA,CAAA,CAAAA,CAAkB,CAAA,IAAA,CACjCE,CAAQ,CAAA,SAAA,CAAYF,CAAA,EAAA,IAAA,CAAA,KAAA,CAAA,CAAAA,CAAkB,CAAA,eAAA,CACtCE,CAAQ,CAAA,WAAA,CAAcF,GAAA,IAAAA,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA,CAAkB,WACxCE,CAAAA,CAAAA,CAAQ,IAAOF,CAAAA,CAAAA,EAAA,IAAAA,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA,CAAkB,IACjCE,CAAAA,CAAAA,CAAQ,eAAkBF,CAAAA,CAAAA,EAAA,IAAAA,CAAAA,KAAAA,CAAAA,CAAAA,CAAAA,CAAkB,eAC5CE,CAAAA,CAAAA,CAAQ,iBAAmBF,CAAA,EAAA,IAAA,CAAA,KAAA,CAAA,CAAAA,CAAkB,CAAA,gBAAA,CAC7CE,CAAQ,CAAA,IAAA,CAAOF,CAAA,EAAA,IAAA,CAAA,KAAA,CAAA,CAAAA,CAAkB,CAAA,aAAA,CACjCE,CAAQ,CAAA,cAAA,CAAiB7I,CACzB,CAAA,IAAM8I,CAASC,CAAAA,MAAAA,GAAS,KAAMC,CAAAA,sBAAAA,CAAuBH,CAAO,CAAC,CAEvDV,CAAAA,CAAAA,CAA0B,EAAC,CAC7BO,CACFA,EAAAA,CAAAA,CAAkB,KAAM,CAAA,OAAA,CAASO,CAAS,EAAA,CACxCd,CAAS,CAAA,IAAA,CAAK,CAAE,IAAM1C,CAAAA,iBAAAA,CAAmB,OAAS,CAAA,CAAC,CAAE,QAAA,CAAUQ,mBAAqB,CAAA,KAAA,CAAOgD,CAAK,CAAA,IAAK,CAAC,CAAE,CAAC,EAC3G,CAAC,CAAA,CAGHR,EAAc,QAAS,CAAA,OAAA,CAASL,CAAY,EAAA,CAC1C,IAAMc,CAAAA,CAAOd,CAAQ,CAAA,IAAA,CACrB,OAAQc,CAAAA,EACN,IAAK,MACH,CAAA,CAEE,IAAMC,CAAAA,CADUf,EAAQ,KACC,CAAA,GAAA,CAAKgB,CACxB,EAAA,MAAA,GAAUA,CACL,CAAA,CAAE,QAAUnD,CAAAA,mBAAAA,CAAqB,MAAOmD,CAAE,CAAA,IAAK,CAE/C,CAAA,CACL,QAAUlD,CAAAA,oBAAAA,CACV,MAAQ,CAAA,MAAA,CACR,MAAO,CACL,IAAA,CAAMmD,6BACN,CAAA,MAAA,CAAQD,CAAE,CAAA,WAAA,CAAY,IACtB,CAAA,SAAA,CAAWA,CAAE,CAAA,WAAA,CAAY,SAAU,CAAA,KAAA,CAAM,GAAG,CAAA,CAAE,CAAC,CACjD,CACF,CAEH,CAAA,CACDjB,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMe,CAAM,CAAA,OAAA,CAASC,CAAS,CAAC,EACjD,CACA,MAEF,IAAK,OACH,CAAA,CAEE,IAAMA,CADUf,CAAAA,CAAAA,CAAQ,KACC,CAAA,GAAA,CAAI,CAACgB,CAAAA,CAAGE,CAC3B,GAAA,MAAA,GAAUF,CACL,CAAA,CAAE,QAAUnD,CAAAA,mBAAAA,CAAqB,KAAOmD,CAAAA,CAAAA,CAAE,IAAK,CAAA,CAE/C,CACL,QAAUjD,CAAAA,uBAAAA,CACV,EAAImD,CAAAA,CAAAA,CAAM,QAAS,EAAA,CACnB,KAAOA,CAAAA,CAAAA,CACP,IAAMF,CAAAA,CAAAA,CAAE,aAAc,CAAA,IAAA,CACtB,SAAW,CAAA,IAAA,CAAK,SAAUA,CAAAA,CAAAA,CAAE,cAAc,IAAI,CAChD,CAEH,CAAA,CACDjB,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMxC,oBAAsB,CAAA,OAAA,CAASwD,CAAS,CAAC,EACjE,CACA,MAEF,IAAK,WACH,CAEE,IAAMA,CADUf,CAAAA,CAAAA,CAAQ,KACC,CAAA,GAAA,CAAI,CAACgB,CAAAA,CAAGE,CACxB,IAAA,CACL,QAAUlD,CAAAA,2BAAAA,CACV,EAAIkD,CAAAA,CAAAA,CAAM,QAAS,EAAA,CACnB,MAAOA,CACP,CAAA,IAAA,CAAMF,CAAE,CAAA,iBAAA,CAAkB,IAC1B,CAAA,IAAA,CAAM,IAAK,CAAA,SAAA,CAAUA,CAAE,CAAA,iBAAA,CAAkB,QAAQ,CACnD,CACD,CAAA,CAAA,CACDjB,CAAS,CAAA,IAAA,CAAK,CAAE,IAAMvC,CAAAA,eAAAA,CAAiB,OAASuD,CAAAA,CAAS,CAAC,EAC5D,CACA,MAEF,QACE,MAAM,IAAII,oBAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,mCAAA,EAAsC,IAAK,CAAA,SAAS,GAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWnB,CAAQ,CAAA,IAAI,CAAkC,+BAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAE,CAC5F,CAAC,CAEL,CACF,CAAC,CAAA,CAED,IAAMoB,CAAoB,CAAA,EAC1B,CAAA,OAAIf,CAAc,CAAA,KAAA,EAChBA,CAAc,CAAA,KAAA,CAAM,qBAAsB,CAAA,OAAA,CAASgB,CAA6B,EAAA,CAC9ED,CAAM,CAAA,IAAA,CAAK,CACT,IAAA,CAAM,WACN,UAAY,CAAA,CACV,MAAQ,CAAA,CACN,IAAMC,CAAAA,CAAAA,CAAK,IACX,CAAA,WAAA,CAAaA,CAAK,CAAA,WAAA,CAClB,UAAYA,CAAAA,CAAAA,CAAK,UACnB,CACF,CACF,CAAC,EACH,CAAC,CAAA,CAGI,CACL,SAAA,CAAAtE,CACA,CAAA,MAAA,CAAA2D,CACA,CAAA,QAAA,CAAAX,EACA,KAAOqB,CAAAA,CAAAA,CAAM,MAAS,CAAA,CAAA,CAAIA,CAAQ,CAAA,KAAA,CACpC,CACF,CAGA,gBAAgBV,CAAoBX,CAAAA,CAAAA,CAA0BqB,CAAgC,CAAA,CAC5F,IAAME,CAAAA,CAAcZ,CAAO,CAAA,UAAA,CAC3B,OAAOA,CAAAA,CAAO,UAEd,CAAA,IAAMa,CAAgB,CAAA,IAAA,CAAK,WAAY,CAAA,MAAA,CAAO,OAAO,SAAUb,CAAAA,CAAM,CACrE,CAAA,GAAI,CAACa,CAAAA,CAAc,OACjB,CAAA,MAAM,IAAIC,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAOD,CAAc,CAAA,KACvB,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAeF,CAAc,CAAA,IAAA,CAEnC,MAAO,CAAA,IAAA,CAAKE,CAAY,CAAA,CAAE,OAAS5E,CAAAA,CAAAA,EAAQ,CACzC,GAAI,EAAEA,CAAO,IAAA,IAAA,CAAK,WAAY,CAAA,MAAA,CAAO,GACnC,CAAA,CAAA,MAAM,IAAI2E,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,yBAAyB3E,CAAG,CAAA;AAAA,8BACvB,EAAA,MAAA,CAAO,KAAK,IAAK,CAAA,WAAA,CAAY,OAAO,GAAG,CAAA,CAAE,IAAK,CAAA,IAAI,CAAC,CAAA,CAAA,CAAG,CAC9E,CAAC,CAEL,CAAC,CAAA,CAED,IAAM6E,CAAAA,CAAoB,OAAO,IAAKD,CAAAA,CAAY,CAAE,CAAA,MAAA,CAAO,CAAC7E,CAAAA,CAAKC,IAAQ,CACvE,IAAM8E,CAAM,CAAA,IAAA,CAAK,WAAY,CAAA,MAAA,CAAO,IAAI9E,CAAG,CAAA,CACrC+E,CAAWD,CAAAA,CAAAA,CAAI,KACfE,CAAAA,CAAAA,CAAcJ,EAA4B5E,CAAG,CAAA,CAEnD,OAAIA,CAAAA,GAAQ,kBAEVD,CAAAA,CAAAA,CAAI,eAAiB,CACnB,eAAA,CAAiBiF,CACnB,CAAA,CACShF,CAAQ,GAAA,oBAAA,CACjBD,EAAI,cACFA,CAAAA,CAAAA,CAAI,gBAAkB,OAAOA,CAAAA,CAAI,gBAAmB,QAChDlE,CAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CAAKiE,CAAI,CAAA,cAAA,CAAA,CAAT,CAAyB,cAAgBiF,CAAAA,CAAW,CACpD,CAAA,CAAA,CAAE,cAAgBA,CAAAA,CAAW,EAC1BD,CAAa,GAAA,iBAAA,EAAqBD,CAAI,CAAA,IAAA,GAAS,OAAWE,EAAAA,CAAAA,GAAe,EAClFjF,CAAIgF,CAAAA,CAAQ,CAAID,CAAAA,CAAAA,CAAI,GAEpB/E,CAAAA,CAAAA,CAAIgF,CAAQ,CAAIC,CAAAA,CAAAA,CAGXjF,CACT,CAAA,CAAG,EAAgB,EAEbhF,CAAiB8J,CAAAA,CAAAA,CAAkB,cACzC,CAAA,OAAOA,CAAkB,CAAA,cAAA,CAEzB,IAAIlB,CACJ,CAAA,GAAIc,CAAgB,GAAA,KAAA,CAAA,CAAW,CAC7B,IAAM5J,EAAa4J,CACnB,CAAA,GAAI,CAACF,CAAUA,EAAAA,CAAAA,EAASA,EAAM,MAAW,GAAA,CAAA,CACvC,MAAM,IAAII,kBAAmB,CAAA,CAC3B,KAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CACnD,KAAO,CAAA,IAAI,MAAM,qDAAqD,CACxE,CAAC,CAAA,CACI,GAAIJ,CAAAA,EAASA,EAAM,MAAS,CAAA,CAAA,CAAG,CACpC,IAAMU,CAAmB,CAAA,IAAA,CAAK,YAAY,MAAO,CAAA,GAAA,CAAI,UACrD,CAAA,GAAKA,CAAiB,CAAA,OAAA,CAAQ,SAASpK,CAAU,CAAA,CAmB3CA,CAAe,GAAA,KAAA,CACjB8I,CAAa,CAAA,CACX,wBAAyB,CACvB,IAAA,CAAM,KACN,CAAA,sBAAA,CAAwBY,CAAM,CAAA,GAAA,CAAKC,GAASA,CAAK,CAAA,UAAA,CAAW,MAAO,CAAA,IAAI,CACzE,CACF,EAEAb,CAAa,CAAA,CACX,uBAAyB,CAAA,CACvB,IAAM9I,CAAAA,CAAAA,CAAW,aACnB,CACF,CA7BE0J,CAAAA,KAAAA,GAAAA,CAAAA,CAAM,GAAKC,CAAAA,CAAAA,EAASA,EAAK,UAAW,CAAA,MAAA,CAAO,IAAI,CAAA,CAAE,QAAS3J,CAAAA,CAAU,EAEtE8I,CAAa,CAAA,CACX,uBAAyB,CAAA,CACvB,IAAM,CAAA,KAAA,CACN,uBAAwB,CAAC9I,CAAU,CACrC,CACF,CAEA,CAAA,KAAA,MAAM,IAAI8J,kBAAmB,CAAA,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,SAAS,IACnD,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,cAAA,EAAiB9J,CAAU,CAAA;AAAA,wBAChCoK,EAAAA,CAAAA,CAAiB,OAAQ,CAAA,IAAA,CAAK,IAAI,CAAC,GAAG,CACpD,CAAC,CAmBP,CACF,CAEA,GAAI,oBAAqBJ,CAAqBA,EAAAA,CAAAA,CAAkB,eAAoB,GAAA,KAAA,CAAA,CAAW,CAC7F,IAAMlJ,EAAiBkJ,CAAkB,CAAA,eAAA,CACzC,GAAIlJ,CAAAA,GAAmB,aAAe,CAAA,CACpC,IAAMuJ,CAAuBL,CAAAA,CAAAA,CAAkB,eAC/C,CAAA,GAAI,EAAE,iBAAA,GAAqBA,IAAsB,CAACA,CAAAA,CAAkB,eAAmB,EAAA,EAACK,CAAA,EAAA,IAAA,EAAAA,EAAsB,MAC5G,CAAA,CAAA,MAAM,IAAIP,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,+BAA+B,IAAK,CAAA,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,+EAA+E,CAClG,CAAC,CAEDE,CAAAA,CAAAA,CAAkB,cAAiBK,CAAAA,CAAAA,CAAqB,OACxDL,CAAkB,CAAA,gBAAA,CAAmB,kBACjC,CAAA,sBAAA,GAA0BK,CAAqB,CAAA,MAAA,EAEjD,OAAQL,CAAkB,CAAA,cAAA,CAAuB,oBAEnD,CAAA,OAAOA,CAAkB,CAAA,eAAA,CACzB,OAAOA,CAAkB,CAAA,gBAE7B,CAAWlJ,KAAAA,CAAAA,GAAmB,aAC5BkJ,EAAAA,CAAAA,CAAkB,eAAiB,CACjC,IAAA,CAAM,QACR,CAAA,CACA,OAAOA,CAAAA,CAAkB,iBAChBlJ,CAAmB,GAAA,MAAA,EAC5B,OAAOkJ,CAAAA,CAAkB,gBAE7B,CAEA,OAAO/I,CAAA,CAAA,CAAA,CAAA,CACL,iBAAmB+I,CAAAA,CAAAA,CAAAA,CACflB,CAAa,CAAA,CAAE,YAAaA,CAAW,CAAA,CAAI,EAAC,CAAA,CAC5C5I,CAAiB,CAAA,CAAE,gBAAiBA,CAAe,CAAA,CAAI,EAAC,CAEhE,CAEA,iBAAA,CAAkBmI,EAAqC,CACrD,GAAI,CAACA,CAAAA,EAAaA,CAAYA,EAAAA,CAAAA,CAAS,SAAW,CAChD,CAAA,OAAO,CAAE,QAAA,CAAU,EAAG,EAExB,IAAMiC,CAAAA,CAAqBC,CAAyB,EAAA,CAClD,IAAMC,CAAAA,CAAcD,EAAK,KAAM,CAAA,gCAAgC,CAC/D,CAAA,OAAIC,CACKD,CAAAA,CAAAA,CAAK,UAAUC,CAAY,CAAA,CAAC,CAAE,CAAA,MAAM,CAEtCD,CAAAA,CACT,EACME,CAAiBpC,CAAAA,CAAAA,CAAS,GAAKC,CAAAA,CAAAA,EAAY,CAC/C,IAAMoC,EAAgBC,OAAQ,EAAA,CAAE,SAAUrC,CAAAA,CAAO,CACjD,CAAA,GAAI,CAACoC,CAAc,CAAA,OAAA,CACjB,MAAM,IAAIjB,oBAAqB,CAAA,CAAE,KAAM,kBAAoB,CAAA,KAAA,CAAOiB,CAAc,CAAA,KAAM,CAAC,CAAA,CAEzF,OAAOA,CAAc,CAAA,IACvB,CAAC,CAAA,CAEDD,CAAe,CAAA,OAAA,CAASnC,GAAY,CAClCA,CAAAA,CAAQ,OAAQ,CAAA,OAAA,CAASC,CAAY,EAAA,CACnC,GAAI,CAAC,IAAA,CAAK,WAAY,CAAA,UAAA,CAAW,QAASA,CAAAA,CAAAA,CAAQ,QAAQ,CACxD,CAAA,MAAM,IAAIkB,oBAAAA,CAAqB,CAC7B,IAAA,CAAM,wCAAwC,IAAK,CAAA,SAAS,CAC5D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAAkClB,+BAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAA;AAAA,sCACjE,EAAA,IAAA,CAAK,YAAY,UAAW,CAAA,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACvE,CAAC,CAEL,CAAC,EACH,CAAC,EAEDkC,CAAe,CAAA,OAAA,CAASnC,GAAY,CAClC,GAAI,CAAC,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,SAASA,CAAQ,CAAA,IAAI,EAC5D,MAAM,IAAImB,oBAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,MAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAA8BnB,2BAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAAA;AAAA,+BAAA,EAC9D,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC1E,CAAC,CAEL,CAAC,CAAA,CAED,IAAMM,CAAqD,CAAA,CAAE,MAAO,EAAG,EACjEgC,CAA6C,CAAA,GAuHnD,GArHAH,CAAAA,CAAe,QAASnC,CAAY,EAAA,CAClC,OAAQA,CAAQ,CAAA,IAAA,EACd,KAAK3C,iBAAAA,CAED2C,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAapC,GAAAA,mBAAAA,CACvByC,EAAkB,KAAM,CAAA,IAAA,CAAK,CAAE,IAAML,CAAAA,CAAAA,CAAQ,KAAM,CAAC,CAAA,CAAA,WAE9C,IAAIkB,oBAAAA,CAAqB,CAC7B,IAAM,CAAA,CAAA,8DAAA,EAAiE,KAAK,SAAS,CAAA,CAAA,CACrF,MAAO,IAAI,KAAA,CAAM,WAAWnB,CAAQ,CAAA,IAAI,0CAA0CC,CAAQ,CAAA,QAAQ,GAAG,CACvG,CAAC,CAEL,CAAC,CAAA,CAEH,MAEF,KAAK1C,oBAAAA,CACH,CACE,IAAMgF,CAAAA,CAAmD,EACzDvC,CAAAA,CAAAA,CAAQ,QAAQ,OAASC,CAAAA,CAAAA,EAAY,CACnC,GAAIA,CAAAA,CAAQ,QAAapC,GAAAA,mBAAAA,CACvB0E,EAAiB,IAAK,CAAA,CAAE,KAAMtC,CAAQ,CAAA,KAAM,CAAC,CACpCA,CAAAA,KAAAA,GAAAA,CAAAA,CAAQ,WAAalC,uBAC9BwE,CAAAA,CAAAA,CAAiB,KAAK,CACpB,aAAA,CAAe,CACb,IAAMtC,CAAAA,CAAAA,CAAQ,KACd,IAAM,CAAA,IAAA,CAAK,MAAMA,CAAQ,CAAA,SAAS,CACpC,CACF,CAAC,OAEK,MAAA,IAAIkB,qBAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWnB,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EACDqC,CAAkB,CAAA,IAAA,CAAK,CACrB,IAAM,CAAA,IAAA,CAAK,YAAY,KAAMtC,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,KAAA,CAAOuC,CACT,CAAC,EACH,CACA,MAEF,KAAKjF,gBACH,CACE,IAAMkF,EAA8C,EAAC,CACrDxC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAapC,GAAAA,mBAAAA,CACvB2E,EAAY,IAAK,CAAA,CAAE,KAAMvC,CAAQ,CAAA,KAAM,CAAC,CAC/BA,CAAAA,KAAAA,GAAAA,CAAAA,CAAQ,QAAanC,GAAAA,oBAAAA,CAAAA,CAC9B,GAAImC,CAAQ,CAAA,KAAA,CAAM,OAAS,QAAU,CAAA,CACnC,IAAIwC,CAAaxC,CAAAA,CAAAA,CAAQ,MAAM,MAE/BwC,CAAAA,CAAAA,CAAaT,EAAkBS,CAAU,CAAA,CACzCD,EAAY,IAAK,CAAA,CACf,YAAa,CACX,SAAA,CAAW,SAASvC,CAAQ,CAAA,KAAA,CAAM,SAAS,CAC3C,CAAA,CAAA,IAAA,CAAMwC,CACR,CACF,CAAC,EACH,CAAWxC,KAAAA,GAAAA,CAAAA,CAAQ,MAAM,IAAS,GAAA,KAAA,CAEhC,MAAM,IAAIkB,oBAAAA,CAAqB,CAC7B,IAAM,CAAA,CAAA,uCAAA,EAA0C,KAAK,SAAS,CAAA,CAAA,CAC9D,MAAO,IAAI,KAAA,CAAM,WAAW,IAAK,CAAA,SAAS,2CAA2ClB,CAAQ,CAAA,KAAA,CAAM,IAAI,CAAG,CAAA,CAAA,CAC5G,CAAC,CAGH,CAAA,KAAA,MAAM,IAAIkB,oBAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWnB,EAAQ,IAAI,CAAA,uCAAA,EAA0CC,EAAQ,QAAQ,CAAA,CAAA,CAAG,CACvG,CAAC,CAEL,CAAC,CACDqC,CAAAA,CAAAA,CAAkB,KAAK,CACrB,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMtC,EAAQ,IAAI,CAAA,CACzC,MAAOwC,CACT,CAAC,EACH,CACA,MAEF,KAAKhF,eACH,CAAA,CACE,IAAMkF,CAAmE,CAAA,GACzE1C,CAAQ,CAAA,OAAA,CAAQ,QAASC,CAAY,EAAA,CACnC,GAAIA,CAAQ,CAAA,QAAA,GAAajC,4BACvB0E,CAAoB,CAAA,IAAA,CAAK,CACvB,iBAAmB,CAAA,CACjB,KAAMzC,CAAQ,CAAA,IAAA,CACd,SAAU,IAAK,CAAA,KAAA,CAAMA,EAAQ,IAAI,CACnC,CACF,CAAC,CAAA,CAAA,WAEK,IAAIkB,oBAAAA,CAAqB,CAC7B,IAAM,CAAA,CAAA,8DAAA,EAAiE,KAAK,SAAS,CAAA,CAAA,CACrF,MAAO,IAAI,KAAA,CAAM,WAAWnB,CAAQ,CAAA,IAAI,0CAA0CC,CAAQ,CAAA,QAAQ,GAAG,CACvG,CAAC,CAEL,CAAC,CAAA,CACDqC,EAAkB,IAAK,CAAA,CACrB,KAAM,IAAK,CAAA,WAAA,CAAY,MAAMtC,CAAQ,CAAA,IAAI,EACzC,KAAO0C,CAAAA,CACT,CAAC,EACH,CACA,MAEF,QACE,MAAM,IAAIvB,oBAAqB,CAAA,CAC7B,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAC1D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWnB,EAAQ,IAAI,CAAA;AAAA,iCACjB,EAAA,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,WAAY,CAAA,KAAK,CAAE,CAAA,IAAA,CAAK,IAAI,CAAC,CAAG,CAAA,CAAA,CAC1E,CAAC,CAEL,CACF,CAAC,CAEGsC,CAAAA,CAAAA,CAAkB,CAAC,CAAA,CAAE,IAAS,GAAA,IAAA,CAAK,WAAY,CAAA,KAAA,CAAMhF,eAAe,CAAA,CACtE,MAAM,IAAI6D,oBAAqB,CAAA,CAC7B,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,SAAA,EAAY,IAAK,CAAA,SAAS,CAA0C,wCAAA,CAAA,CACvF,CAAC,CAAA,CAGH,IAAMwB,CAAAA,CAAwB7B,CACxBA,EAAAA,CAAAA,GAAS,IAAK,CAAA,WAAA,CAAY,KAAMxD,CAAAA,eAAe,CAAKwD,EAAAA,CAAAA,GAAS,IAAK,CAAA,WAAA,CAAY,KAAMtD,CAAAA,eAAe,CAC9F,CAAA,CAAC,KAAK,WAAY,CAAA,KAAA,CAAMD,oBAAoB,CAAW,CAEzD,CAAA,CAAC,IAAK,CAAA,WAAA,CAAY,KAAMD,CAAAA,eAAe,CAAa,CAAA,IAAA,CAAK,WAAY,CAAA,KAAA,CAAME,eAAe,CAAW,CAG9G,CAAA,IAAA,IAAS,CAAI,CAAA,CAAA,CAAG,CAAI8E,CAAAA,CAAAA,CAAkB,MAAQ,CAAA,CAAA,EAAA,CAC5C,GAAI,CAACK,CAAqBL,CAAAA,CAAAA,CAAkB,CAAI,CAAA,CAAC,CAAE,CAAA,IAAI,CAAE,CAAA,QAAA,CAASA,CAAkB,CAAA,CAAC,CAAE,CAAA,IAAI,CACzF,CAAA,MAAM,IAAInB,oBAAAA,CAAqB,CAC7B,IAAA,CAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KACT,CAAA,CAAA,SAAA,EAAY,IAAK,CAAA,SAAS,CAAsCmB,mCAAAA,EAAAA,CAAAA,CAAkB,CAAC,CAAA,CAAE,IAAI,CAAA,6BAAA,EAAgCA,CAAkB,CAAA,CAAA,CAAI,CAAC,CAAE,CAAA,IAAI,CACxJ,CAAA,CAAA,CACF,CAAC,CAAA,CAIL,GACEA,CAAAA,CAAkBA,CAAkB,CAAA,MAAA,CAAS,CAAC,CAAA,CAAE,IAAS,GAAA,IAAA,CAAK,WAAY,CAAA,KAAA,CAAMhF,eAAe,CAAA,EAC/FgF,CAAkBA,CAAAA,CAAAA,CAAkB,MAAS,CAAA,CAAC,CAAE,CAAA,IAAA,GAAS,IAAK,CAAA,WAAA,CAAY,KAAM9E,CAAAA,eAAe,CAE/F,CAAA,MAAM,IAAI2D,oBAAAA,CAAqB,CAC7B,IAAA,CAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,SAAA,EAAY,IAAK,CAAA,SAAS,CAAyC,uCAAA,CAAA,CACtF,CAAC,CAAA,CAGH,OAAOxI,CAAAA,CAAA,CACL,QAAA,CAAU2J,CACNhC,CAAAA,CAAAA,CAAAA,CAAkB,KAAM,CAAA,MAAA,CAAS,CAAI,CAAA,CAAE,kBAAoBA,CAAAA,CAAkB,CAAI,CAAA,GAEzF,CAEA,cAAA,CAAec,CAA+B,CAAA,CAC5C,GAAI,CAAC,IAAK,CAAA,WAAA,CAAY,UAAW,CAAA,QAAA,CAASrD,uBAAuB,CAAA,CAC/D,MAAM,IAAI6E,iBAAkB,CAAA,CAC1B,IAAM,CAAA,CAAA,oCAAA,EAAuC,IAAK,CAAA,SAAS,CAC3D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,CAAY,SAAA,EAAA,IAAA,CAAK,SAAS,CAAA,oCAAA,EAAuC7E,uBAAuB,CAAA,CAAA,CAAG,CAC9G,CAAC,CAGH,CAAA,OAAI,CAACqD,CAAAA,EAAUA,CAASA,EAAAA,CAAAA,CAAM,MAAW,GAAA,CAAA,CAChC,CAAE,KAAA,CAAO,EAAiB,CAiB5B,CAAA,CACL,KAAO,CAAA,CACL,CACE,qBAAA,CAjBcA,CAAM,CAAA,GAAA,CAAKC,CAAS,EAAA,CACtC,IAAMwB,CAAAA,CAAaC,IAAK,EAAA,CAAE,SAAUzB,CAAAA,CAAI,CACxC,CAAA,GAAI,CAACwB,CAAW,CAAA,OAAA,CACd,MAAM,IAAID,iBAAkB,CAAA,CAAE,IAAM,CAAA,eAAA,CAAiB,KAAOC,CAAAA,CAAAA,CAAW,KAAM,CAAC,CAEhF,CAAA,OAAOA,CAAW,CAAA,IACpB,CAAC,CAAA,CAEoC,GAAKxB,CAAAA,CAAAA,GAAU,CAClD,IAAA,CAAMA,CAAK,CAAA,UAAA,CAAW,MAAO,CAAA,IAAA,CAC7B,WAAaA,CAAAA,CAAAA,CAAK,UAAW,CAAA,MAAA,CAAO,YACpC,UAAYA,CAAAA,CAAAA,CAAK,UAAW,CAAA,MAAA,CAAO,UACrC,CAAA,CAAE,CAME,CACF,CACF,CACF,CAGM,kBAAA,CAAmBX,CAAqBX,CAAAA,CAAAA,CAA0BqB,CAAsC,CAAA,CAAA,OAAA2B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,eAAe,EAC9B,CAAC,CACH,CAAA,CAAA,CAGM,uBAAuBtC,CAAqBX,CAAAA,CAAAA,CAA0BqB,CAA0C,CAAA,CAAA,OAAA2B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CACpH,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,iBAAA,EAAmB,EAClC,CAAC,CACH,CAEM,CAAA,CAAA,mBAAA,CAAoBtC,CAAoBX,CAAAA,CAAAA,CAAyBqB,CAAyC,CAAA,CAAA,OAAA2B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC9G,IAAMrB,CAAAA,CAAoB,IAAK,CAAA,eAAA,CAAgBhB,CAAQX,CAAAA,CAAAA,CAAUqB,CAAK,CAAA,CAChE6B,CAAsB,CAAA,IAAA,CAAK,iBAAkBlD,CAAAA,CAAQ,CAC3D,CAAA,GAAIkD,CAAoB,CAAA,QAAA,EAAaA,CAAoB,CAAA,QAAA,CAA2B,MAAW,GAAA,CAAA,CAC7F,MAAM,IAAI9B,oBAAqB,CAAA,CAC7B,IAAM,CAAA,uBAAA,CACN,KAAO,CAAA,IAAI,KAAM,CAAA,uBAAuB,CAC1C,CAAC,CAGH,CAAA,IAAM+B,CAAmB9B,CAAAA,CAAAA,CAAQ,KAAK,cAAeA,CAAAA,CAAK,CAAI,CAAA,EAE9D,CAAA,OAAO,IAAI,OAAA,CAAS4B,CAAY,EAAA,CAC9BA,CAAQrK,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,EACH,CAAA,IAAA,CAAK,gBAAiB,EAAA,CAAA,CACtB+I,CACAuB,CAAAA,CAAAA,CAAAA,CAAAA,CACAC,CACJ,CAAA,EACH,CAAC,CACH,CAEA,CAAA,CAAA,6BAAA,CAA8BC,CAAiC,CAAA,CAC7D,IAAMC,CAAAA,CAAO1E,EAA2B,CAAA,SAAA,CAAUyE,CAAQ,CAAA,CAC1D,GAAIC,CAAAA,CAAK,OAAS,CAAA,CAChB,GAAIA,CAAAA,CAAK,IAAK,CAAA,UAAA,CAAW,MAAW,GAAA,CAAA,CAClC,MAAM,IAAIC,kBAAmB,CAAA,CAC3B,IAAM,CAAA,6BAAA,CACN,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,yBAAA,EAA4B,IAAK,CAAA,SAAA,CAAUD,CAAK,CAAA,IAAI,CAAC,CAAA,CAAE,CAC1E,CAAC,CAGH,CAAA,IAAME,EAAiDF,CAAK,CAAA,IAAA,CACtDrD,CAA0B,CAAA,EAC5BwD,CAAAA,CAAAA,CACExC,CAAWuC,CAAAA,CAAAA,CAAe,UAAW,CAAA,CAAC,CAAE,CAAA,OAAA,CAC9C,GAAIvC,CAAAA,CAAU,CACZ,IAAMd,CAAUc,CAAAA,CAAAA,CAAS,KAAM,CAAA,GAAA,CAAI,CAACyC,CAAAA,CAAkBtC,CAAe,GAAA,CACnE,GAAI,MAAA,GAAUsC,CAAeA,EAAAA,CAAAA,CAAY,IAAS,GAAA,KAAA,CAAA,CAChD,OAAOC,iBAAAA,CAAkBD,CAAY,CAAA,IAAI,CACpC,CAAA,GAAI,cAAkBA,GAAAA,CAAAA,EAAeA,CAAY,CAAA,YAAA,GAAiB,KACvE,CAAA,CAAA,OAAOE,qBACLxC,CAAAA,CAAAA,CACA,CAAGsC,EAAAA,CAAAA,CAAY,YAAa,CAAA,IAAI,CAAItC,CAAAA,EAAAA,CAAK,CACzCsC,CAAAA,CAAAA,CAAAA,CAAY,YAAa,CAAA,IAAA,CACzB,IAAK,CAAA,SAAA,CAAUA,CAAY,CAAA,YAAA,CAAa,IAAI,CAC9C,CAEJ,CAAC,EAED,OAAAzD,CAAAA,CAAS,IAAK,CAAA,CACZ,IAAMxC,CAAAA,oBAAAA,CACN,OAAS0C,CAAAA,CACX,CAAC,CAAA,CAEGqD,CAAe,CAAA,aAAA,GACjBC,CAAQ,CAAA,CACN,YAAcD,CAAAA,CAAAA,CAAe,aAAc,CAAA,gBAAA,CAC3C,WAAaA,CAAAA,CAAAA,CAAe,aAAc,CAAA,eAAA,CAC1C,gBAAkBA,CAAAA,CAAAA,CAAe,aAAc,CAAA,oBAAA,EAAwB,CACzE,CAAA,CAAA,CAGK,CACL,QAAA,CAAUvD,EACV,KAAOwD,CAAAA,CAAAA,CACP,QAAU,CAAA,KAAA,CACZ,CACF,CAEA,IAAMI,CAAAA,CAAgBL,CAAe,CAAA,UAAA,CAAW,CAAC,CAAA,CAAE,aAanD,CAAA,GAZIK,CAAiBA,EAAAA,CAAAA,CAAc,MAAS,CAAA,CAAA,EAC1CA,CAAc,CAAA,OAAA,CAASC,CAAW,EAAA,CAChC,GAAIA,CAAAA,CAAO,OACT,CAAA,MAAM,IAAIP,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,iCAAiCO,CAAO,CAAA,QAAQ,CAAsBA,mBAAAA,EAAAA,CAAAA,CAAO,WAAW,CAAA,CAAA,CAC9F,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,8BAAA,EAAiCA,CAAO,CAAA,QAAQ,CAAsBA,mBAAAA,EAAAA,CAAAA,CAAO,WAAW,CAAA,CAAE,CAC7G,CAAC,CAEL,CAAC,CAGkBN,CAAAA,CAAAA,CAAe,UAAW,CAAA,CAAC,CAAE,CAAA,YAAA,GAC7B,QACnB,CAAA,MAAM,IAAID,kBAAAA,CAAmB,CAC3B,IAAA,CAAM,6DACN,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,6DAA6D,CAChF,CAAC,CAEL,CAEA,MAAM,IAAIA,kBAAAA,CAAmB,CAAE,IAAA,CAAM,6BAA+B,CAAA,KAAA,CAAOD,CAAK,CAAA,KAAM,CAAC,CACzF,CAGM,gBAAA,CAAiB1C,CAAqBX,CAAAA,CAAAA,CAA0BqB,CAAsC,CAAA,CAAA,OAAA2B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1G,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,aAAa,EAC5B,CAAC,CACH,CAGM,CAAA,CAAA,oBAAA,CAAqBtC,CAAqBX,CAAAA,CAAAA,CAA0BqB,CAA0C,CAAA,CAAA,OAAA2B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAClH,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,iBAAA,EAAmB,EAClC,CAAC,CACH,CAEM,CAAA,CAAA,iBAAA,CAAkBtC,CAAoBX,CAAAA,CAAAA,CAAyBqB,CAAyC,CAAA,CAAA,OAAA2B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,IAAMrB,CAAAA,CAAoB,IAAK,CAAA,eAAA,CAAgBhB,CAAQX,CAAAA,CAAAA,CAAUqB,CAAK,CAAA,CAChE6B,CAAsB,CAAA,IAAA,CAAK,iBAAkBlD,CAAAA,CAAQ,CAC3D,CAAA,GAAIkD,CAAoB,CAAA,QAAA,EAAaA,CAAoB,CAAA,QAAA,CAA2B,MAAW,GAAA,CAAA,CAC7F,MAAM,IAAI9B,oBAAqB,CAAA,CAC7B,IAAM,CAAA,uBAAA,CACN,MAAO,IAAI,KAAA,CAAM,uBAAuB,CAC1C,CAAC,CAAA,CAGH,IAAM+B,CAAAA,CAAmB9B,CAAQ,CAAA,IAAA,CAAK,cAAeA,CAAAA,CAAK,CAAI,CAAA,EAE9D,CAAA,OAAO,IAAI,OAAA,CAAS4B,CAAY,EAAA,CAC9BA,CAAQrK,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,EACH,CAAA,IAAA,CAAK,gBAAiB,EAAA,CAAA,CACtB+I,CACAuB,CAAAA,CAAAA,CAAAA,CAAAA,CACAC,CACJ,CAAA,EACH,CAAC,CACH,CAEO,CAAA,CAAA,gCAAA,CACLW,CACAC,CAAAA,CAAAA,CAC8E,CAAAC,OAAAA,EAAAA,CAAA,IAE9E,CAAA,IAAA,CAAA,WAAA,CAAA,IAAMC,CAASF,CAAAA,CAAAA,CAAAA,CAASD,CAAO,EAAA,KAAA,CAAM,KAAK,CAAA,CAAE,MAAQI,CAAAA,CAAAA,EAASA,CAAK,CAAA,IAAA,EAAW,GAAA,EAAE,CAC/E,CAAA,IAAA,IAAWA,CAAQD,IAAAA,CAAAA,CAAO,CACxB,IAAIE,CAAeD,CAAAA,CAAAA,CAGnB,GADAC,CAAAA,CAAeA,EAAa,OAAQ,CAAA,KAAA,CAAO,EAAE,CAAA,CACzCA,CAAa,CAAA,UAAA,CAAW,GAAG,CAAA,EAAKA,CAAa,CAAA,UAAA,CAAW,IAAI,CAAA,CAE9DA,CAAeA,CAAAA,CAAAA,CAAa,KAAM,CAAA,CAAC,CAC1BA,CAAAA,KAAAA,GAAAA,CAAAA,CAAa,QAAS,CAAA,GAAG,CAAG,CAAA,CACrC,GAAIA,CAAAA,GAAiB,GAEnB,CAAA,OAGAA,CAAeA,CAAAA,CAAAA,CAAa,KAAM,CAAA,CAAA,CAAG,CAAE,CAAA,EAE3C,CAEA,IAAIC,CACJ,CAAA,GAAI,CACFA,CAAAA,CAAiB,IAAK,CAAA,KAAA,CAAMD,CAAY,EAC1C,CAASE,MAAAA,CAAAA,CAAO,CAEd,GAAIA,CAAiB,YAAA,WAAA,CAAa,CAChCN,CAAAA,CAASI,CACT,CAAA,QACF,CAEE,KAAA,MAAME,CAEV,CAGAN,CAAS,CAAA,EAAA,CACT,IAAMV,CAAAA,CAAOvE,EAAyB,CAAA,SAAA,CAAUsF,CAAc,CAC9D,CAAA,GAAIf,CAAK,CAAA,OAAA,CAAS,CAChB,IAAMiB,CAA2C,CAAA,CAAE,eAAiB,CAAA,EAAG,CAAA,CACjEf,CAA+CF,CAAAA,CAAAA,CAAK,IAC1D,CAAA,GAAIE,CAAe,CAAA,UAAA,CAAW,MAAS,CAAA,CAAA,CAAG,CACxC,IAAMtD,CAAUsD,CAAAA,CAAAA,CAAe,UAAW,CAAA,CAAC,CAAE,CAAA,OAAA,CACzCtD,CAAW,EAAA,OAAA,GAAWA,CAAWA,EAAAA,CAAAA,CAAQ,KAAM,CAAA,MAAA,CAAS,CAC1DA,EAAAA,CAAAA,CAAQ,KAAM,CAAA,OAAA,CAAQ,CAACsE,CAAAA,CAAapD,CAAU,GAAA,CAK5C,GAJI,MAAA,GAAUoD,CAAeA,EAAAA,CAAAA,CAAY,IAAS,GAAA,KAAA,CAAA,EAChDD,CAAgB,CAAA,eAAA,CAAgB,IAAKE,CAAAA,wBAAAA,CAAyBhH,oBAAsB+G,CAAAA,CAAAA,CAAY,IAAI,CAAC,CAGnG,CAAA,cAAA,GAAkBA,CAAeA,EAAAA,CAAAA,CAAY,YAAiB,GAAA,KAAA,CAAA,CAAW,CAC3E,IAAME,CAAAA,CAAWF,CAAY,CAAA,YAAA,CAC7BD,CAAgB,CAAA,eAAA,CAAgB,IAC9BI,CAAAA,4BAAAA,CACElH,oBACA2D,CAAAA,CAAAA,CACA,CAAGsD,EAAAA,CAAAA,CAAS,IAAI,CAAA,CAAA,EAAItD,CAAK,CAAA,CAAA,CACzBsD,CAAS,CAAA,IAAA,CACT,IAAK,CAAA,SAAA,CAAUA,CAAS,CAAA,IAAI,CAC9B,CACF,EACF,CACF,CAAC,EAEL,CAEIlB,CAAAA,CAAe,aACjBe,GAAAA,CAAAA,CAAgB,KAAQ,CAAA,CACtB,YAAcf,CAAAA,CAAAA,CAAe,aAAc,CAAA,gBAAA,CAC3C,gBAAkBA,CAAAA,CAAAA,CAAe,aAAc,CAAA,oBAAA,CAC/C,WAAaA,CAAAA,CAAAA,CAAe,aAAc,CAAA,eAC5C,CAGF,CAAA,CAAA,MAAM,CAAE,eAAA,CAAiBe,CAAiB,CAAA,MAAA,CAAQP,CAAO,EAC3D,CACE,KAAA,MAAM,IAAIT,kBAAAA,CAAmB,CAAE,IAAA,CAAM,6BAA+B,CAAA,KAAA,CAAOD,EAAK,KAAM,CAAC,CAE3F,CAEA,MAAM,CAAE,eAAiB,CAAA,CAAE,eAAiB,CAAA,EAAG,CAAA,CAAG,MAAQU,CAAAA,CAAO,EACnE,CAAA,CAAA,CACO,qCACLD,CAAAA,CAAAA,CACAC,CACA7B,CAAAA,CAAAA,CACAyC,CACAC,CAAAA,CAAAA,CAC8E,CAAAZ,OAAAA,EAAAA,CAAA,IAE9E,CAAA,IAAA,CAAA,WAAA,CAAA,GAAA,CAAIY,CAAA,EAAA,IAAA,CAAA,KAAA,CAAA,CAAAA,CAAO,CAAA,GAAA,IAAQ,KAAO,CAAA,CACxB,MAAAC,EAAAA,CAAO,IAAK,CAAA,gCAAA,CAAiCf,CAAOC,CAAAA,CAAM,CAC1D,CAAA,CAAA,MACF,CAGA,IAAMe,CAAUf,CAAAA,CAAAA,CAASD,CACrBG,CAAAA,CAAAA,CAAkB,EAAC,CACnBc,CAAY,CAAA,EAAA,CAGZC,CAAe,CAAA,CAAA,CACnB,KAAOA,CAAAA,CAAeF,CAAQ,CAAA,MAAA,EAAQ,CACpC,IAAMG,CAAeH,CAAAA,CAAAA,CAAQ,OAAQ,CAAA,CAAA;AAAA,CAAME,CAAAA,CAAY,EACvD,GAAIC,CAAAA,GAAiB,GAAI,CACvBF,CAAAA,CAAYD,EAAQ,SAAUE,CAAAA,CAAY,EAC1C,KACF,CAAA,KAAO,CACL,IAAMd,CAAAA,CAAOY,EAAQ,SAAUE,CAAAA,CAAAA,CAAcC,CAAY,CAAA,CAAE,IAAK,EAAA,CAC5Df,GACFD,CAAM,CAAA,IAAA,CAAKC,CAAI,CAEjBc,CAAAA,CAAAA,CAAeC,EAAe,EAChC,CACF,CAGA,IAAWf,IAAAA,CAAAA,IAAQD,EAAO,CACxB,GAAIC,IAAS,cACX,CAAA,OAGF,GAAIA,CAAK,CAAA,UAAA,CAAW,QAAQ,CAAA,CAAG,CAC7B,IAAMgB,EAAUhB,CAAK,CAAA,SAAA,CAAU,CAAe,CAC9C,CAAA,GAAI,CACF,IAAME,CAAAA,CAAiB,KAAK,KAAMc,CAAAA,CAAO,EACnC7B,CAAOvE,CAAAA,EAAAA,CAAyB,UAAUsF,CAAc,CAAA,CAC9D,GAAIf,CAAK,CAAA,OAAA,CAAS,CAChB,IAAMiB,CAA2C,CAAA,CAAE,gBAAiB,EAAG,EACjEf,CAA+CF,CAAAA,CAAAA,CAAK,KAC1D,GAAIE,CAAAA,CAAe,UAAW,CAAA,MAAA,CAAS,CAAG,CAAA,CACxC,IAAMtD,CAAUsD,CAAAA,CAAAA,CAAe,WAAW,CAAC,CAAA,CAAE,QACzCtD,CAAW,EAAA,OAAA,GAAWA,CAAWA,EAAAA,CAAAA,CAAQ,KAAM,CAAA,MAAA,CAAS,GAC1DA,CAAQ,CAAA,KAAA,CAAM,QAAQ,CAACsE,CAAAA,CAAapD,IAAU,CAK5C,GAJI,SAAUoD,CAAeA,EAAAA,CAAAA,CAAY,OAAS,KAChDD,CAAAA,EAAAA,CAAAA,CAAgB,gBAAgB,IAAKE,CAAAA,wBAAAA,CAAyBhH,qBAAsB+G,CAAY,CAAA,IAAI,CAAC,CAAA,CAGnG,cAAkBA,GAAAA,CAAAA,EAAeA,EAAY,YAAiB,GAAA,KAAA,CAAA,CAAW,CAC3E,IAAME,EAAAA,CAAWF,EAAY,YAC7BD,CAAAA,CAAAA,CAAgB,gBAAgB,IAC9BI,CAAAA,4BAAAA,CACElH,qBACA2D,CACA,CAAA,CAAA,EAAGsD,GAAS,IAAI,CAAA,CAAA,EAAItD,CAAK,CACzBsD,CAAAA,CAAAA,EAAAA,CAAS,IACT,CAAA,IAAA,CAAK,SAAUA,CAAAA,EAAAA,CAAS,IAAI,CAC9B,CACF,EACF,CACF,CAAC,EAEL,CAGElB,CAAAA,CAAe,eACfA,CAAe,CAAA,aAAA,CAAc,iBAC7BA,CAAe,CAAA,aAAA,CAAc,kBAC7BA,CAAe,CAAA,aAAA,CAAc,uBAE7Be,CAAgB,CAAA,KAAA,CAAQ,CACtB,YAAA,CAAcf,CAAe,CAAA,aAAA,CAAc,iBAC3C,gBAAkBA,CAAAA,CAAAA,CAAe,cAAc,oBAC/C,CAAA,WAAA,CAAaA,EAAe,aAAc,CAAA,eAC5C,CAGF,CAAA,CAAA,MAAM,CAAE,eAAA,CAAiBe,EAAiB,MAAQP,CAAAA,CAAO,EAC3D,CACE,KAAA,MAAM,IAAIT,kBAAmB,CAAA,CAAE,IAAM,CAAA,6BAAA,CAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CAE3F,OAASgB,CAAO,CAAA,CACd,MAAM,IAAIf,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,mCAAA,EAAsC4B,CAAO,CACnD,CAAA,CAAA,KAAA,CAAOb,CACT,CAAC,CACH,CACF,CACF,CAGA,MAAM,CAAE,eAAiB,CAAA,CAAE,gBAAiB,EAAG,EAAG,MAAQU,CAAAA,CAAU,EACtE,CAEM,CAAA,CAAA,uBAAA,CAAwB7C,EAAYyC,CAAkCC,CAAAA,CAAAA,CAAkD,QAAA5B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5H,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,eAAe,EAC9B,CAAC,CACH,CAEM,CAAA,CAAA,qBAAA,CAAsBf,EAAYyC,CAAkCC,CAAAA,CAAAA,CAAkD,QAAA5B,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1H,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9B,GAAI,CAAC2B,CAAS,EAAA,MAAA,CAAO,KAAKA,CAAK,CAAA,CAAE,MAAW,GAAA,CAAA,CAAG,CAC7C3B,CAAAA,CAAQ,KAAK,aAAa,CAAA,CAC1B,MACF,CAEA,IAAMkC,EAAM,IAAI,GAAA,CAAI,IAAK,CAAA,aAAa,CACtC,CAAA,MAAA,CAAO,QAAQP,CAAK,CAAA,CAAE,QAAQ,CAAC,CAAC9H,EAAKsI,CAAK,CAAA,GAAM,CAC1CA,CAAAA,EAAS,IACXD,EAAAA,CAAAA,CAAI,aAAa,GAAIrI,CAAAA,CAAAA,CAAKsI,CAAK,EAEnC,CAAC,EAEDnC,CAAQkC,CAAAA,CAAAA,CAAI,UAAqB,EACnC,CAAC,CACH,CAAA,CAAA,CACM,4BAA4BjD,CAAYyC,CAAAA,CAAAA,CAAkCC,EAAsD,CAAA5B,OAAAA,CAAAA,CAAA,IACpI,CAAA,IAAA,CAAA,WAAA,CAAA,GAAI,CAAC2B,CAAAA,CACH,OAAO,EAAC,CAEV,IAAMU,CAA2CzM,CAAAA,CAAAA,CAAA,GAAK+L,CAEtD,CAAA,CAAA,OAAA,OAAOU,EAAiB,IACxB,CAAA,OAAOA,EAAiB,gBAAgB,CAAA,CACjCA,CACT,CACM,CAAA,CAAA,yBAAA,CAA0BnD,EAAYyC,CAAkCC,CAAAA,CAAAA,CAAsD,CAAA5B,OAAAA,CAAAA,CAAA,IAElI,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,MAAM,IAAK,CAAA,2BAAA,CAA4Bd,EAAMyC,CAASC,CAAAA,CAAK,CACpE,CACA,CAAA,CAAA,eAAA,EAAsC,CAEpC,GAAI,EAAE,KAAK,SAAaxH,IAAAA,CAAAA,CAAAA,CACtB,MAAM,IAAIkG,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,mCAAA,EAAsC,IAAK,CAAA,SAAS,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,0CAAA,EAA6C,KAAK,SAAS,CAAA,CAAA,CAAG,CACjF,CAAC,CAAA,CAIH,OADclG,CAAAA,CAAY,IAAK,CAAA,SAAqC,CAEtE,CACF,ECjhCM3D,IAAAA,EAAAA,CAA2B,sBAC3B6L,CAAAA,EAAAA,CACJ,0LAGI1L,CAAAA,EAAAA,CAA0B2L,gBAAgBlI,CAAsBa,CAAAA,CAA6B,EAAE,KAAM,CAAA,CACzG,KAAMzE,EACN,CAAA,WAAA,CAAa6L,GACb,cAAgB,CAAA,GAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAO1H,EACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKxE,CAAuB,CAAA,cAAA,CAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,EAAE,GACpE,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,CAAA,CAAK,EAAK,IAAM,CAAA,CAAA,CAAG,GAAI,CAAE,CAAA,MACzE,EACA,KAAO+D,CAAAA,CAAAA,CAAY3D,EAAwB,CAC7C,CAAC,CAEKE,CAAAA,EAAAA,CAA2B+F,CAG3BhG,CAAAA,EAAAA,CAAN,cAAgCiG,CAAc,CAC5C,YAAY5C,CAAuC,CAAA,CACjD,MAAMnD,EAAyBmD,CAAAA,CAAO,EACxC,CACF,EC1BMlD,IAAAA,EAAAA,CAA2B,uBAC3B2L,EACJ,CAAA,0LAAA,CAGIxL,EAA0BuL,CAAAA,eAAAA,CAAgBlI,CAAsBa,CAAAA,CAA6B,EAAE,KAAM,CAAA,CACzG,KAAMrE,EACN,CAAA,WAAA,CAAa2L,GACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,KAAO5H,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKxE,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,IAAM,CAAA,CAAA,CAAG,GAAI,CAAA,CAAE,IACpE,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,EAAE,MACzE,CAAA,CACA,MAAO+D,CAAYvD,CAAAA,EAAwB,CAC7C,CAAC,CAAA,CAEKE,GAA2B2F,CAG3B5F,CAAAA,EAAAA,CAAN,cAAgC6F,CAAc,CAC5C,WAAA,CAAY5C,EAAuC,CACjD,KAAA,CAAM/C,GAAyB+C,CAAO,EACxC,CACF,MC1BM9C,EAA8B,CAAA,yBAAA,CAC9BwL,GACJ,oKAGIrL,CAAAA,EAAAA,CAA6BmL,gBAAgBlI,CAAsBa,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC5G,IAAA,CAAMjE,GACN,WAAawL,CAAAA,EAAAA,CACb,eAAgB,GAChB,CAAA,eAAA,CAAiB,KACjB,KAAO7H,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKxE,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,CAAE,CAAA,GAAA,CACpE,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,EAAE,MACzE,CAAA,CACA,KAAO+D,CAAAA,CAAAA,CAAYnD,EAA2B,CAChD,CAAC,CAEKE,CAAAA,EAAAA,CAA8BuF,EAG9BxF,EAAN,CAAA,cAAmCyF,CAAc,CAC/C,WAAA,CAAY5C,CAA0C,CAAA,CACpD,KAAM3C,CAAAA,EAAAA,CAA4B2C,CAAO,EAC3C,CACF,EC1BA,IAAM1C,GAAwB,kBACxBqL,CAAAA,EAAAA,CACJ,2LAGIlL,EAAuB+K,CAAAA,eAAAA,CAAgBlI,EAAsBa,CAA6B,CAAA,CAAE,MAAM,CACtG,IAAA,CAAM7D,EACN,CAAA,WAAA,CAAaqL,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,IAAA,CACjB,MAAO9H,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,IAAKxE,CAAuB,CAAA,cAAA,CAAe,EAAK,CAAK,CAAA,IAAA,CAAM,EAAG,GAAI,CAAA,CAAE,IACpE,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,CAAA,CAAK,CAAK,CAAA,IAAA,CAAM,EAAG,GAAI,CAAA,CAAE,MACzE,CACA,CAAA,KAAA,CAAO+D,EAAY/C,EAAqB,CAC1C,CAAC,CAEKE,CAAAA,EAAAA,CAAwBmF,EAGxBpF,EAAN,CAAA,cAA6BqF,CAAc,CACzC,WAAA,CAAY5C,EAAoC,CAC9C,KAAA,CAAMvC,EAAsBuC,CAAAA,CAAO,EACrC,CACF,EC1BA,IAAMtC,GAAyB,oBACzBkL,CAAAA,EAAAA,CACJ,oKAGI/K,CAAAA,EAAAA,CAAwB2K,eAAgBlI,CAAAA,CAAAA,CAAsBa,CAA6B,CAAE,CAAA,KAAA,CAAM,CACvG,IAAMzD,CAAAA,EAAAA,CACN,YAAakL,EACb,CAAA,cAAA,CAAgB,GAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO/H,EACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKxE,EAAuB,cAAe,CAAA,CAAA,CAAK,EAAK,IAAM,CAAA,CAAA,CAAG,GAAI,CAAE,CAAA,GAAA,CACpE,OAAQA,CAAuB,CAAA,cAAA,CAAe,EAAK,CAAK,CAAA,IAAA,CAAM,CAAG,CAAA,GAAI,CAAE,CAAA,MACzE,EACA,KAAO+D,CAAAA,CAAAA,CAAY3C,EAAsB,CAC3C,CAAC,EAEKE,EAAyB+E,CAAAA,CAAAA,CAGzBhF,EAAN,CAAA,cAA8BiF,CAAc,CAC1C,YAAY5C,CAAqC,CAAA,CAC/C,MAAMnC,EAAuBmC,CAAAA,CAAO,EACtC,CACF,MC1BMlC,EAAyB,CAAA,oBAAA,CACzB+K,GACJ,oKAGI5K,CAAAA,EAAAA,CAAwBuK,gBAAgBlI,CAAsBa,CAAAA,CAA6B,EAAE,KAAM,CAAA,CACvG,KAAMrD,EACN,CAAA,WAAA,CAAa+K,GACb,cAAgB,CAAA,GAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAOhI,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKxE,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,CAAE,CAAA,GAAA,CACpE,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,EAAE,MACzE,CAAA,CACA,KAAO+D,CAAAA,CAAAA,CAAYvC,EAAsB,CAC3C,CAAC,CAEKE,CAAAA,EAAAA,CAAyB2E,EAGzB5E,EAAN,CAAA,cAA8B6E,CAAc,CAC1C,WAAA,CAAY5C,EAAqC,CAC/C,KAAA,CAAM/B,GAAuB+B,CAAO,EACtC,CACF,EC1BM9B,IAAAA,EAAAA,CAA4B,uBAC5B4K,CAAAA,EAAAA,CACJ,qKAGIzK,EAA2BmK,CAAAA,eAAAA,CAAgBlI,EAAsBa,CAA6B,CAAA,CAAE,MAAM,CAC1G,IAAA,CAAMjD,GACN,WAAa4K,CAAAA,EAAAA,CACb,eAAgB,GAChB,CAAA,eAAA,CAAiB,KACjB,KAAOjI,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKxE,CAAuB,CAAA,cAAA,CAAe,EAAK,CAAK,CAAA,IAAA,CAAM,EAAG,GAAI,CAAA,CAAE,IACpE,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,CAAK,CAAA,CAAA,CAAK,KAAM,CAAG,CAAA,GAAI,EAAE,MACzE,CAAA,CACA,MAAO+D,CAAYnC,CAAAA,EAAyB,CAC9C,CAAC,CAEKE,CAAAA,EAAAA,CAA4BuE,EAG5BxE,EAAN,CAAA,cAAiCyE,CAAc,CAC7C,WAAA,CAAY5C,EAAwC,CAClD,KAAA,CAAM3B,EAA0B2B,CAAAA,CAAO,EACzC,CACF,EC1BA,IAAM1B,GAAsB,gBACtByK,CAAAA,EAAAA,CACJ,oKAGItK,CAAAA,EAAAA,CAAqB+J,eAAgBlI,CAAAA,CAAAA,CAAsBa,CAA6B,CAAE,CAAA,KAAA,CAAM,CACpG,IAAM7C,CAAAA,EAAAA,CACN,YAAayK,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,IAAA,CACjB,MAAOlI,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,IAAKxE,CAAuB,CAAA,cAAA,CAAe,CAAK,CAAA,CAAA,CAAK,IAAM,CAAA,CAAA,CAAG,GAAI,CAAE,CAAA,GAAA,CACpE,OAAQA,CAAuB,CAAA,cAAA,CAAe,EAAK,CAAK,CAAA,IAAA,CAAM,EAAG,GAAI,CAAA,CAAE,MACzE,CACA,CAAA,KAAA,CAAO+D,EAAY/B,EAAmB,CACxC,CAAC,CAEKE,CAAAA,EAAAA,CAAsBmE,CAGtBpE,CAAAA,EAAAA,CAAN,cAA2BqE,CAAc,CACvC,WAAY5C,CAAAA,CAAAA,CAAkC,CAC5C,KAAMvB,CAAAA,EAAAA,CAAoBuB,CAAO,EACnC,CACF,EC1BA,IAAMtB,GAA2B,sBAC3BsK,CAAAA,EAAAA,CACJ,sJAGInK,EAA0B2J,CAAAA,eAAAA,CAAgBlI,CAAsBa,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CACzG,IAAMzC,CAAAA,EAAAA,CACN,YAAasK,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,IAAA,CACjB,KAAOnI,CAAAA,CAAAA,CACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKxE,EAAuB,cAAe,CAAA,CAAA,CAAK,EAAK,IAAM,CAAA,CAAA,CAAG,GAAI,CAAA,CAAE,GACpE,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,CAAA,CAAK,EAAK,IAAM,CAAA,CAAA,CAAG,GAAI,CAAE,CAAA,MACzE,EACA,KAAO+D,CAAAA,CAAAA,CAAY3B,EAAwB,CAC7C,CAAC,EAEKE,EAA2B+D,CAAAA,CAAAA,CAG3BhE,GAAN,cAAgCiE,CAAc,CAC5C,WAAA,CAAY5C,CAAuC,CAAA,CACjD,MAAMnB,EAAyBmB,CAAAA,CAAO,EACxC,CACF,EC1BMlB,IAAAA,EAAAA,CAAmC,iCACnCmK,EACJ,CAAA,6GAAA,CAEIhK,GAAkCuJ,eAAgBlI,CAAAA,CAAAA,CAAsBa,CAA6B,CAAE,CAAA,KAAA,CAAM,CACjH,IAAA,CAAMrC,EACN,CAAA,WAAA,CAAamK,GACb,cAAgB,CAAA,OAAA,CAChB,gBAAiB,KACjB,CAAA,KAAA,CAAOpI,EACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKxE,EAAuB,cAAe,CAAA,CAAA,CAAK,EAAK,KAAO,CAAA,CAAA,CAAG,GAAI,CAAE,CAAA,GAAA,CACrE,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,CAAA,CAAK,EAAK,KAAO,CAAA,CAAA,CAAG,GAAI,CAAE,CAAA,MAC1E,EACA,KAAO+D,CAAAA,CAAAA,CAAYvB,EAAgC,CACrD,CAAC,CAAA,CAEKE,GAAmC2D,CAGnC5D,CAAAA,EAAAA,CAAN,cAAwC6D,CAAc,CACpD,YAAY5C,CAA+C,CAAA,CACzD,KAAMf,CAAAA,EAAAA,CAAiCe,CAAO,EAChD,CACF,MCzBMd,EAAiC,CAAA,8BAAA,CACjCgK,GACJ,8HAEI7J,CAAAA,EAAAA,CAAgCmJ,gBAAgBlI,CAAsBa,CAAAA,CAA6B,EAAE,KAAM,CAAA,CAC/G,KAAMjC,EACN,CAAA,WAAA,CAAagK,EACb,CAAA,cAAA,CAAgB,OAChB,CAAA,eAAA,CAAiB,MACjB,KAAOrI,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKxE,CAAAA,CAAAA,CAAuB,SAAU,CAAA,CAAA,CAAK,CAAK,CAAA,KAAA,CAAO,EAAG,GAAI,CAAA,CAAE,IAChE,MAAQA,CAAAA,CAAAA,CAAuB,UAAU,CAAK,CAAA,CAAA,CAAK,KAAO,CAAA,CAAA,CAAG,GAAI,CAAA,CAAE,MACrE,CACA,CAAA,KAAA,CAAO+D,EAAYnB,EAA8B,CACnD,CAAC,CAEKE,CAAAA,EAAAA,CAAiCuD,EAGjCxD,EAAN,CAAA,cAAsCyD,CAAc,CAClD,WAAA,CAAY5C,EAA6C,CACvD,KAAA,CAAMX,GAA+BW,CAAO,EAC9C,CACF,MC7BMmJ,EAAyE,CAAA,CAACC,4BAA4B,CAAA,CAEtGC,EAAqCrO,CAAAA,CAAAA,CAAE,KAAK,CAACoO,4BAA4B,CAAC,ECL1EE,IAAAA,EAAAA,CAA8BtO,CAAE,CAAA,MAAA,CAAO,CAC3C,UAAYA,CAAAA,CAAAA,CAAE,MACZA,CAAE,CAAA,MAAA,CAAO,CACP,MAAQA,CAAAA,CAAAA,CAAE,MAAMA,CAAE,CAAA,MAAA,EAAQ,CAC5B,CAAC,CACH,CACF,CAAC,ECNKuO,IAAAA,EAAAA,CAA8BvO,EAAE,MAAO,CAAA,CAC3C,MAAOA,CAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAC,EACvB,OAASA,CAAAA,CAAAA,CAAE,OAAO,CAChB,KAAA,CAAOA,EACJ,KACCA,CAAAA,CAAAA,CAAE,OAAO,CACP,IAAA,CAAMA,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CACxB,CAAC,CACH,CACC,CAAA,GAAA,CAAI,CAAC,CACV,CAAC,CACH,CAAC,CAAA,CAGKwO,GAAyBxO,CAAE,CAAA,MAAA,CAAO,CACtC,KAAOA,CAAAA,CAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAClC,SAAUA,CAAE,CAAA,KAAA,CAAMuO,EAA2B,CAAE,CAAA,GAAA,CAAI,CAAC,CACpD,CAAA,oBAAA,CAAsBvO,CAAE,CAAA,MAAA,EAAS,CAAA,GAAA,GAAM,GAAI,CAAA,CAAC,EAAE,QAAS,EACzD,CAAC,ECSKyO,IAAAA,CAAAA,CAA4BzO,EAAE,MAAO,CAAA,CACzC,UAAWA,CAAE,CAAA,MAAA,GACb,MAAQA,CAAAA,CAAAA,CAAE,QACV,CAAA,OAAA,CAASA,EAAE,MAAO,EAAA,CAAE,KAAM,CAAA,QAAA,GAC1B,gBAAkBA,CAAAA,CAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,UACrC,CAAC,EAGK0O,CAAN,CAAA,KAA+E,CAS7E,WAAY7G,CAAAA,CAAAA,CAAuC7C,EAAwC,CAR3F,IAAA,CAAS,QAAU,IASjB,CAAA,IAAMI,EAAgBqJ,CAA0B,CAAA,KAAA,CAAMzJ,CAAO,CAC7D,CAAA,IAAA,CAAK,WAAc6C,CAAAA,CAAAA,CACnB,IAAK,CAAA,SAAA,CAAYzC,EAAc,SAC/B,CAAA,IAAA,CAAK,OAASA,CAAc,CAAA,MAAA,CAC5B,KAAK,OAAU2C,CAAAA,uBAAAA,CAAwB3C,CAAc,CAAA,OAAA,EAAW3D,CAAO,CAAA,OAAO,EAC9E,IAAK,CAAA,gBAAA,CAAmBsG,wBACtB3C,CAAc,CAAA,gBAAA,EAAoB,GAAG,IAAK,CAAA,OAAO,CAAW,QAAA,EAAA,IAAA,CAAK,SAAS,CAAA,wBAAA,EAA2B,KAAK,MAAM,CAAA,CAClH,EACF,CAEA,iBAAA,EAA6B,CAC3B,OAAO,IAAA,CAAK,OACd,CAEA,iBAAA,EAAiC,CAC/B,OAAO,CACL,eAAgB,kBAClB,CACF,CAEA,gBAA+B,EAAA,CAC7B,OAAO,CACL,KAAO,CAAA,IAAA,CAAK,SACd,CACF,CAGA,cAAc4C,CAAyE,CAAA,CACrF,OAAO,CAAE,WAAA,CAAa,GAAO,OAAS,CAAA,CAAE,CAC1C,CAGA,aAAA,CAAc2G,EAAyC,CACrD,OAAOA,EAAS,QAAS,CAAA,MAAA,CAAO,CAAC7J,CAAAA,CAAKsD,CAAYtD,GAAAA,CAAAA,CAAMsD,EAAQ,MAAQ,CAAA,CAAC,CAC3E,CAEA,qBAAA,CAAsBA,EAIpB,CACA,IAAMC,EAAcmG,EAAuB,CAAA,SAAA,CAAUpG,CAAO,CAC5D,CAAA,GAAI,CAACC,CAAY,CAAA,OAAA,CACf,MAAM,IAAIC,wBAAAA,CAAyB,CAAE,IAAA,CAAM,uBAAyB,CAAA,KAAA,CAAOD,EAAY,KAAM,CAAC,EAGhG,IAAME,CAAAA,CAAgBF,EAAY,IAE5BpD,CAAAA,CAAAA,CAAYsD,CAAc,CAAA,KAAA,CAE1BI,CAAU,CAAA,CACd,qBAAsBJ,CAAc,CAAA,oBACtC,EACMK,CAASC,CAAAA,MAAAA,GAAS,KAAMC,CAAAA,sBAAAA,CAAuBH,CAAO,CAAC,CAEvDiG,CAAAA,CAAAA,CAA2C,CAC/C,QAAUR,CAAAA,4BAAAA,CACV,SAAU7F,CAAc,CAAA,QAAA,CAAS,OAAO,CAACzD,CAAAA,CAAKsD,KAC5CtD,CAAI,CAAA,IAAA,CAAK,GAAGsD,CAAQ,CAAA,OAAA,CAAQ,MAAM,GAAK,CAAA,CAAA,EAAM,EAAE,IAAI,CAAC,CAC7CtD,CAAAA,CAAAA,CAAAA,CACN,EAAc,CACnB,CAEA,CAAA,OAAO,CACL,SAAAG,CAAAA,CAAAA,CACA,OAAA2D,CACA,CAAA,iBAAA,CAAAgG,CACF,CACF,CAGA,eAAA,CAAgBhG,EAAoB+F,CAA8C,CAAA,CAChF,IAAMlF,CAAgB,CAAA,IAAA,CAAK,YAAY,MAAO,CAAA,MAAA,CAAO,SAAUb,CAAAA,CAAM,CACrE,CAAA,GAAI,CAACa,CAAc,CAAA,OAAA,CACjB,MAAM,IAAIC,kBAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAOD,CAAc,CAAA,KACvB,CAAC,CAGH,CAAA,IAAME,EAAeF,CAAc,CAAA,IAAA,CACnC,OAAO,MAAA,CAAA,IAAA,CAAKE,CAA0B,CAAA,CAAE,QAAS5E,CAAQ,EAAA,CACvD,GAAI,CAAC,IAAA,CAAK,YAAY,MAAO,CAAA,GAAA,CAAIA,CAAG,CAAA,CAClC,MAAM,IAAI2E,mBAAmB,CAC3B,IAAA,CAAM,+BAA+B,IAAK,CAAA,SAAS,IACnD,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,sBAAA,EAAyB3E,CAAG,CAAA;AAAA,8BACvB,EAAA,MAAA,CAAO,KAAK,IAAK,CAAA,WAAA,CAAY,OAAO,GAAG,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC9E,CAAC,CAEL,CAAC,CAAA,CAEyB,OAAO,IAAK4E,CAAAA,CAAY,CAAE,CAAA,MAAA,CAAO,CAAC7E,CAAAA,CAAKC,IAAQ,CAEvE,IAAM+E,EADM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAI/E,CAAAA,CAAG,EACtB,KACfgF,CAAAA,CAAAA,CAAaJ,EAAa5E,CAAG,CAAA,CACnC,OAAAD,CAAIgF,CAAAA,CAAQ,EAAIC,CACTjF,CAAAA,CACT,CAAG,CAAA,EAAgB,CAGrB,CAEA,0BAA2B6J,CAAAA,CAAAA,CAA6C,CACtE,IAAME,CAAAA,CAAkBC,mBAAoB,CAAA,SAAA,CAAUH,CAAQ,CAC9D,CAAA,GAAI,CAACE,CAAgB,CAAA,OAAA,CACnB,MAAM,IAAIE,6BAAAA,CAA8B,CAAE,IAAM,CAAA,4BAAA,CAA8B,KAAOF,CAAAA,CAAAA,CAAgB,KAAM,CAAC,EAG9G,GAAIF,CAAAA,CAAS,WAAaP,4BACxB,CAAA,MAAM,IAAIW,6BAA8B,CAAA,CACtC,KAAM,CAA2C,wCAAA,EAAA,IAAA,CAAK,SAAS,CAC/D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,MAAA,EAASX,4BAA4B,CAAwC,qCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAG,CACjH,CAAC,EAUH,OAAO,CACL,SARmDS,CAAgB,CAAA,IAAA,CAAK,SAAS,GAAKzG,CAAAA,CAAAA,GAC/E,CACL,KAAO,CAAA,CAAA,OAAA,EAAU,KAAK,SAAS,CAAA,CAAA,CAC/B,QAAS,CAAE,KAAA,CAAO,CAAC,CAAE,IAAA,CAAMA,CAAkB,CAAC,CAAE,CAClD,EACD,CAID,CACF,CAGM,mBAAoBQ,CAAAA,CAAAA,CAAqB+F,EAAoD,CAAA1D,OAAAA,CAAAA,CAAA,sBACjG,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,EAAQ,IAAK,CAAA,gBAAgB,EAC/B,CAAC,CACH,CAGM,CAAA,CAAA,uBAAA,CAAwBtC,CAAqB+F,CAAAA,CAAAA,CAAwD,QAAA1D,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CACzG,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9BA,CAAAA,CAAQ,KAAK,iBAAkB,EAAC,EAClC,CAAC,CACH,GAEM,oBAAqBtC,CAAAA,CAAAA,CAAoB+F,EAAsD,CAAA1D,OAAAA,CAAAA,CAAA,IACnG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9B,IAAMvC,EAAU,IAAK,CAAA,eAAA,CAAgBC,CAAM,CACrCoG,CAAAA,CAAAA,CAAY,IAAK,CAAA,0BAAA,CAA2BL,CAAQ,CAAA,CAE1D,GAAIA,CAAS,CAAA,QAAA,CAAS,SAAW,CAC/B,CAAA,MAAM,IAAII,6BAA8B,CAAA,CACtC,IAAM,CAAA,CAAA,wCAAA,EAA2C,IAAK,CAAA,SAAS,IAC/D,KAAO,CAAA,IAAI,MAAM,0BAA0B,CAC7C,CAAC,CAGCpG,CAAAA,CAAAA,CAAQ,uBACTqG,CAAkB,CAAA,QAAA,CAAS,QAAS5G,CAAiB,EAAA,CACpDA,EAAQ,oBAAuBO,CAAAA,CAAAA,CAAQ,qBACzC,CAAC,CAAA,CACD,OAAOA,CAAAA,CAAQ,oBAGjBuC,CAAAA,CAAAA,CAAAA,CAAQrK,MAAA,EACH,CAAA,IAAA,CAAK,kBACL8H,CAAAA,CAAAA,CAAAA,CAAAA,CACAqG,EACJ,EACH,CAAC,CACH,CAEA,CAAA,CAAA,8BAAA,CAA+B3D,EAAsC,CACnE,IAAMC,EAAOgD,EAA4B,CAAA,SAAA,CAAUjD,CAAQ,CAC3D,CAAA,GAAIC,CAAK,CAAA,OAAA,CAAS,CAEhB,IAAM2D,EADiB3D,CAAK,CAAA,IAAA,CACM,WAAW,GAAI,CAAA,CAAC4D,EAAW9F,CACpD,IAAA,CACL,MAAAA,CACA,CAAA,SAAA,CAAW8F,EAAU,MACvB,CAAA,CACD,EAED,OAAO,CACL,eAAgBC,qBAChB,CAAA,UAAA,CAAYF,CACd,CACF,CAEA,MAAM,IAAI1D,kBAAmB,CAAA,CAAE,KAAM,6BAA+B,CAAA,KAAA,CAAOD,EAAK,KAAM,CAAC,CACzF,CACF,EClOMhH,IAAAA,EAAAA,CAA4B,qBAC5B8K,EAAiC,CAAA,oBAAA,CAEjC3K,EAA2B4K,CAAAA,oBAAAA,CAAqBhB,EAAkC,CAAA,CAAE,MAAM,CAC9F,IAAA,CAAM/J,GACN,WAAa8K,CAAAA,EAAAA,CACb,WAAYjB,EACZ,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,GAAA,CACjB,OAAQ,CACN,GAAA,CAAK5M,EAA4B,IAAK,CAAA,GAAG,EAAE,GAC3C,CAAA,MAAA,CAAQA,CAA4B,CAAA,IAAA,CAAK,GAAG,CAAA,CAAE,MAChD,CACF,CAAC,EAEKiD,EAA4BiK,CAAAA,CAAAA,CAG5BlK,GAAN,cAAiCmK,CAAmB,CAClD,WAAY1J,CAAAA,CAAAA,CAAwC,CAClD,KAAMP,CAAAA,EAAAA,CAA0BO,CAAO,EACzC,CACF,ECtBMN,IAAAA,EAAAA,CAA4B,qBAC5B4K,EAAiC,CAAA,oBAAA,CAEjCzK,GAA2BwK,oBAAqBhB,CAAAA,EAAkC,EAAE,KAAM,CAAA,CAC9F,KAAM3J,EACN,CAAA,WAAA,CAAa4K,GACb,UAAYnB,CAAAA,EAAAA,CACZ,eAAgB,IAChB,CAAA,eAAA,CAAiB,IACjB,MAAQ,CAAA,CACN,GAAK5M,CAAAA,CAAAA,CAA4B,IAAK,CAAA,GAAG,EAAE,GAC3C,CAAA,MAAA,CAAQA,EAA4B,IAAK,CAAA,GAAG,EAAE,MAChD,CACF,CAAC,CAAA,CAEKqD,EAA4B6J,CAAAA,CAAAA,CAG5B9J,GAAN,cAAiC+J,CAAmB,CAClD,WAAY1J,CAAAA,CAAAA,CAAwC,CAClD,KAAMH,CAAAA,EAAAA,CAA0BG,CAAO,EACzC,CACF","file":"index.mjs","sourcesContent":["import { z } from \"zod\";\n\nimport {\n  CHAT_CONFIG,\n  MultiStringConfigItem,\n  ObjectSchemaConfigItem,\n  RangeConfigItem,\n  SelectBooleanConfigItem,\n  SelectStringConfigItem,\n} from \"@adaline/provider\";\n\nconst temperature = (max: number, _default: number) =>\n  RangeConfigItem({\n    param: \"temperature\",\n    title: CHAT_CONFIG.TEMPERATURE.title,\n    description: CHAT_CONFIG.TEMPERATURE.description,\n    min: 0.0,\n    max: max,\n    step: 0.01,\n    default: _default,\n  });\n\nconst maxTokens = (maxOutputTokens: number) =>\n  RangeConfigItem({\n    param: \"maxOutputTokens\",\n    title: CHAT_CONFIG.MAX_TOKENS.title,\n    description: CHAT_CONFIG.MAX_TOKENS.description,\n    min: 0,\n    max: maxOutputTokens,\n    step: 1,\n    default: 0,\n  });\n\nconst stop = (maxSequences: number) =>\n  MultiStringConfigItem({\n    param: \"stopSequences\",\n    title: CHAT_CONFIG.STOP(maxSequences).title,\n    description: CHAT_CONFIG.STOP(maxSequences).description,\n    max: maxSequences,\n  });\n\nconst topP = (_default: number) =>\n  RangeConfigItem({\n    param: \"topP\",\n    title: CHAT_CONFIG.TOP_P.title,\n    description: CHAT_CONFIG.TOP_P.description,\n    min: 0,\n    max: 1,\n    step: 0.01,\n    default: _default,\n  });\n\nconst topK = (_default: number) =>\n  RangeConfigItem({\n    param: \"topK\",\n    title: CHAT_CONFIG.TOP_K.title,\n    description: CHAT_CONFIG.TOP_K.description,\n    min: 1,\n    max: 40,\n    step: 1,\n    default: _default,\n  });\n\nconst frequencyPenalty = RangeConfigItem({\n  param: \"frequencyPenalty\",\n  title: CHAT_CONFIG.FREQUENCY_PENALTY.title,\n  description: CHAT_CONFIG.FREQUENCY_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst presencePenalty = RangeConfigItem({\n  param: \"presencePenalty\",\n  title: CHAT_CONFIG.PRESENCE_PENALTY.title,\n  description: CHAT_CONFIG.PRESENCE_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst seed = RangeConfigItem({\n  param: \"seed\",\n  title: CHAT_CONFIG.SEED.title,\n  description: CHAT_CONFIG.SEED.description,\n  min: 0,\n  max: 1000000,\n  step: 1,\n  default: 0,\n});\n\nconst toolChoice = SelectStringConfigItem({\n  param: \"toolChoice\",\n  title: \"Tool choice\",\n  description:\n    \"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.\",\n  default: \"auto\",\n  choices: [\"auto\", \"any\", \"none\"],\n});\n\nconst safetySettings = ObjectSchemaConfigItem({\n  param: \"safetySettings\",\n  title: \"Safety settings\",\n  description: \"The safety rating contains the category of harm and the harm probability level in that category for a piece of content.\",\n  objectSchema: z.array(\n    z.object({\n      threshold: z.enum([\n        \"HARM_BLOCK_THRESHOLD_UNSPECIFIED\",\n        \"BLOCK_LOW_AND_ABOVE\",\n        \"BLOCK_MEDIUM_AND_ABOVE\",\n        \"BLOCK_ONLY_HIGH\",\n        \"BLOCK_NONE\",\n        \"OFF\",\n      ]),\n      category: z.enum([\n        \"HARM_CATEGORY_UNSPECIFIED\",\n        \"HARM_CATEGORY_HARASSMENT\",\n        \"HARM_CATEGORY_HATE_SPEECH\",\n        \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"HARM_CATEGORY_CIVIC_INTEGRITY\",\n      ]),\n    })\n  ),\n});\n\nconst reasoningEnabled = SelectBooleanConfigItem({\n  param: \"reasoningEnabled\",\n  title: \"Reasoning Enabled\",\n  description:\n    \"Controls whether the model is allowed to think for a longer period of time before generating a response. This can be useful for complex tasks that require more time to think.\",\n  default: false,\n});\n\nexport { frequencyPenalty, maxTokens, presencePenalty, reasoningEnabled, safetySettings, seed, stop, temperature, toolChoice, topK, topP };\n","import { z } from \"zod\";\n\nimport { maxTokens, safetySettings, stop, temperature, toolChoice, topP } from \"./common.config.chat-model.google\";\n\nconst ChatModelBaseConfigSchema = (\n  maxTemperature: number,\n  defaultTemperature: number,\n  maxOutputTokens: number,\n  maxSequences: number,\n  defaultTopP: number\n) =>\n  z.object({\n    temperature: temperature(maxTemperature, defaultTemperature).schema,\n    maxTokens: maxTokens(maxOutputTokens).schema,\n    stop: stop(maxSequences).schema,\n    topP: topP(defaultTopP).schema,\n    toolChoice: toolChoice.schema,\n    safetySettings: safetySettings.schema,\n  });\n\nconst ChatModelBaseConfigDef = (\n  maxTemperature: number,\n  defaultTemperature: number,\n  maxOutputTokens: number,\n  maxSequences: number,\n  defaultTopP: number\n) =>\n  ({\n    temperature: temperature(maxTemperature, defaultTemperature).def,\n    maxTokens: maxTokens(maxOutputTokens).def,\n    stop: stop(maxSequences).def,\n    topP: topP(defaultTopP).def,\n    toolChoice: toolChoice.def,\n    safetySettings: safetySettings.def,\n  }) as const;\n\nexport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema };\n","import { CHAT_CONFIG, ObjectSchemaConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\nimport { ResponseSchema } from \"@adaline/types\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.google\";\n\nconst responseSchema = ObjectSchemaConfigItem({\n  param: \"response_schema\",\n  title: CHAT_CONFIG.RESPONSE_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_SCHEMA.description,\n  objectSchema: ResponseSchema,\n});\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,\n  default: \"text\",\n  choices: [\"text\", \"json_schema\"],\n});\n\nconst GoogleChatModelResponseSchemaConfigDef = (\n  maxTemperature: number,\n  defaultTemperature: number,\n  maxOutputTokens: number,\n  maxSequences: number,\n  defaultTopP: number\n) => ({\n  ...ChatModelBaseConfigDef(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n  responseFormat: responseFormat.def,\n  responseSchema: responseSchema.def,\n});\n\nconst GoogleChatModelResponseSchemaConfigSchema = (\n  maxTemperature: number,\n  defaultTemperature: number,\n  maxOutputTokens: number,\n  maxSequences: number,\n  defaultTopP: number\n) =>\n  ChatModelBaseConfigSchema(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP).extend({\n    responseFormat: responseFormat.schema,\n    responseSchema: responseSchema.schema,\n  });\n\nexport { GoogleChatModelResponseSchemaConfigDef, GoogleChatModelResponseSchemaConfigSchema };\n","import { reasoningEnabled } from \"./common.config.chat-model.google\";\n\nimport {\n  GoogleChatModelResponseSchemaConfigDef,\n  GoogleChatModelResponseSchemaConfigSchema,\n} from \"./response-schema.config.chat-model.google\";\n\nconst ChatModelReasoningConfigSchema = (\n  maxTemperature: number,\n  defaultTemperature: number,\n  maxOutputTokens: number,\n  maxSequences: number,\n  defaultTopP: number,\n) =>\n  GoogleChatModelResponseSchemaConfigSchema(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP).extend({\n    reasoningEnabled: reasoningEnabled.schema,\n  });\n\nconst ChatModelReasoningConfigDef = (\n  maxTemperature: number,\n  defaultTemperature: number,\n  maxOutputTokens: number,\n  maxSequences: number,\n  defaultTopP: number,\n) =>\n  ({\n    ...GoogleChatModelResponseSchemaConfigDef(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n    reasoningEnabled: reasoningEnabled.def,\n  });\n\nexport { ChatModelReasoningConfigDef, ChatModelReasoningConfigSchema };","import { z } from \"zod\";\n\nimport { dimensions } from \"./common.config.embedding-model.google\";\n\nconst EmbeddingModelBaseConfigSchema = (maxDimensions: number) =>\n  z.object({\n    dimensions: dimensions(maxDimensions).schema,\n  });\n\nconst EmbeddingModelBaseConfigDef = (maxDimensions: number) =>\n  ({\n    dimensions: dimensions(maxDimensions).def,\n  }) as const;\n\nexport { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema };\n","import { EMBEDDING_CONFIG, RangeConfigItem } from \"@adaline/provider\";\n\nconst dimensions = (maxDimensions: number) =>\n  RangeConfigItem({\n    param: \"outputDimensionality\",\n    title: EMBEDDING_CONFIG.DIMENSIONS.title,\n    description: EMBEDDING_CONFIG.DIMENSIONS.description,\n    min: 1,\n    max: maxDimensions,\n    step: 1,\n    default: maxDimensions,\n  });\n\nexport { dimensions };\n","import {\n  ChatModelBaseConfigDef,\n  ChatModelBaseConfigSchema,\n  ChatModelReasoningConfigDef,\n  ChatModelReasoningConfigSchema,\n  GoogleChatModelResponseSchemaConfigDef,\n  GoogleChatModelResponseSchemaConfigSchema,\n} from \"./chat-model\";\nimport { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema } from \"./embedding-model\";\n\nconst GoogleChatModelConfigs = {\n  base: (maxTemperature: number, defaultTemperature: number, maxOutputTokens: number, maxSequences: number, defaultTopP: number) => ({\n    def: ChatModelBaseConfigDef(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n    schema: ChatModelBaseConfigSchema(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n  }),\n  responseSchema: (maxTemperature: number, defaultTemperature: number, maxOutputTokens: number, maxSequences: number, defaultTopP: number) => ({\n    def: GoogleChatModelResponseSchemaConfigDef(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n    schema: GoogleChatModelResponseSchemaConfigSchema(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n  }),\n  reasoning: (\n    maxTemperature: number,\n    defaultTemperature: number,\n    maxOutputTokens: number,\n    maxSequences: number,\n    defaultTopP: number,\n  ) => ({\n    def: ChatModelReasoningConfigDef(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n    schema: ChatModelReasoningConfigSchema(maxTemperature, defaultTemperature, maxOutputTokens, maxSequences, defaultTopP),\n  }),\n} as const;\n\nconst GoogleEmbeddingModelConfigs = {\n  base: (maxDimensions: number) => ({\n    def: EmbeddingModelBaseConfigDef(maxDimensions),\n    schema: EmbeddingModelBaseConfigSchema(maxDimensions),\n  }),\n} as const;\n\nexport { GoogleChatModelConfigs, GoogleEmbeddingModelConfigs };\n","import { z } from \"zod\";\n\nimport { ChatModelSchemaType, ChatModelV1, EmbeddingModelSchemaType, EmbeddingModelV1, ProviderError, ProviderV1 } from \"@adaline/provider\";\n\nimport * as Models from \"../models\";\n\nconst ProviderLiteral = \"google\";\nclass Google<C extends Models.BaseChatModelOptionsType, E extends Models.BaseEmbeddingModelOptionsType> implements ProviderV1<C, E> {\n  readonly version = \"v1\" as const;\n  readonly name = ProviderLiteral;\n  static readonly baseUrl: string = \"https://generativelanguage.googleapis.com/v1beta\";\n\n  private readonly chatModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): ChatModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: ChatModelSchemaType;\n    }\n  > = {\n    [Models.Gemini1_5Flash001Literal]: {\n      model: Models.Gemini1_5Flash001,\n      modelOptions: Models.Gemini1_5Flash001Options,\n      modelSchema: Models.Gemini1_5Flash001Schema,\n    },\n    [Models.Gemini1_5Flash002Literal]: {\n      model: Models.Gemini1_5Flash002,\n      modelOptions: Models.Gemini1_5Flash002Options,\n      modelSchema: Models.Gemini1_5Flash002Schema,\n    },\n    [Models.Gemini1_5FlashLatestLiteral]: {\n      model: Models.Gemini1_5FlashLatest,\n      modelOptions: Models.Gemini1_5FlashLatestOptions,\n      modelSchema: Models.Gemini1_5FlashLatestSchema,\n    },\n    [Models.Gemini1_5FlashLiteral]: {\n      model: Models.Gemini1_5Flash,\n      modelOptions: Models.Gemini1_5FlashOptions,\n      modelSchema: Models.Gemini1_5FlashSchema,\n    },\n    [Models.Gemini1_5Pro001Literal]: {\n      model: Models.Gemini1_5Pro001,\n      modelOptions: Models.Gemini1_5Pro001Options,\n      modelSchema: Models.Gemini1_5Pro001Schema,\n    },\n    [Models.Gemini1_5Pro002Literal]: {\n      model: Models.Gemini1_5Pro002,\n      modelOptions: Models.Gemini1_5Pro002Options,\n      modelSchema: Models.Gemini1_5Pro002Schema,\n    },\n    [Models.Gemini1_5ProLatestLiteral]: {\n      model: Models.Gemini1_5ProLatest,\n      modelOptions: Models.Gemini1_5ProLatestOptions,\n      modelSchema: Models.Gemini1_5ProLatestSchema,\n    },\n    [Models.Gemini1_5ProLiteral]: {\n      model: Models.Gemini1_5Pro,\n      modelOptions: Models.Gemini1_5ProOptions,\n      modelSchema: Models.Gemini1_5ProSchema,\n    },\n    [Models.Gemini2_0FlashExpLiteral]: {\n      model: Models.Gemini2_0FlashExp,\n      modelOptions: Models.Gemini2_0FlashExpOptions,\n      modelSchema: Models.Gemini2_0FlashExpSchema,\n    },\n\n    [Models.Gemini2_5FlashPreview0417Literal]: {\n      model: Models.Gemini2_5FlashPreview0417,\n      modelOptions: Models.Gemini2_5FlashPreview0417Options,\n      modelSchema: Models.Gemini2_5FlashPreview0417Schema,\n    },\n    [Models.Gemini2_5ProPreview0325Literal]: {\n      model: Models.Gemini2_5ProPreview0325,\n      modelOptions: Models.Gemini2_5ProPreview0325Options,\n      modelSchema: Models.Gemini2_5ProPreview0325Schema,\n    },\n  };\n\n  private readonly embeddingModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): EmbeddingModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: EmbeddingModelSchemaType;\n    }\n  > = {\n    [Models.Text_Embedding_001Literal]: {\n      model: Models.Text_Embedding_001,\n      modelOptions: Models.Text_Embedding_001Options,\n      modelSchema: Models.Text_Embedding_001Schema,\n    },\n    [Models.Text_Embedding_004Literal]: {\n      model: Models.Text_Embedding_004,\n      modelOptions: Models.Text_Embedding_004Options,\n      modelSchema: Models.Text_Embedding_004Schema,\n    },\n  };\n\n  chatModelLiterals(): string[] {\n    return Object.keys(this.chatModelFactories);\n  }\n\n  chatModelSchemas(): Record<string, ChatModelSchemaType> {\n    return Object.keys(this.chatModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.chatModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, ChatModelSchemaType>\n    );\n  }\n\n  chatModel(options: C): ChatModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.chatModelFactories)) {\n      throw new ProviderError({\n        info: `Google chat model: ${modelName} not found`,\n        cause: new Error(`Google chat model: ${modelName} not found, available chat models: \n          [${this.chatModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.chatModelFactories[modelName].model;\n    const parsedOptions = this.chatModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n\n  embeddingModelLiterals(): string[] {\n    return Object.keys(this.embeddingModelFactories);\n  }\n\n  embeddingModelSchemas(): Record<string, EmbeddingModelSchemaType> {\n    return Object.keys(this.embeddingModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.embeddingModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, EmbeddingModelSchemaType>\n    );\n  }\n\n  embeddingModel(options: E): EmbeddingModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.embeddingModelFactories)) {\n      throw new ProviderError({\n        info: `Google embedding model: ${modelName} not found`,\n        cause: new Error(`Google embedding model: ${modelName} not found, available embedding models: \n          [${this.embeddingModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.embeddingModelFactories[modelName].model;\n    const parsedOptions = this.embeddingModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n}\n\nexport { Google, ProviderLiteral };\n","{\n  \"base-gemini-1-chat-model\": {\n    \"modelName\": \"base-gemini-1-chat-model\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0,\n            \"outputPricePerMillion\": 0\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.0-pro-001\": {\n    \"modelName\": \"gemini-1.0-pro-001\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.0-pro-latest\": {\n    \"modelName\": \"gemini-1.0-pro-latest\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.0-pro-vision\": {\n    \"modelName\": \"gemini-1.0-pro-vision\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.0-pro\": {\n    \"modelName\": \"gemini-1.0-pro\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-flash-001\": {\n    \"modelName\": \"gemini-1.5-flash-001\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.075,\n            \"outputPricePerMillion\": 0.3\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.15,\n            \"outputPricePerMillion\": 0.6\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-flash-002\": {\n    \"modelName\": \"gemini-1.5-flash-002\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.0375,\n            \"outputPricePerMillion\": 0.15\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.075,\n            \"outputPricePerMillion\": 0.3\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-flash-latest\": {\n    \"modelName\": \"gemini-1.5-flash-latest\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.075,\n            \"outputPricePerMillion\": 0.3\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.15,\n            \"outputPricePerMillion\": 0.6\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-flash\": {\n    \"modelName\": \"gemini-1.5-flash\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.075,\n            \"outputPricePerMillion\": 0.3\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.15,\n            \"outputPricePerMillion\": 0.6\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-pro-001\": {\n    \"modelName\": \"gemini-1.5-pro-001\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.25,\n            \"outputPricePerMillion\": 5\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-pro-002\": {\n    \"modelName\": \"gemini-1.5-pro-002\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.25,\n            \"outputPricePerMillion\": 5\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-pro-latest\": {\n    \"modelName\": \"gemini-1.5-pro-latest\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.25,\n            \"outputPricePerMillion\": 5\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-1.5-pro\": {\n    \"modelName\": \"gemini-1.5-pro\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 128000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.25,\n            \"outputPricePerMillion\": 5\n          }\n        }\n      },\n      {\n        \"minTokens\": 128001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-2.0-flash-exp\": {\n    \"modelName\": \"gemini-2.0-flash-exp\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.1,\n            \"outputPricePerMillion\": 0.4\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-2.5-flash-preview-04-17\": {\n    \"modelName\": \"gemini-2.5-flash-preview-04-17\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.15,\n            \"outputPricePerMillion\": 0.6\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-2.5-pro-preview-03-25\": {\n    \"modelName\": \"gemini-2.5-pro-preview-03-25\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": 200000,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.25,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      },\n      {\n        \"minTokens\": 200001,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 15\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-pro-vision\": {\n    \"modelName\": \"gemini-pro-vision\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gemini-pro\": {\n    \"modelName\": \"gemini-pro\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  }\n}\n","import { z } from \"zod\";\n\nimport { AssistantRoleLiteral, SystemRoleLiteral, ToolRoleLiteral, UserRoleLiteral } from \"@adaline/types\";\n\nconst GoogleChatModelRoles = z.enum([SystemRoleLiteral, UserRoleLiteral, AssistantRoleLiteral, ToolRoleLiteral]);\n\nconst GoogleChatAssistantRoleLiteral = \"model\";\nconst GoogleChatToolRoleLiteral = \"function\";\n\nconst GoogleChatModelRolesMap = {\n  system: UserRoleLiteral,\n  user: UserRoleLiteral,\n  assistant: GoogleChatAssistantRoleLiteral,\n  tool: GoogleChatToolRoleLiteral,\n} as const;\n\nexport { GoogleChatAssistantRoleLiteral, GoogleChatToolRoleLiteral, GoogleChatModelRoles, GoogleChatModelRolesMap };\n","import { z } from \"zod\";\n\nimport { ChatModelSchemaType } from \"@adaline/provider\";\nimport { ImageModalityLiteral, TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral } from \"@adaline/types\";\n\nconst GoogleChatModelModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst GoogleChatModelModalitiesEnum = z.enum([\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n]);\n\nconst GoogleChatModelTextModalities: ChatModelSchemaType[\"modalities\"] = [TextModalityLiteral];\n\nconst GoogleChatModelTextModalitiesEnum = z.enum([TextModalityLiteral]);\n\nconst GoogleChatModelTextVisionModalities: ChatModelSchemaType[\"modalities\"] = [TextModalityLiteral, ImageModalityLiteral];\n\nconst GoogleChatModelTextVisionModalitiesEnum = z.enum([TextModalityLiteral, ImageModalityLiteral]);\n\nconst GoogleChatModelTextToolModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst GoogleChatModelTextToolModalitiesEnum = z.enum([TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral]);\n\nexport {\n  GoogleChatModelModalitiesEnum,\n  GoogleChatModelModalities,\n  GoogleChatModelTextModalitiesEnum,\n  GoogleChatModelTextModalities,\n  GoogleChatModelTextToolModalitiesEnum,\n  GoogleChatModelTextToolModalities,\n  GoogleChatModelTextVisionModalitiesEnum,\n  GoogleChatModelTextVisionModalities,\n};\n","import { z } from \"zod\";\n\nconst GoogleCompleteChatTextResponse = z.object({\n  text: z.string(),\n});\n\nconst GoogleCompleteChatToolResponse = z.object({\n  functionCall: z.object({\n    name: z.string(),\n    args: z.record(z.any()),\n  }),\n});\n\nconst GoogleCompleteChatResponse = z.object({\n  candidates: z.array(\n    z.object({\n      content: z\n        .object({\n          role: z.string(),\n          parts: z.array(z.union([GoogleCompleteChatTextResponse, GoogleCompleteChatToolResponse])),\n        })\n        .optional(),\n      finishReason: z.string(),\n      index: z.number().optional(),\n      safetyRatings: z.optional(\n        z.array(\n          z.object({\n            category: z.string(),\n            probability: z.string(),\n            blocked: z.boolean().optional(),\n          })\n        )\n      ),\n    })\n  ),\n  promptFeedback: z.optional(\n    z.object({\n      safetyRatings: z.optional(\n        z.array(\n          z.object({\n            category: z.string(),\n            probability: z.string(),\n          })\n        )\n      ),\n    })\n  ),\n  usageMetadata: z\n    .object({\n      promptTokenCount: z.number(),\n      cachedContentTokenCount: z.number().optional(),\n      candidatesTokenCount: z.number().optional(),\n      totalTokenCount: z.number(),\n    })\n    .optional(),\n});\ntype GoogleCompleteChatResponseType = z.infer<typeof GoogleCompleteChatResponse>;\n\nconst GoogleStreamChatTextResponse = z.object({\n  text: z.string(),\n});\n\nconst GoogleStreamChatToolResponse = z.object({\n  functionCall: z.object({\n    name: z.string(),\n    args: z.record(z.any()),\n  }),\n});\n\nconst GoogleStreamChatResponse = z.object({\n  candidates: z.array(\n    z.object({\n      content: z\n        .object({\n          role: z.string(),\n          parts: z.array(z.union([GoogleStreamChatTextResponse, GoogleStreamChatToolResponse])),\n        })\n        .optional(),\n      finishReason: z.string().optional(),\n      index: z.number().optional(),\n      safetyRatings: z.optional(\n        z.array(\n          z.object({\n            category: z.string(),\n            probability: z.string(),\n            blocked: z.boolean().optional(),\n          })\n        )\n      ),\n    })\n  ),\n  promptFeedback: z.optional(\n    z.object({\n      safetyRatings: z.optional(\n        z.array(\n          z.object({\n            category: z.string(),\n            probability: z.string(),\n          })\n        )\n      ),\n    })\n  ),\n  usageMetadata: z\n    .object({\n      promptTokenCount: z.number().optional(),\n      cachedContentTokenCount: z.number().optional(),\n      candidatesTokenCount: z.number().optional(),\n      totalTokenCount: z.number().optional(),\n    })\n    .optional(),\n});\ntype GoogleStreamChatResponseType = z.infer<typeof GoogleStreamChatResponse>;\n\nexport {\n  GoogleCompleteChatResponse,\n  GoogleCompleteChatTextResponse,\n  GoogleCompleteChatToolResponse,\n  GoogleStreamChatResponse,\n  GoogleStreamChatTextResponse,\n  GoogleStreamChatToolResponse,\n  type GoogleCompleteChatResponseType,\n  type GoogleStreamChatResponseType,\n};\n","import { z } from \"zod\";\n\nconst GoogleChatContentPartText = z.object({\n  text: z.string().min(1),\n});\ntype GoogleChatContentPartTextType = z.infer<typeof GoogleChatContentPartText>;\n\nconst GoogleChatContentPartInlineData = z.object({\n  inline_data: z.object({\n    mime_type: z.string().min(1),\n    data: z.string().base64(),\n  }),\n});\ntype GoogleChatContentPartInlineDataType = z.infer<typeof GoogleChatContentPartInlineData>;\n\nconst GoogleChatContentPartFunctionCall = z.object({\n  function_call: z.object({\n    name: z.string().min(1),\n    args: z.record(z.string().min(1)),\n  }),\n});\ntype GoogleChatContentPartFunctionCallType = z.infer<typeof GoogleChatContentPartFunctionCall>;\n\nconst GoogleChatContentPartFunctionResponse = z.object({\n  function_response: z.object({\n    name: z.string().min(1),\n    response: z.record(z.string().min(1)),\n  }),\n});\ntype GoogleChatContentPartFunctionResponseType = z.infer<typeof GoogleChatContentPartFunctionResponse>;\n\nconst GoogleChatContent = z.object({\n  role: z.enum([\"user\", \"model\", \"function\"]),\n  parts: z.array(\n    z.union([\n      GoogleChatContentPartText,\n      GoogleChatContentPartInlineData,\n      GoogleChatContentPartFunctionCall,\n      GoogleChatContentPartFunctionResponse,\n    ])\n  ),\n});\ntype GoogleChatContentType = z.infer<typeof GoogleChatContent>;\n\nconst GoogleChatSystemInstruction = z.object({\n  parts: z.array(GoogleChatContentPartText),\n});\ntype GoogleChatSystemInstructionType = z.infer<typeof GoogleChatSystemInstruction>;\n\nconst GoogleChatTool = z.object({\n  name: z.string().min(1),\n  description: z.string().min(1),\n  parameters: z.any(),\n});\ntype GoogleChatToolType = z.infer<typeof GoogleChatTool>;\n\nconst GoogleChatToolConfig = z.object({\n  function_calling_config: z.object({\n    mode: z.enum([\"ANY\", \"AUTO\", \"NONE\"]),\n    allowed_function_names: z.array(z.string()).optional(),\n  }),\n});\ntype GoogleChatToolConfigType = z.infer<typeof GoogleChatToolConfig>;\n\nconst GoogleChatGenerationConfig = z.object({\n  stopSequences: z.array(z.string()).optional(),\n  maxOutputTokens: z.number().optional(),\n  temperature: z.number().optional(),\n  topP: z.number().optional(),\n  topK: z.number().optional(),\n  presencePenalty: z.number().optional(),\n  frequencyPenalty: z.number().optional(),\n  seed: z.number().optional(),\n});\ntype GoogleChatGenerationConfigType = z.infer<typeof GoogleChatGenerationConfig>;\n\nconst GoogleChatSafetySettings = z.object({\n  category: z.enum([\n    \"HARM_CATEGORY_HARASSMENT\",\n    \"HARM_CATEGORY_HATE_SPEECH\",\n    \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n    \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n    \"HARM_CATEGORY_CIVIC_INTEGRITY\",\n  ]),\n  threshold: z.enum([\n    \"HARM_BLOCK_THRESHOLD_UNSPECIFIED\",\n    \"BLOCK_LOW_AND_ABOVE\",\n    \"BLOCK_MEDIUM_AND_ABOVE\",\n    \"BLOCK_ONLY_HIGH\",\n    \"BLOCK_NONE\",\n    \"OFF\",\n  ]),\n});\ntype GoogleChatSafetySettingsType = z.infer<typeof GoogleChatSafetySettings>;\n\nconst GoogleChatRequest = z.object({\n  model: z.string().min(1).optional(),\n  contents: z.array(GoogleChatContent),\n  systemInstruction: GoogleChatSystemInstruction.optional(),\n  system_instruction: GoogleChatSystemInstruction.optional(),\n  generationConfig: GoogleChatGenerationConfig.optional(),\n  generation_config: GoogleChatGenerationConfig.optional(),\n  safetySettings: z.array(GoogleChatSafetySettings).optional(),\n  safety_settings: z.array(GoogleChatSafetySettings).optional(),\n  tools: z\n    .object({\n      function_declarations: z.array(GoogleChatTool),\n    })\n    .optional(),\n  toolConfig: GoogleChatToolConfig.optional(),\n  tool_config: GoogleChatToolConfig.optional(),\n});\ntype GoogleChatRequestType = z.infer<typeof GoogleChatRequest>;\n\nexport {\n  GoogleChatContent,\n  GoogleChatContentPartFunctionCall,\n  GoogleChatContentPartFunctionResponse,\n  GoogleChatContentPartInlineData,\n  GoogleChatContentPartText,\n  GoogleChatGenerationConfig,\n  GoogleChatRequest,\n  GoogleChatSystemInstruction,\n  GoogleChatTool,\n  GoogleChatToolConfig,\n  GoogleChatSafetySettings,\n  type GoogleChatContentPartTextType,\n  type GoogleChatContentPartFunctionCallType,\n  type GoogleChatContentPartFunctionResponseType,\n  type GoogleChatContentPartInlineDataType,\n  type GoogleChatToolType,\n  type GoogleChatToolConfigType,\n  type GoogleChatGenerationConfigType,\n  type GoogleChatRequestType,\n  type GoogleChatContentType,\n  type GoogleChatSystemInstructionType,\n  type GoogleChatSafetySettingsType,\n};\n","import { z } from \"zod\";\n\nimport {\n  ChatModelSchemaType,\n  ChatModelV1,\n  HeadersType,\n  InvalidConfigError,\n  InvalidMessagesError,\n  InvalidModelRequestError,\n  InvalidToolsError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  SelectStringConfigItemDefType,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\nimport {\n  AssistantRoleLiteral,\n  Base64ImageContentTypeLiteral,\n  Base64ImageContentValueType,\n  ChatModelPriceType,\n  ChatResponseType,\n  ChatUsageType,\n  Config,\n  ConfigType,\n  ContentType,\n  createPartialTextMessage,\n  createPartialToolCallMessage,\n  createTextContent,\n  createToolCallContent,\n  ImageContentType,\n  ImageModalityLiteral,\n  Message,\n  MessageType,\n  PartialChatResponseType,\n  ResponseSchemaType,\n  SystemRoleLiteral,\n  TextModalityLiteral,\n  Tool,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n  ToolRoleLiteral,\n  ToolType,\n  UserRoleLiteral,\n} from \"@adaline/types\";\n\nimport { Google } from \"../../provider/provider.google\";\nimport pricingData from \"../pricing.json\";\nimport {\n  GoogleChatContentPartFunctionCallType,\n  GoogleChatContentPartFunctionResponseType,\n  GoogleChatContentPartInlineDataType,\n  GoogleChatContentPartTextType,\n  GoogleChatContentType,\n  GoogleChatRequest,\n  GoogleChatRequestType,\n  GoogleChatSystemInstructionType,\n  GoogleChatToolType,\n  GoogleCompleteChatResponse,\n  GoogleCompleteChatResponseType,\n  GoogleStreamChatResponse,\n  GoogleStreamChatResponseType,\n} from \"./types\";\n\nconst BaseChatModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  completeChatUrl: z.string().url().optional(),\n  streamChatUrl: z.string().url().optional(),\n});\ntype BaseChatModelOptionsType = z.infer<typeof BaseChatModelOptions>;\n\nclass BaseChatModel implements ChatModelV1<ChatModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: ChatModelSchemaType;\n  readonly modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly streamChatUrl: string;\n  private readonly completeChatUrl: string;\n\n  constructor(modelSchema: ChatModelSchemaType, options: BaseChatModelOptionsType) {\n    const parsedOptions = BaseChatModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl ?? Google.baseUrl);\n    this.completeChatUrl = urlWithoutTrailingSlash(\n      parsedOptions.completeChatUrl || `${this.baseUrl}/models/${this.modelName}:generateContent?key=${this.apiKey}`\n    );\n    this.streamChatUrl = urlWithoutTrailingSlash(\n      parsedOptions.streamChatUrl || `${this.baseUrl}/models/${this.modelName}:streamGenerateContent?key=${this.apiKey}`\n    );\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      \"Content-Type\": \"application/json\",\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {};\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    return { shouldRetry: false, delayMs: 0 };\n  }\n\n  // TODO: unused method, not tested; should add support for non-text modalities, tools\n  getTokenCount(messages: MessageType[]): number {\n    return messages.reduce((acc, message) => {\n      return acc + message.content.map((content) => (content.modality === \"text\" ? content.value : \"\")).join(\" \").length;\n    }, 0);\n  }\n\n  transformModelRequest(request: GoogleChatRequestType): {\n    modelName: string | undefined;\n    config: ConfigType;\n    messages: MessageType[];\n    tools: ToolType[] | undefined;\n  } {\n    const safeRequest = GoogleChatRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    if (parsedRequest.system_instruction && parsedRequest.systemInstruction) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'system_instruction' and 'systemInstruction' are not allowed at the same time\"),\n      });\n    }\n\n    if (parsedRequest.generation_config && parsedRequest.generationConfig) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'generation_config' and 'generationConfig' are not allowed at the same time\"),\n      });\n    }\n\n    if (parsedRequest.tool_config && parsedRequest.toolConfig) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'tool_config' and 'toolConfig' are not allowed at the same time\"),\n      });\n    }\n\n    const systemInstruction = parsedRequest.system_instruction || parsedRequest.systemInstruction;\n    const generationConfig = parsedRequest.generation_config || parsedRequest.generationConfig;\n    const safetySettings = parsedRequest.safety_settings || parsedRequest.safetySettings;\n    const toolConfig = parsedRequest.tool_config || parsedRequest.toolConfig;\n\n    if (toolConfig && (!parsedRequest.tools || parsedRequest.tools.function_declarations.length === 0)) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'tools' are required when 'tool_choice' is specified\"),\n      });\n    }\n\n    const _config: ConfigType = {};\n\n    if (toolConfig) {\n      if (toolConfig.function_calling_config.mode === \"ANY\") {\n        if (\n          toolConfig.function_calling_config.allowed_function_names &&\n          toolConfig.function_calling_config.allowed_function_names.length === 1\n        ) {\n          _config.toolChoice = toolConfig.function_calling_config.allowed_function_names[0];\n        } else {\n          _config.toolChoice = toolConfig.function_calling_config.mode.toLowerCase();\n        }\n      } else {\n        _config.toolChoice = toolConfig.function_calling_config.mode.toLowerCase();\n      }\n    }\n\n    _config.seed = generationConfig?.seed;\n    _config.maxTokens = generationConfig?.maxOutputTokens;\n    _config.temperature = generationConfig?.temperature;\n    _config.topP = generationConfig?.topP;\n    _config.presencePenalty = generationConfig?.presencePenalty;\n    _config.frequencyPenalty = generationConfig?.frequencyPenalty;\n    _config.stop = generationConfig?.stopSequences;\n    _config.safetySettings = safetySettings;\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    const messages: MessageType[] = [];\n    if (systemInstruction) {\n      systemInstruction.parts.forEach((part) => {\n        messages.push({ role: SystemRoleLiteral, content: [{ modality: TextModalityLiteral, value: part.text }] });\n      });\n    }\n\n    parsedRequest.contents.forEach((message) => {\n      const role = message.role;\n      switch (role) {\n        case \"user\":\n          {\n            const content = message.parts as (GoogleChatContentPartTextType | GoogleChatContentPartInlineDataType)[];\n            const _content = content.map((c) => {\n              if (\"text\" in c) {\n                return { modality: TextModalityLiteral, value: c.text };\n              } else {\n                return {\n                  modality: ImageModalityLiteral,\n                  detail: \"auto\" as ImageContentType[\"detail\"],\n                  value: {\n                    type: Base64ImageContentTypeLiteral,\n                    base64: c.inline_data.data,\n                    mediaType: c.inline_data.mime_type.split(\"/\")[1] as Base64ImageContentValueType[\"mediaType\"],\n                  },\n                };\n              }\n            });\n            messages.push({ role: role, content: _content });\n          }\n          break;\n\n        case \"model\":\n          {\n            const content = message.parts as (GoogleChatContentPartTextType | GoogleChatContentPartFunctionCallType)[];\n            const _content = content.map((c, index) => {\n              if (\"text\" in c) {\n                return { modality: TextModalityLiteral, value: c.text };\n              } else {\n                return {\n                  modality: ToolCallModalityLiteral,\n                  id: index.toString(),\n                  index: index,\n                  name: c.function_call.name,\n                  arguments: JSON.stringify(c.function_call.args),\n                };\n              }\n            });\n            messages.push({ role: AssistantRoleLiteral, content: _content });\n          }\n          break;\n\n        case \"function\":\n          {\n            const content = message.parts as GoogleChatContentPartFunctionResponseType[];\n            const _content = content.map((c, index) => {\n              return {\n                modality: ToolResponseModalityLiteral,\n                id: index.toString(),\n                index: index,\n                name: c.function_response.name,\n                data: JSON.stringify(c.function_response.response),\n              };\n            });\n            messages.push({ role: ToolRoleLiteral, content: _content });\n          }\n          break;\n\n        default: {\n          throw new InvalidMessagesError({\n            info: `Invalid message 'role' for model : ${this.modelName}`,\n            cause: new Error(`role : '${message.role}' is not supported for model : ${this.modelName}`),\n          });\n        }\n      }\n    });\n\n    const tools: ToolType[] = [];\n    if (parsedRequest.tools) {\n      parsedRequest.tools.function_declarations.forEach((tool: GoogleChatToolType) => {\n        tools.push({\n          type: \"function\",\n          definition: {\n            schema: {\n              name: tool.name,\n              description: tool.description,\n              parameters: tool.parameters,\n            },\n          },\n        });\n      });\n    }\n\n    return {\n      modelName,\n      config,\n      messages,\n      tools: tools.length > 0 ? tools : undefined,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, messages?: MessageType[], tools?: ToolType[]): ParamsType {\n    const _toolChoice = config.toolChoice;\n    delete config.toolChoice; // can have a specific tool name that is not in the model schema, validated at transformation\n\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n\n    Object.keys(parsedConfig).forEach((key) => {\n      if (!(key in this.modelSchema.config.def)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = (parsedConfig as ConfigType)[key];\n\n      if (key === \"reasoningEnabled\") {\n        // Handle reasoningEnabled specially\n        acc.thinkingConfig = {\n          includeThoughts: paramValue,\n        };\n      } else if (key === \"maxReasoningTokens\") {\n        acc.thinkingConfig =\n          acc.thinkingConfig && typeof acc.thinkingConfig === \"object\"\n            ? { ...acc.thinkingConfig, thinkingBudget: paramValue }\n            : { thinkingBudget: paramValue };\n      } else if (paramKey === \"maxOutputTokens\" && def.type === \"range\" && paramValue === 0) {\n        acc[paramKey] = def.max;\n      } else {\n        acc[paramKey] = paramValue;\n      }\n\n      return acc;\n    }, {} as ParamsType);\n\n    const safetySettings = transformedConfig.safetySettings;\n    delete transformedConfig.safetySettings;\n\n    let toolConfig;\n    if (_toolChoice !== undefined) {\n      const toolChoice = _toolChoice as string;\n      if (!tools || (tools && tools.length === 0)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(\"'tools' are required when 'toolChoice' is specified\"),\n        });\n      } else if (tools && tools.length > 0) {\n        const configToolChoice = this.modelSchema.config.def.toolChoice as SelectStringConfigItemDefType;\n        if (!configToolChoice.choices.includes(toolChoice)) {\n          // toolChoice not in model schema choices\n          if (tools.map((tool) => tool.definition.schema.name).includes(toolChoice)) {\n            // toolChoice is a specific tool name\n            toolConfig = {\n              function_calling_config: {\n                mode: \"ANY\",\n                allowed_function_names: [toolChoice],\n              },\n            };\n          } else {\n            throw new InvalidConfigError({\n              info: `Invalid config for model : '${this.modelName}'`,\n              cause: new Error(`toolChoice : '${toolChoice}' is not part of provided 'tools' names or \n                one of [${configToolChoice.choices.join(\", \")}]`),\n            });\n          }\n        } else {\n          // toolChoice is in model schema choices\n          if (toolChoice === \"any\") {\n            toolConfig = {\n              function_calling_config: {\n                mode: \"ANY\",\n                allowed_function_names: tools.map((tool) => tool.definition.schema.name),\n              },\n            };\n          } else {\n            toolConfig = {\n              function_calling_config: {\n                mode: toolChoice.toUpperCase(), // Google uses uppercase for toolChoice\n              },\n            };\n          }\n        }\n      }\n    }\n\n    if (\"response_format\" in transformedConfig && transformedConfig.response_format !== undefined) {\n      const responseFormat = transformedConfig.response_format as string;\n      if (responseFormat === \"json_schema\") {\n        const responseSchemaConfig = transformedConfig.response_schema as ResponseSchemaType;\n        if (!(\"response_schema\" in transformedConfig) || !transformedConfig.response_schema || !responseSchemaConfig?.schema) {\n          throw new InvalidConfigError({\n            info: `Invalid config for model : '${this.modelName}'`,\n            cause: new Error(\"'responseSchema' is required in config when 'responseFormat' is 'json_schema'\"),\n          });\n        } else {\n          transformedConfig.responseSchema = responseSchemaConfig.schema;\n          transformedConfig.responseMimeType = \"application/json\";\n          if (\"additionalProperties\" in responseSchemaConfig.schema) {\n            // Google does not support additionalProperties in responseSchema but our schema always has it\n            delete (transformedConfig.responseSchema as any).additionalProperties;\n          }\n          delete transformedConfig.response_format;\n          delete transformedConfig.response_schema;\n        }\n      } else if (responseFormat === \"json_object\") {\n        transformedConfig.responseSchema = {\n          type: \"object\"\n        };\n        delete transformedConfig.response_format;\n      } else if (responseFormat === \"text\") {\n        delete transformedConfig.response_format;\n      }\n    }\n\n    return {\n      generation_config: transformedConfig,\n      ...(toolConfig ? { tool_config: toolConfig } : {}),\n      ...(safetySettings ? { safety_settings: safetySettings } : {}),\n    };\n  }\n\n  transformMessages(messages: MessageType[]): ParamsType {\n    if (!messages || (messages && messages.length === 0)) {\n      return { messages: [] };\n    }\n    const stripBase64Prefix = (data: string): string => {\n      const prefixMatch = data.match(/^data:image\\/[a-zA-Z]+;base64,/);\n      if (prefixMatch) {\n        return data.substring(prefixMatch[0].length);\n      }\n      return data;\n    };\n    const parsedMessages = messages.map((message) => {\n      const parsedMessage = Message().safeParse(message);\n      if (!parsedMessage.success) {\n        throw new InvalidMessagesError({ info: \"Invalid messages\", cause: parsedMessage.error });\n      }\n      return parsedMessage.data;\n    });\n\n    parsedMessages.forEach((message) => {\n      message.content.forEach((content) => {\n        if (!this.modelSchema.modalities.includes(content.modality)) {\n          throw new InvalidMessagesError({\n            info: `Invalid message content for model : '${this.modelName}'`,\n            cause: new Error(`model : '${this.modelName}' does not support modality : '${content.modality}', \n              available modalities : [${this.modelSchema.modalities.join(\", \")}]`),\n          });\n        }\n      });\n    });\n\n    parsedMessages.forEach((message) => {\n      if (!Object.keys(this.modelSchema.roles).includes(message.role)) {\n        throw new InvalidMessagesError({\n          info: `Invalid message content for model : '${this.modelName}'`,\n          cause: new Error(`model : '${this.modelName}' does not support role : '${message.role}', \n            available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n        });\n      }\n    });\n\n    const systemInstruction: GoogleChatSystemInstructionType = { parts: [] };\n    const nonSystemMessages: GoogleChatContentType[] = [];\n\n    parsedMessages.forEach((message) => {\n      switch (message.role) {\n        case SystemRoleLiteral:\n          {\n            message.content.forEach((content) => {\n              if (content.modality === TextModalityLiteral) {\n                systemInstruction.parts.push({ text: content.value });\n              } else {\n                throw new InvalidMessagesError({\n                  info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                  cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n                });\n              }\n            });\n          }\n          break;\n\n        case AssistantRoleLiteral:\n          {\n            const assistantContent: GoogleChatContentType[\"parts\"] = [];\n            message.content.forEach((content) => {\n              if (content.modality === TextModalityLiteral) {\n                assistantContent.push({ text: content.value });\n              } else if (content.modality === ToolCallModalityLiteral) {\n                assistantContent.push({\n                  function_call: {\n                    name: content.name,\n                    args: JSON.parse(content.arguments),\n                  },\n                });\n              } else {\n                throw new InvalidMessagesError({\n                  info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                  cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n                });\n              }\n            });\n            nonSystemMessages.push({\n              role: this.modelSchema.roles[message.role] as GoogleChatContentType[\"role\"],\n              parts: assistantContent,\n            });\n          }\n          break;\n\n        case UserRoleLiteral:\n          {\n            const userContent: GoogleChatContentType[\"parts\"] = [];\n            message.content.forEach((content) => {\n              if (content.modality === TextModalityLiteral) {\n                userContent.push({ text: content.value });\n              } else if (content.modality === ImageModalityLiteral) {\n                if (content.value.type === \"base64\") {\n                  let base64Data = content.value.base64;\n                  // Check and strip the data URL prefix if it exists.\n                  base64Data = stripBase64Prefix(base64Data);\n                  userContent.push({\n                    inline_data: {\n                      mime_type: `image/${content.value.mediaType}`,\n                      data: base64Data,\n                    },\n                  });\n                } else if (content.value.type === \"url\") {\n                  // TODO: add logic to fetch image from url, remove this error\n                  throw new InvalidMessagesError({\n                    info: `Invalid message 'modality' for model : ${this.modelName}`,\n                    cause: new Error(`model: '${this.modelName}' does not support image content type: '${content.value.type}'`),\n                  });\n                }\n              } else {\n                throw new InvalidMessagesError({\n                  info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                  cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n                });\n              }\n            });\n            nonSystemMessages.push({\n              role: this.modelSchema.roles[message.role] as GoogleChatContentType[\"role\"],\n              parts: userContent,\n            });\n          }\n          break;\n\n        case ToolRoleLiteral:\n          {\n            const toolResponseContent: GoogleChatContentPartFunctionResponseType[] = [];\n            message.content.forEach((content) => {\n              if (content.modality === ToolResponseModalityLiteral) {\n                toolResponseContent.push({\n                  function_response: {\n                    name: content.name,\n                    response: JSON.parse(content.data),\n                  },\n                });\n              } else {\n                throw new InvalidMessagesError({\n                  info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                  cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n                });\n              }\n            });\n            nonSystemMessages.push({\n              role: this.modelSchema.roles[message.role] as GoogleChatContentType[\"role\"],\n              parts: toolResponseContent,\n            });\n          }\n          break;\n\n        default: {\n          throw new InvalidMessagesError({\n            info: `Invalid message 'role' for model : ${this.modelName}`,\n            cause: new Error(`role : '${message.role}' is not supported, \n              available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n          });\n        }\n      }\n    });\n\n    if (nonSystemMessages[0].role !== this.modelSchema.roles[UserRoleLiteral]) {\n      throw new InvalidMessagesError({\n        info: `Invalid message 'role' for model : ${this.modelName}`,\n        cause: new Error(`model : '${this.modelName}' requires first message to be from user`),\n      });\n    }\n\n    const getNextExpectedRoles = (role: string): string[] => {\n      if (role === this.modelSchema.roles[UserRoleLiteral] || role === this.modelSchema.roles[ToolRoleLiteral]) {\n        return [this.modelSchema.roles[AssistantRoleLiteral] as string];\n      }\n      return [this.modelSchema.roles[UserRoleLiteral] as string, this.modelSchema.roles[ToolRoleLiteral] as string];\n    };\n\n    for (let i = 1; i < nonSystemMessages.length; i++) {\n      if (!getNextExpectedRoles(nonSystemMessages[i - 1].role).includes(nonSystemMessages[i].role)) {\n        throw new InvalidMessagesError({\n          info: `Invalid message format for model : ${this.modelName}`,\n          cause: new Error(\n            `model : '${this.modelName}' cannot have message with role : '${nonSystemMessages[i].role}' after message with role : '${nonSystemMessages[i - 1].role}'`\n          ),\n        });\n      }\n    }\n\n    if (\n      nonSystemMessages[nonSystemMessages.length - 1].role !== this.modelSchema.roles[UserRoleLiteral] &&\n      nonSystemMessages[nonSystemMessages.length - 1].role !== this.modelSchema.roles[ToolRoleLiteral]\n    ) {\n      throw new InvalidMessagesError({\n        info: `Invalid message format for model : ${this.modelName}`,\n        cause: new Error(`model : '${this.modelName}' requires last message to be from user`),\n      });\n    }\n\n    return {\n      contents: nonSystemMessages,\n      ...(systemInstruction.parts.length > 0 ? { system_instruction: systemInstruction } : {}),\n    };\n  }\n\n  transformTools(tools: ToolType[]): ParamsType {\n    if (!this.modelSchema.modalities.includes(ToolCallModalityLiteral)) {\n      throw new InvalidToolsError({\n        info: `Invalid tool 'modality' for model : ${this.modelName}`,\n        cause: new Error(`model : '${this.modelName}' does not support tool modality : '${ToolCallModalityLiteral}'`),\n      });\n    }\n\n    if (!tools || (tools && tools.length === 0)) {\n      return { tools: [] as ToolType[] };\n    }\n\n    const parsedTools = tools.map((tool) => {\n      const parsedTool = Tool().safeParse(tool);\n      if (!parsedTool.success) {\n        throw new InvalidToolsError({ info: \"Invalid tools\", cause: parsedTool.error });\n      }\n      return parsedTool.data;\n    });\n\n    const transformedTools = parsedTools.map((tool) => ({\n      name: tool.definition.schema.name,\n      description: tool.definition.schema.description,\n      parameters: tool.definition.schema.parameters,\n    }));\n\n    return {\n      tools: [\n        {\n          function_declarations: transformedTools,\n        },\n      ],\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getCompleteChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  transformCompleteChatResponse(response: any): ChatResponseType {\n    const safe = GoogleCompleteChatResponse.safeParse(response);\n    if (safe.success) {\n      if (safe.data.candidates.length === 0) {\n        throw new ModelResponseError({\n          info: \"Invalid response from model\",\n          cause: new Error(`No choices in response : ${JSON.stringify(safe.data)}`),\n        });\n      }\n\n      const parsedResponse: GoogleCompleteChatResponseType = safe.data;\n      const messages: MessageType[] = [];\n      let usage: ChatUsageType | undefined;\n      const _content = parsedResponse.candidates[0].content;\n      if (_content) {\n        const content = _content.parts.map((contentItem: any, index: any) => {\n          if (\"text\" in contentItem && contentItem.text !== undefined) {\n            return createTextContent(contentItem.text);\n          } else if (\"functionCall\" in contentItem && contentItem.functionCall !== undefined) {\n            return createToolCallContent(\n              index,\n              `${contentItem.functionCall.name}_${index}`,\n              contentItem.functionCall.name,\n              JSON.stringify(contentItem.functionCall.args)\n            );\n          }\n        }) as ContentType[];\n\n        messages.push({\n          role: AssistantRoleLiteral,\n          content: content,\n        });\n\n        if (parsedResponse.usageMetadata) {\n          usage = {\n            promptTokens: parsedResponse.usageMetadata.promptTokenCount,\n            totalTokens: parsedResponse.usageMetadata.totalTokenCount,\n            completionTokens: parsedResponse.usageMetadata.candidatesTokenCount || 0,\n          };\n        }\n\n        return {\n          messages: messages,\n          usage: usage,\n          logProbs: undefined,\n        };\n      }\n\n      const safetyRatings = parsedResponse.candidates[0].safetyRatings;\n      if (safetyRatings && safetyRatings.length > 0) {\n        safetyRatings.forEach((rating) => {\n          if (rating.blocked) {\n            throw new ModelResponseError({\n              info: `Blocked content for category: ${rating.category} with probability: ${rating.probability}`,\n              cause: new Error(`Blocked content for category: ${rating.category} with probability: ${rating.probability}`),\n            });\n          }\n        });\n      }\n\n      const finishReason = parsedResponse.candidates[0].finishReason;\n      if (finishReason === \"SAFETY\") {\n        throw new ModelResponseError({\n          info: \"Blocked content, model response finished with safety reason\",\n          cause: new Error(\"Blocked content, model response finished with safety reason\"),\n        });\n      }\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.streamChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getStreamChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  async *transformStreamChatResponseChunk(\n    chunk: string,\n    buffer: string\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    // merge last buffer message and split into lines\n    const lines = (buffer + chunk).split(\",\\r\").filter((line) => line.trim() !== \"\");\n    for (const line of lines) {\n      let completeLine = line;\n      // remove all '\\n' from string JSON\n      completeLine = completeLine.replace(/\\n/g, \"\");\n      if (completeLine.startsWith(\"[\") || completeLine.startsWith(\",{\")) {\n        // start of stream, remove '['\n        completeLine = completeLine.slice(1);\n      } else if (completeLine.endsWith(\"]\")) {\n        if (completeLine === \"]\") {\n          // strict end of stream\n          return;\n        } else {\n          // remaining message and then end of stream, remove ']'\n          completeLine = completeLine.slice(0, -1);\n        }\n      }\n\n      let structuredLine: any;\n      try {\n        structuredLine = JSON.parse(completeLine);\n      } catch (error) {\n        // malformed JSON error, must be the end of loop\n        if (error instanceof SyntaxError) {\n          buffer = completeLine;\n          continue;\n        } else {\n          // non JSON parse error, re-raise\n          throw error;\n        }\n      }\n\n      // reset buffer\n      buffer = \"\";\n      const safe = GoogleStreamChatResponse.safeParse(structuredLine);\n      if (safe.success) {\n        const partialResponse: PartialChatResponseType = { partialMessages: [] };\n        const parsedResponse: GoogleStreamChatResponseType = safe.data;\n        if (parsedResponse.candidates.length > 0) {\n          const message = parsedResponse.candidates[0].content;\n          if (message && \"parts\" in message && message.parts.length > 0) {\n            message.parts.forEach((messagePart, index) => {\n              if (\"text\" in messagePart && messagePart.text !== undefined) {\n                partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, messagePart.text));\n              }\n\n              if (\"functionCall\" in messagePart && messagePart.functionCall !== undefined) {\n                const toolCall = messagePart.functionCall;\n                partialResponse.partialMessages.push(\n                  createPartialToolCallMessage(\n                    AssistantRoleLiteral,\n                    index,\n                    `${toolCall.name}_${index}`,\n                    toolCall.name,\n                    JSON.stringify(toolCall.args)\n                  )\n                );\n              }\n            });\n          }\n        }\n\n        if (parsedResponse.usageMetadata) {\n          partialResponse.usage = {\n            promptTokens: parsedResponse.usageMetadata.promptTokenCount,\n            completionTokens: parsedResponse.usageMetadata.candidatesTokenCount,\n            totalTokens: parsedResponse.usageMetadata.totalTokenCount,\n          };\n        }\n\n        yield { partialResponse: partialResponse, buffer: buffer };\n      } else {\n        throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n      }\n    }\n\n    yield { partialResponse: { partialMessages: [] }, buffer: buffer };\n  }\n  async *transformProxyStreamChatResponseChunk(\n    chunk: string,\n    buffer: string,\n    data?: any,\n    headers?: Record<string, string>,\n    query?: Record<string, string>\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    // If query has alt not equal to 'sse', delegate to streamTransform logic\n    if (query?.alt !== \"sse\") {\n      yield* this.transformStreamChatResponseChunk(chunk, buffer);\n      return;\n    }\n\n    // --- proxyStreamTransform logic starts here ---\n    const newData = buffer + chunk;\n    let lines: string[] = [];\n    let newBuffer = \"\";\n\n    // Split newData into complete lines and new buffer\n    let currentIndex = 0;\n    while (currentIndex < newData.length) {\n      const newlineIndex = newData.indexOf(\"\\n\", currentIndex);\n      if (newlineIndex === -1) {\n        newBuffer = newData.substring(currentIndex);\n        break;\n      } else {\n        const line = newData.substring(currentIndex, newlineIndex).trim();\n        if (line) {\n          lines.push(line);\n        }\n        currentIndex = newlineIndex + 1;\n      }\n    }\n\n    // Process each complete line\n    for (const line of lines) {\n      if (line === \"data: [DONE]\") {\n        return; // End of stream\n      }\n\n      if (line.startsWith(\"data: \")) {\n        const jsonStr = line.substring(\"data: \".length);\n        try {\n          const structuredLine = JSON.parse(jsonStr);\n          const safe = GoogleStreamChatResponse.safeParse(structuredLine);\n          if (safe.success) {\n            const partialResponse: PartialChatResponseType = { partialMessages: [] };\n            const parsedResponse: GoogleStreamChatResponseType = safe.data;\n            if (parsedResponse.candidates.length > 0) {\n              const message = parsedResponse.candidates[0].content;\n              if (message && \"parts\" in message && message.parts.length > 0) {\n                message.parts.forEach((messagePart, index) => {\n                  if (\"text\" in messagePart && messagePart.text !== undefined) {\n                    partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, messagePart.text));\n                  }\n\n                  if (\"functionCall\" in messagePart && messagePart.functionCall !== undefined) {\n                    const toolCall = messagePart.functionCall;\n                    partialResponse.partialMessages.push(\n                      createPartialToolCallMessage(\n                        AssistantRoleLiteral,\n                        index,\n                        `${toolCall.name}_${index}`,\n                        toolCall.name,\n                        JSON.stringify(toolCall.args)\n                      )\n                    );\n                  }\n                });\n              }\n            }\n\n            if (\n              parsedResponse.usageMetadata &&\n              parsedResponse.usageMetadata.totalTokenCount &&\n              parsedResponse.usageMetadata.promptTokenCount &&\n              parsedResponse.usageMetadata.candidatesTokenCount\n            ) {\n              partialResponse.usage = {\n                promptTokens: parsedResponse.usageMetadata.promptTokenCount,\n                completionTokens: parsedResponse.usageMetadata.candidatesTokenCount,\n                totalTokens: parsedResponse.usageMetadata.totalTokenCount,\n              };\n            }\n\n            yield { partialResponse: partialResponse, buffer: buffer };\n          } else {\n            throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n          }\n        } catch (error) {\n          throw new ModelResponseError({\n            info: `Malformed JSON received in stream: ${jsonStr}`,\n            cause: error,\n          });\n        }\n      }\n    }\n\n    // Yield the updated buffer after processing all lines\n    yield { partialResponse: { partialMessages: [] }, buffer: newBuffer };\n  }\n\n  async getProxyCompleteChatUrl(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  async getProxyStreamChatUrl(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<UrlType> {\n    return new Promise((resolve) => {\n      if (!query || Object.keys(query).length === 0) {\n        resolve(this.streamChatUrl);\n        return;\n      }\n\n      const url = new URL(this.streamChatUrl);\n      Object.entries(query).forEach(([key, value]) => {\n        if (value != null) {\n          url.searchParams.set(key, value);\n        }\n      });\n\n      resolve(url.toString() as UrlType);\n    });\n  }\n  async getProxyCompleteChatHeaders(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<HeadersType> {\n    if (!headers) {\n      return {};\n    }\n    const sanitizedHeaders: Record<string, string> = { ...headers };\n\n    delete sanitizedHeaders.host;\n    delete sanitizedHeaders[\"content-length\"];\n    return sanitizedHeaders;\n  }\n  async getProxyStreamChatHeaders(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<HeadersType> {\n    // Directly delegate to getProxyCompleteChatHeaders for now\n    return await this.getProxyCompleteChatHeaders(data, headers, query);\n  }\n  getModelPricing(): ChatModelPriceType {\n    // Check if the modelName exists in pricingData before accessing it\n    if (!(this.modelName in pricingData)) {\n      throw new ModelResponseError({\n        info: `Invalid model pricing for model : '${this.modelName}'`,\n        cause: new Error(`No pricing configuration found for model \"${this.modelName}\"`),\n      });\n    }\n\n    const entry = pricingData[this.modelName as keyof typeof pricingData];\n    return entry as ChatModelPriceType;\n  }\n}\n\nexport { BaseChatModel, BaseChatModelOptions, type BaseChatModelOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5Flash001Literal = \"gemini-1.5-flash-001\";\nconst Gemini1_5Flash001Description =\n  \"Google's fastest, most cost-efficient multimodal model with great performance for high-frequency tasks. \\\n  Optimized for fast and versatile performance across a diverse variety of tasks\";\n\nconst Gemini1_5Flash001Schema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5Flash001Literal,\n  description: Gemini1_5Flash001Description,\n  maxInputTokens: 1000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5Flash001Literal],\n});\n\nconst Gemini1_5Flash001Options = BaseChatModelOptions;\ntype Gemini1_5Flash001OptionsType = z.infer<typeof Gemini1_5Flash001Options>;\n\nclass Gemini1_5Flash001 extends BaseChatModel {\n  constructor(options: Gemini1_5Flash001OptionsType) {\n    super(Gemini1_5Flash001Schema, options);\n  }\n}\n\nexport {\n  Gemini1_5Flash001,\n  Gemini1_5Flash001Literal,\n  Gemini1_5Flash001Options,\n  Gemini1_5Flash001Schema,\n  type Gemini1_5Flash001OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5Flash002Literal = \"gemini-1.5-flash-002\";\nconst Gemini1_5Flash002Description =\n  \"Google's fastest, most cost-efficient multimodal model with great performance for high-frequency tasks. \\\n  Optimized for fast and versatile performance across a diverse variety of tasks\";\n\nconst Gemini1_5Flash002Schema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5Flash002Literal,\n  description: Gemini1_5Flash002Description,\n  maxInputTokens: 1000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5Flash002Literal],\n});\n\nconst Gemini1_5Flash002Options = BaseChatModelOptions;\ntype Gemini1_5Flash002OptionsType = z.infer<typeof Gemini1_5Flash002Options>;\n\nclass Gemini1_5Flash002 extends BaseChatModel {\n  constructor(options: Gemini1_5Flash002OptionsType) {\n    super(Gemini1_5Flash002Schema, options);\n  }\n}\n\nexport {\n  Gemini1_5Flash002,\n  Gemini1_5Flash002Literal,\n  Gemini1_5Flash002Options,\n  Gemini1_5Flash002Schema,\n  type Gemini1_5Flash002OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5FlashLatestLiteral = \"gemini-1.5-flash-latest\";\nconst Gemini1_5FlashLatestDescription =\n  \"Google's latest multimodal model with great performance for high-frequency tasks. \\\n  Optimized for fast and versatile performance across a diverse variety of tasks\";\n\nconst Gemini1_5FlashLatestSchema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5FlashLatestLiteral,\n  description: Gemini1_5FlashLatestDescription,\n  maxInputTokens: 1000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5FlashLatestLiteral],\n});\n\nconst Gemini1_5FlashLatestOptions = BaseChatModelOptions;\ntype Gemini1_5FlashLatestOptionsType = z.infer<typeof Gemini1_5FlashLatestOptions>;\n\nclass Gemini1_5FlashLatest extends BaseChatModel {\n  constructor(options: Gemini1_5FlashLatestOptionsType) {\n    super(Gemini1_5FlashLatestSchema, options);\n  }\n}\n\nexport {\n  Gemini1_5FlashLatest,\n  Gemini1_5FlashLatestLiteral,\n  Gemini1_5FlashLatestOptions,\n  Gemini1_5FlashLatestSchema,\n  type Gemini1_5FlashLatestOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5FlashLiteral = \"gemini-1.5-flash\";\nconst Gemini1_5FlashDescription =\n  \"Google's fastest, most cost-efficient multimodal model with great performance for high-frequency tasks. \\\n  Optimized for fast and versatile performance across a diverse variety of tasks\";\n\nconst Gemini1_5FlashSchema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5FlashLiteral,\n  description: Gemini1_5FlashDescription,\n  maxInputTokens: 1000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5FlashLiteral],\n});\n\nconst Gemini1_5FlashOptions = BaseChatModelOptions;\ntype Gemini1_5FlashOptionsType = z.infer<typeof Gemini1_5FlashOptions>;\n\nclass Gemini1_5Flash extends BaseChatModel {\n  constructor(options: Gemini1_5FlashOptionsType) {\n    super(Gemini1_5FlashSchema, options);\n  }\n}\n\nexport { Gemini1_5Flash, Gemini1_5FlashLiteral, Gemini1_5FlashOptions, Gemini1_5FlashSchema, type Gemini1_5FlashOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5Pro001Literal = \"gemini-1.5-pro-001\";\nconst Gemini1_5Pro001Description =\n  \"Google's best performing multimodal model with features for a wide variety of reasoning tasks. \\\n  Optimized for complex reasoning tasks requiring more intelligence\";\n\nconst Gemini1_5Pro001Schema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5Pro001Literal,\n  description: Gemini1_5Pro001Description,\n  maxInputTokens: 2000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5Pro001Literal],\n});\n\nconst Gemini1_5Pro001Options = BaseChatModelOptions;\ntype Gemini1_5Pro001OptionsType = z.infer<typeof Gemini1_5Pro001Options>;\n\nclass Gemini1_5Pro001 extends BaseChatModel {\n  constructor(options: Gemini1_5Pro001OptionsType) {\n    super(Gemini1_5Pro001Schema, options);\n  }\n}\n\nexport { Gemini1_5Pro001, Gemini1_5Pro001Literal, Gemini1_5Pro001Options, Gemini1_5Pro001Schema, type Gemini1_5Pro001OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5Pro002Literal = \"gemini-1.5-pro-002\";\nconst Gemini1_5Pro002Description =\n  \"Google's best performing multimodal model with features for a wide variety of reasoning tasks. \\\n  Optimized for complex reasoning tasks requiring more intelligence\";\n\nconst Gemini1_5Pro002Schema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5Pro002Literal,\n  description: Gemini1_5Pro002Description,\n  maxInputTokens: 2000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5Pro002Literal],\n});\n\nconst Gemini1_5Pro002Options = BaseChatModelOptions;\ntype Gemini1_5Pro002OptionsType = z.infer<typeof Gemini1_5Pro002Options>;\n\nclass Gemini1_5Pro002 extends BaseChatModel {\n  constructor(options: Gemini1_5Pro002OptionsType) {\n    super(Gemini1_5Pro002Schema, options);\n  }\n}\n\nexport { Gemini1_5Pro002, Gemini1_5Pro002Literal, Gemini1_5Pro002Options, Gemini1_5Pro002Schema, type Gemini1_5Pro002OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5ProLatestLiteral = \"gemini-1.5-pro-latest\";\nconst Gemini1_5ProLatestDescription =\n  \"Google's best performing multimodal model with features for a wide variety of reasoning tasks. \\\n  Optimized for complex reasoning tasks requiring more intelligence\";\n\nconst Gemini1_5ProLatestSchema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5ProLatestLiteral,\n  description: Gemini1_5ProLatestDescription,\n  maxInputTokens: 2000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5ProLatestLiteral],\n});\n\nconst Gemini1_5ProLatestOptions = BaseChatModelOptions;\ntype Gemini1_5ProLatestOptionsType = z.infer<typeof Gemini1_5ProLatestOptions>;\n\nclass Gemini1_5ProLatest extends BaseChatModel {\n  constructor(options: Gemini1_5ProLatestOptionsType) {\n    super(Gemini1_5ProLatestSchema, options);\n  }\n}\n\nexport {\n  Gemini1_5ProLatest,\n  Gemini1_5ProLatestLiteral,\n  Gemini1_5ProLatestOptions,\n  Gemini1_5ProLatestSchema,\n  type Gemini1_5ProLatestOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini1_5ProLiteral = \"gemini-1.5-pro\";\nconst Gemini1_5ProDescription =\n  \"Google's best performing multimodal model with features for a wide variety of reasoning tasks. \\\n  Optimized for complex reasoning tasks requiring more intelligence\";\n\nconst Gemini1_5ProSchema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini1_5ProLiteral,\n  description: Gemini1_5ProDescription,\n  maxInputTokens: 2000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini1_5ProLiteral],\n});\n\nconst Gemini1_5ProOptions = BaseChatModelOptions;\ntype Gemini1_5ProOptionsType = z.infer<typeof Gemini1_5ProOptions>;\n\nclass Gemini1_5Pro extends BaseChatModel {\n  constructor(options: Gemini1_5ProOptionsType) {\n    super(Gemini1_5ProSchema, options);\n  }\n}\n\nexport { Gemini1_5Pro, Gemini1_5ProLiteral, Gemini1_5ProOptions, Gemini1_5ProSchema, type Gemini1_5ProOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini2_0FlashExpLiteral = \"gemini-2.0-flash-exp\";\nconst Gemini2_0FlashExpDescription =\n  \"Google's experimental multimodal model with enhanced capabilities. \\\n  Designed for cutting-edge performance across complex and high-frequency tasks.\";\n\nconst Gemini2_0FlashExpSchema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini2_0FlashExpLiteral,\n  description: Gemini2_0FlashExpDescription,\n  maxInputTokens: 1000000,\n  maxOutputTokens: 8192,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 8192, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini2_0FlashExpLiteral],\n});\n\nconst Gemini2_0FlashExpOptions = BaseChatModelOptions;\ntype Gemini2_0FlashExpOptionsType = z.infer<typeof Gemini2_0FlashExpOptions>;\n\nclass Gemini2_0FlashExp extends BaseChatModel {\n  constructor(options: Gemini2_0FlashExpOptionsType) {\n    super(Gemini2_0FlashExpSchema, options);\n  }\n}\n\nexport {\n  Gemini2_0FlashExp,\n  Gemini2_0FlashExpLiteral,\n  Gemini2_0FlashExpOptions,\n  Gemini2_0FlashExpSchema,\n  type Gemini2_0FlashExpOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini2_5FlashPreview0417Literal = \"gemini-2.5-flash-preview-04-17\";\nconst Gemini2_5FlashPreview0417Description =\n  \"Google's best model in Gemini 2.5 family in terms of price-performance, offering well-rounded capabilities.\";\n\nconst Gemini2_5FlashPreview0417Schema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini2_5FlashPreview0417Literal,\n  description: Gemini2_5FlashPreview0417Description,\n  maxInputTokens: 1048576,\n  maxOutputTokens: 65536,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 65536, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.responseSchema(2.0, 1.0, 65536, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini2_5FlashPreview0417Literal],\n});\n\nconst Gemini2_5FlashPreview0417Options = BaseChatModelOptions;\ntype Gemini2_5FlashPreview0417OptionsType = z.infer<typeof Gemini2_5FlashPreview0417Options>;\n\nclass Gemini2_5FlashPreview0417 extends BaseChatModel {\n  constructor(options: Gemini2_5FlashPreview0417OptionsType) {\n    super(Gemini2_5FlashPreview0417Schema, options);\n  }\n}\n\nexport {\n  Gemini2_5FlashPreview0417,\n  Gemini2_5FlashPreview0417Literal,\n  Gemini2_5FlashPreview0417Options,\n  Gemini2_5FlashPreview0417Schema,\n  type Gemini2_5FlashPreview0417OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { GoogleChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.google\";\nimport { GoogleChatModelModalities, GoogleChatModelModalitiesEnum, GoogleChatModelRoles, GoogleChatModelRolesMap } from \"./types\";\n\nconst Gemini2_5ProPreview0325Literal = \"gemini-2.5-pro-preview-03-25\";\nconst Gemini2_5ProPreview0325Description =\n  \"Google's preview model in Gemini 2.5 family for enhanced thinking, reasoning, multimodal understanding, and advanced coding.\";\n\nconst Gemini2_5ProPreview0325Schema = ChatModelSchema(GoogleChatModelRoles, GoogleChatModelModalitiesEnum).parse({\n  name: Gemini2_5ProPreview0325Literal,\n  description: Gemini2_5ProPreview0325Description,\n  maxInputTokens: 1048576,\n  maxOutputTokens: 65536,\n  roles: GoogleChatModelRolesMap,\n  modalities: GoogleChatModelModalities,\n  config: {\n    def: GoogleChatModelConfigs.reasoning(2.0, 1.0, 65536, 4, 0.95).def,\n    schema: GoogleChatModelConfigs.reasoning(2.0, 1.0, 65536, 4, 0.95).schema,\n  },\n  price: pricingData[Gemini2_5ProPreview0325Literal],\n});\n\nconst Gemini2_5ProPreview0325Options = BaseChatModelOptions;\ntype Gemini2_5ProPreview0325OptionsType = z.infer<typeof Gemini2_5ProPreview0325Options>;\n\nclass Gemini2_5ProPreview0325 extends BaseChatModel {\n  constructor(options: Gemini2_5ProPreview0325OptionsType) {\n    super(Gemini2_5ProPreview0325Schema, options);\n  }\n}\n\nexport {\n  Gemini2_5ProPreview0325,\n  Gemini2_5ProPreview0325Literal,\n  Gemini2_5ProPreview0325Options,\n  Gemini2_5ProPreview0325Schema,\n  type Gemini2_5ProPreview0325OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchemaType } from \"@adaline/provider\";\nimport { EmbeddingTextModalityLiteral } from \"@adaline/types\";\n\nconst GoogleEmbeddingModelModalities: EmbeddingModelSchemaType[\"modalities\"] = [EmbeddingTextModalityLiteral];\n\nconst GoogleEmbeddingModelModalitiesEnum = z.enum([EmbeddingTextModalityLiteral]);\n\nexport { GoogleEmbeddingModelModalitiesEnum, GoogleEmbeddingModelModalities };\n","import { z } from \"zod\";\n\nconst GoogleGetEmbeddingsResponse = z.object({\n  embeddings: z.array(\n    z.object({\n      values: z.array(z.number()),\n    })\n  ),\n});\ntype GoogleGetEmbeddingsResponseType = z.infer<typeof GoogleGetEmbeddingsResponse>;\n\nexport { GoogleGetEmbeddingsResponse, type GoogleGetEmbeddingsResponseType };\n","import { z } from \"zod\";\n\nconst GoogleEmbeddingRequestInput = z.object({\n  model: z.string().min(1),\n  content: z.object({\n    parts: z\n      .array(\n        z.object({\n          text: z.string().min(1),\n        })\n      )\n      .min(1),\n  }),\n});\ntype GoogleEmbeddingRequestInputType = z.infer<typeof GoogleEmbeddingRequestInput>;\n\nconst GoogleEmbeddingRequest = z.object({\n  model: z.string().min(1).optional(),\n  requests: z.array(GoogleEmbeddingRequestInput).min(1),\n  outputDimensionality: z.number().int().min(1).optional(),\n});\ntype GoogleEmbeddingRequestType = z.infer<typeof GoogleEmbeddingRequest>;\n\nexport { GoogleEmbeddingRequest, GoogleEmbeddingRequestInput, type GoogleEmbeddingRequestType, type GoogleEmbeddingRequestInputType };\n","import { z } from \"zod\";\n\nimport {\n  EmbeddingModelSchemaType,\n  EmbeddingModelV1,\n  HeadersType,\n  InvalidConfigError,\n  InvalidEmbeddingRequestsError,\n  InvalidModelRequestError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\nimport {\n  Config,\n  ConfigType,\n  EmbeddingRequests,\n  EmbeddingRequestsType,\n  EmbeddingResponseType,\n  EmbeddingTextModalityLiteral,\n  FloatEmbeddingLiteral,\n  FloatEmbeddingType,\n} from \"@adaline/types\";\n\nimport { Google } from \"../../provider/provider.google\";\nimport { GoogleEmbeddingRequest, GoogleEmbeddingRequestInputType, GoogleGetEmbeddingsResponse } from \"./types\";\n\nconst BaseEmbeddingModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  getEmbeddingsUrl: z.string().url().optional(),\n});\ntype BaseEmbeddingModelOptionsType = z.infer<typeof BaseEmbeddingModelOptions>;\n\nclass BaseEmbeddingModel implements EmbeddingModelV1<EmbeddingModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: EmbeddingModelSchemaType;\n  readonly modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly getEmbeddingsUrl: string;\n\n  constructor(modelSchema: EmbeddingModelSchemaType, options: BaseEmbeddingModelOptionsType) {\n    const parsedOptions = BaseEmbeddingModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || Google.baseUrl);\n    this.getEmbeddingsUrl = urlWithoutTrailingSlash(\n      parsedOptions.getEmbeddingsUrl || `${this.baseUrl}/models/${this.modelName}:batchEmbedContents?key=${this.apiKey}`\n    );\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      \"Content-Type\": \"application/json\",\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelName,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    return { shouldRetry: false, delayMs: 0 };\n  }\n\n  // TODO: unused method, not tested\n  getTokenCount(requests: EmbeddingRequestsType): number {\n    return requests.requests.reduce((acc, request) => acc + request.length, 0);\n  }\n\n  transformModelRequest(request: any): {\n    modelName: string | undefined;\n    config: ConfigType;\n    embeddingRequests: EmbeddingRequestsType;\n  } {\n    const safeRequest = GoogleEmbeddingRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    const _config = {\n      outputDimensionality: parsedRequest.outputDimensionality,\n    };\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    const embeddingRequests: EmbeddingRequestsType = {\n      modality: EmbeddingTextModalityLiteral,\n      requests: parsedRequest.requests.reduce((acc, request) => {\n        acc.push(...request.content.parts.map((p) => p.text));\n        return acc;\n      }, [] as string[]),\n    };\n\n    return {\n      modelName,\n      config,\n      embeddingRequests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, requests?: EmbeddingRequestsType): ParamsType {\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    Object.keys(parsedConfig as ConfigType).forEach((key) => {\n      if (!this.modelSchema.config.def[key]) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = parsedConfig[key];\n      acc[paramKey] = paramValue;\n      return acc;\n    }, {} as ParamsType);\n\n    return transformedConfig;\n  }\n\n  transformEmbeddingRequests(requests: EmbeddingRequestsType): ParamsType {\n    const _parsedRequests = EmbeddingRequests().safeParse(requests);\n    if (!_parsedRequests.success) {\n      throw new InvalidEmbeddingRequestsError({ info: \"Invalid embedding requests\", cause: _parsedRequests.error });\n    }\n\n    if (requests.modality !== EmbeddingTextModalityLiteral) {\n      throw new InvalidEmbeddingRequestsError({\n        info: `Invalid embedding requests for model : '${this.modelName}'`,\n        cause: new Error(`Only '${EmbeddingTextModalityLiteral}' modality is supported for model : '${this.modelName}'`),\n      });\n    }\n\n    const _requests: GoogleEmbeddingRequestInputType[] = _parsedRequests.data.requests.map((request) => {\n      return {\n        model: `models/${this.modelName}`,\n        content: { parts: [{ text: request as string }] },\n      };\n    });\n\n    return {\n      requests: _requests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsUrl(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.getEmbeddingsUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsHeaders(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getGetEmbeddingsData(config: ConfigType, requests: EmbeddingRequestsType): Promise<ParamsType> {\n    return new Promise((resolve) => {\n      const _config = this.transformConfig(config);\n      const _requests = this.transformEmbeddingRequests(requests);\n\n      if (requests.requests.length === 0) {\n        throw new InvalidEmbeddingRequestsError({\n          info: `Invalid embedding requests for model : '${this.modelName}'`,\n          cause: new Error(\"requests cannot be empty\"),\n        });\n      }\n\n      if (_config.outputDimensionality) {\n        (_requests as any).requests.forEach((request: any) => {\n          request.outputDimensionality = _config.outputDimensionality;\n        });\n        delete _config.outputDimensionality;\n      }\n\n      resolve({\n        ...this.getDefaultParams(),\n        ..._config,\n        ..._requests,\n      });\n    });\n  }\n\n  transformGetEmbeddingsResponse(response: any): EmbeddingResponseType {\n    const safe = GoogleGetEmbeddingsResponse.safeParse(response);\n    if (safe.success) {\n      const parsedResponse = safe.data;\n      const embeddings = parsedResponse.embeddings.map((embedding, index) => {\n        return {\n          index,\n          embedding: embedding.values,\n        } as FloatEmbeddingType;\n      });\n\n      return {\n        encodingFormat: FloatEmbeddingLiteral,\n        embeddings: embeddings,\n      } as EmbeddingResponseType;\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n}\n\nexport { BaseEmbeddingModel, BaseEmbeddingModelOptions, type BaseEmbeddingModelOptionsType };\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { GoogleEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.google\";\nimport { GoogleEmbeddingModelModalities, GoogleEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_001Literal = \"text-embedding-001\";\nconst Text_Embedding_001_Description = \"text-embedding-001\";\n\nconst Text_Embedding_001Schema = EmbeddingModelSchema(GoogleEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_001Literal,\n  description: Text_Embedding_001_Description,\n  modalities: GoogleEmbeddingModelModalities,\n  maxInputTokens: 2048,\n  maxOutputTokens: 768,\n  config: {\n    def: GoogleEmbeddingModelConfigs.base(768).def,\n    schema: GoogleEmbeddingModelConfigs.base(768).schema,\n  },\n});\n\nconst Text_Embedding_001Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_001OptionsType = z.infer<typeof Text_Embedding_001Options>;\n\nclass Text_Embedding_001 extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_001OptionsType) {\n    super(Text_Embedding_001Schema, options);\n  }\n}\n\nexport {\n  Text_Embedding_001,\n  Text_Embedding_001Options,\n  Text_Embedding_001Schema,\n  Text_Embedding_001Literal,\n  type Text_Embedding_001OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { GoogleEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.google\";\nimport { GoogleEmbeddingModelModalities, GoogleEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_004Literal = \"text-embedding-004\";\nconst Text_Embedding_004_Description = \"text-embedding-004\";\n\nconst Text_Embedding_004Schema = EmbeddingModelSchema(GoogleEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_004Literal,\n  description: Text_Embedding_004_Description,\n  modalities: GoogleEmbeddingModelModalities,\n  maxInputTokens: 2048,\n  maxOutputTokens: 768,\n  config: {\n    def: GoogleEmbeddingModelConfigs.base(768).def,\n    schema: GoogleEmbeddingModelConfigs.base(768).schema,\n  },\n});\n\nconst Text_Embedding_004Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_004OptionsType = z.infer<typeof Text_Embedding_004Options>;\n\nclass Text_Embedding_004 extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_004OptionsType) {\n    super(Text_Embedding_004Schema, options);\n  }\n}\n\nexport {\n  Text_Embedding_004,\n  Text_Embedding_004Options,\n  Text_Embedding_004Schema,\n  Text_Embedding_004Literal,\n  type Text_Embedding_004OptionsType,\n};\n"]}