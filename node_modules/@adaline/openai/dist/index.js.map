{"version":3,"sources":["../src/configs/chat-model/common.config.chat-model.openai.ts","../src/configs/chat-model/base.config.chat-model.openai.ts","../src/configs/chat-model/o-series.config.chat-model.openai.ts","../src/configs/chat-model/response-schema.config.chat-model.openai.ts","../src/configs/chat-model/response-format.config.chat-model.openai.ts","../src/configs/embedding-model/common.config.embedding-model.openai.ts","../src/configs/embedding-model/base.config.embedding-model.openai.ts","../src/configs/embedding-model/dimensions.config.embedding-model.openai.ts","../src/configs/configs.openai.ts","../src/models/pricing.json","../src/provider/provider.openai.ts","../src/models/chat-models/types/roles.chat-model.openai.ts","../src/models/chat-models/types/modalities.chat-model.openai.ts","../src/models/chat-models/types/response.chat-model.openai.ts","../src/models/chat-models/types/request.chat-model.openai.ts","../src/models/chat-models/base-chat-model.openai.ts","../src/models/chat-models/gpt-3-5-turbo-0125.openai.ts","../src/models/chat-models/gpt-3-5-turbo-1106.openai.ts","../src/models/chat-models/gpt-3-5-turbo.openai.ts","../src/models/chat-models/gpt-4-0125-preview.openai.ts","../src/models/chat-models/gpt-4-0613.openai.ts","../src/models/chat-models/gpt-4-1106-preview.openai.ts","../src/models/chat-models/gpt-4-1.openai.ts","../src/models/chat-models/gpt-4-1-mini.openai.ts","../src/models/chat-models/gpt-4-1-nano.openai.ts","../src/models/chat-models/gpt-4-turbo-2024-04-09.openai.ts","../src/models/chat-models/gpt-4-turbo-preview.openai.ts","../src/models/chat-models/gpt-4-turbo.openai.ts","../src/models/chat-models/gpt-4.openai.ts","../src/models/chat-models/gpt-4o-2024-05-13.openai.ts","../src/models/chat-models/gpt-4o-2024-08-06.openai.ts","../src/models/chat-models/gpt-4o-mini-2024-07-18.openai.ts","../src/models/chat-models/gpt-4o-mini.openai.ts","../src/models/chat-models/gpt-4o.openai.ts","../src/models/chat-models/o1-2024-12-17.openai.ts","../src/models/chat-models/o1.openai.ts","../src/models/chat-models/o3-2025-04-16.openai.ts","../src/models/chat-models/o3.openai.ts","../src/models/chat-models/o3-mini.openai.ts","../src/models/chat-models/o3-mini-2025-01-31.openai.ts","../src/models/chat-models/o4-mini-2025-04-16.openai.ts","../src/models/chat-models/o4-mini.openai.ts","../src/models/embedding-models/types/modalitites.embedding-model.openai.ts","../src/models/embedding-models/types/response.embedding-model.openai.ts","../src/models/embedding-models/types/request.embedding-model.openai.ts","../src/models/embedding-models/base-embedding-model.openai.ts","../src/models/embedding-models/text-embedding-ada-002.openai.ts","../src/models/embedding-models/text-embedding-3-small.openai.ts","../src/models/embedding-models/text-embedding-3-large.openai.ts"],"names":["temperature","RangeConfigItem","CHAT_CONFIG","maxTokens","maxOutputTokens","stop","maxSequences","MultiStringConfigItem","topP","frequencyPenalty","presencePenalty","seed","logProbs","SelectBooleanConfigItem","topLogProbs","toolChoice","SelectStringConfigItem","ChatModelBaseConfigSchema","z","value","ChatModelBaseConfigDef","responseSchema","ObjectSchemaConfigItem","ResponseSchema","responseFormat","ChatModelResponseSchemaConfigDef","__spreadProps","__spreadValues","ChatModelResponseSchemaConfigSchema","reasoningEffort","ChatModelOSeriesConfigDef","ChatModelOSeriesConfigSchema","ChatModelResponseFormatConfigDef","ChatModelResponseFormatConfigSchema","encodingFormat","dimensions","maxDimensions","EmbeddingModelBaseConfigSchema","EmbeddingModelBaseConfigDef","EmbeddingModelDimensionsConfigSchema","EmbeddingModelDimensionsConfigDef","OpenAIChatModelConfigs","OpenAIEmbeddingModelConfigs","pricing_default","ProviderLiteral","OpenAI","GPT_3_5_TurboLiteral","GPT_3_5_Turbo","GPT_3_5_TurboOptions","GPT_3_5_TurboSchema","GPT_3_5_Turbo_0125Literal","GPT_3_5_Turbo_0125","GPT_3_5_Turbo_0125Options","GPT_3_5_Turbo_0125Schema","GPT_3_5_Turbo_1106Literal","GPT_3_5_Turbo_1106","GPT_3_5_Turbo_1106Options","GPT_3_5_Turbo_1106Schema","GPT_4_0125_PreviewLiteral","GPT_4_0125_Preview","GPT_4_0125_PreviewOptions","GPT_4_0125_PreviewSchema","GPT_4_0613Literal","GPT_4_0613","GPT_4_0613Options","GPT_4_0613Schema","GPT_4_1106_PreviewLiteral","GPT_4_1106_Preview","GPT_4_1106_PreviewOptions","GPT_4_1106_PreviewSchema","GPT_4_1Literal","GPT_4_1","GPT_4_1Options","GPT_4_1Schema","GPT_4_1_MiniLiteral","GPT_4_1_Mini","GPT_4_1_MiniOptions","GPT_4_1_MiniSchema","GPT_4_1_NanoLiteral","GPT_4_1_Nano","GPT_4_1_NanoOptions","GPT_4_1_NanoSchema","GPT_4_Turbo_2024_04_09Literal","GPT_4_Turbo_2024_04_09","GPT_4_Turbo_2024_04_09Options","GPT_4_Turbo_2024_04_09Schema","GPT_4_Turbo_PreviewLiteral","GPT_4_Turbo_Preview","GPT_4_Turbo_PreviewOptions","GPT_4_Turbo_PreviewSchema","GPT_4_TurboLiteral","GPT_4_Turbo","GPT_4_TurboOptions","GPT_4_TurboSchema","GPT_4Literal","GPT_4","GPT_4Options","GPT_4Schema","GPT_4o_2024_08_06Literal","GPT_4o_2024_08_06","GPT_4o_2024_08_06Options","GPT_4o_2024_08_06Schema","GPT_4o_MiniLiteral","GPT_4o_Mini","GPT_4o_MiniOptions","GPT_4o_MiniSchema","GPT_4oLiteral","GPT_4o","GPT_4oOptions","GPT_4oSchema","GPT_4o_Mini_2024_07_18Literal","GPT_4o_Mini_2024_07_18","GPT_4o_Mini_2024_07_18Options","GPT_4o_Mini_2024_07_18Schema","GPT_4o_2024_05_13Literal","GPT_4o_2024_05_13","GPT_4o_2024_05_13Options","GPT_4o_2024_05_13Schema","O1Literal","O1","O1Options","O1Schema","O1_2024_12_17Literal","O1_2024_12_17","O1_2024_12_17Options","O1_2024_12_17Schema","O3Mini2025_01_31Literal","O3Mini2025_01_31","O3Mini2025_01_31Options","O3Mini2025_01_31Schema","O3MiniLiteral","O3Mini","O3MiniOptions","O3MiniSchema","O3_2025_04_16Literal","O3_2025_04_16","O3_2025_04_16Options","O3_2025_04_16Schema","O3Literal","O3","O3Options","O3Schema","O4_Mini_2025_04_16Literal","O4_Mini_2025_04_16","O4_Mini_2025_04_16Options","O4_Mini_2025_04_16Schema","O4_MiniLiteral","O4_Mini","O4_MiniOptions","O4_MiniSchema","Text_Embedding_Ada002Literal","Text_Embedding_Ada002","Text_Embedding_Ada002_Options","Text_Embedding_Ada002Schema","Text_Embedding_3_SmallLiteral","Text_Embedding_3_Small","Text_Embedding_3_Small_Options","Text_Embedding_3_SmallSchema","Text_Embedding_3_LargeLiteral","Text_Embedding_3_Large","Text_Embedding_3_Large_Options","Text_Embedding_3_LargeSchema","acc","key","options","modelName","ProviderError","model","parsedOptions","OpenAIChatModelRoles","SystemRoleLiteral","UserRoleLiteral","AssistantRoleLiteral","ToolRoleLiteral","OpenAIChatModelRolesMap","OpenAIChatModelModalities","TextModalityLiteral","ImageModalityLiteral","ToolCallModalityLiteral","ToolResponseModalityLiteral","OpenAIChatModelModalitiesEnum","OpenAIChatModelTextModalities","OpenAIChatModelTextModalitiesEnum","OpenAIChatModelTextToolModalities","OpenAIChatModelTextToolModalitiesEnum","OpenAIBaseLogProb","OpenAILogProb","OpenAIToolCallsCompleteChatResponse","OpenAICompleteChatResponse","OpenAIToolCallsStreamChatResponse","OpenAIStreamChatResponse","OpenAIChatRequestTool","OpenAIChatRequestToolChoiceEnum","OpenAIChatRequestToolChoiceFunction","OpenAIChatRequestResponseFormat","OpenAIChatRequestTextContent","OpenAIChatRequestImageContent","OpenAIChatRequestToolCallContent","OpenAIChatRequestSystemMessage","OpenAIChatRequestUserMessage","OpenAIChatRequestAssistantMessage","OpenAIChatRequestToolMessage","OpenAIChatRequestMessage","OpenAIChatRequest","BaseChatModelOptions","BaseChatModel","modelSchema","urlWithoutTrailingSlash","responseHeaders","parseDuration","duration","regex","timeUnits","match","totalMs","unit","resetRequestsDelayMs","resetTokensDelayMs","shouldRetry","delayMs","messages","message","content","request","safeRequest","InvalidModelRequestError","parsedRequest","_config","config","Config","removeUndefinedEntries","toolCallMap","role","_content","c","Base64ImageContentTypeLiteral","getMimeTypeFromBase64","UrlImageContentTypeLiteral","assistantContent","toolCall","index","toolCallContent","toolResponse","tools","tool","_toolChoice","_parsedConfig","InvalidConfigError","parsedConfig","transformedConfig","def","paramKey","paramValue","configToolChoice","parsedMessages","parsedMessage","Message","InvalidMessagesError","textContent","toolCalls","imageContent","combinedContent","InvalidToolsError","parsedTool","Tool","__async","resolve","transformedMessages","transformedTools","response","safe","ModelResponseError","parsedResponse","createTextContent","createToolCallContent","usage","_logProbs","logProb","topLogProb","chunk","buffer","__asyncGenerator","_a","_b","data","lines","newBuffer","currentIndex","newlineIndex","line","jsonStr","structuredLine","partialResponse","createPartialTextMessage","createPartialToolCallMessage","error","headers","query","__yieldStar","sanitizedHeaders","GPT_3_5_Turbo_0125Description","ChatModelSchema","GPT_3_5_Turbo_1106Description","GPT_3_5_TurboDescription","GPT_4_0125_PreviewDescription","GPT_4_0613Description","GPT_4_1106_PreviewDescription","GPT_4_1Description","GPT_4_1_MiniDescription","GPT_4_1_NanoDescription","GPT_4_Turbo_2024_04_09Description","GPT_4_Turbo_PreviewDescription","GPT_4_TurboDescription","GPT_4Description","GPT_4o_2024_05_13Description","GPT_4o_2024_08_06Description","GPT_4o_MiniDescription","GPT_4oDescription","O1_2024_12_17Description","O1Description","O3_2025_04_16Description","O3Description","O3MiniDescription","O3Mini2025_01_31Description","O4_Mini_2025_04_16Description","O4_MiniDescription","OpenAIEmbeddingModelModalities","EmbeddingTextModalityLiteral","EmbeddingTokenModalityLiteral","OpenAIEmbeddingModelModalitiesEnum","OpenAIGetEmbeddingsResponse","OpenAIEmbeddingRequestInput","OpenAIEmbeddingRequest","BaseEmbeddingModelOptions","BaseEmbeddingModel","requests","embeddingRequests","embeddingFormat","_parsedRequests","EmbeddingRequests","InvalidEmbeddingRequestsError","Base64EmbeddingLiteral","FloatEmbeddingLiteral","embeddings","item","Text_Embedding_Ada002Description","EmbeddingModelSchema","Text_Embedding_3_SmallDescription","Text_Embedding_3_LargeDescription"],"mappings":";;;;;;2hDAEMA,IAAAA,EAAAA,CAAcC,wBAAgB,CAAA,CAClC,KAAO,CAAA,aAAA,CACP,KAAOC,CAAAA,oBAAAA,CAAY,WAAY,CAAA,KAAA,CAC/B,WAAaA,CAAAA,oBAAAA,CAAY,YAAY,WACrC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,CACL,CAAA,IAAA,CAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKC,CAAAA,EAAAA,CAAaC,CACjBH,EAAAA,wBAAAA,CAAgB,CACd,KAAO,CAAA,uBAAA,CACP,KAAOC,CAAAA,oBAAAA,CAAY,UAAW,CAAA,KAAA,CAC9B,WAAaA,CAAAA,oBAAAA,CAAY,UAAW,CAAA,WAAA,CACpC,GAAK,CAAA,CAAA,CACL,GAAKE,CAAAA,CAAAA,CACL,KAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEGC,CAAAA,EAAAA,CAAQC,GACZC,8BAAsB,CAAA,CACpB,KAAO,CAAA,MAAA,CACP,KAAOL,CAAAA,oBAAAA,CAAY,KAAKI,CAAY,CAAA,CAAE,KACtC,CAAA,WAAA,CAAaJ,oBAAY,CAAA,IAAA,CAAKI,CAAY,CAAA,CAAE,WAC5C,CAAA,GAAA,CAAKA,CACP,CAAC,CAEGE,CAAAA,EAAAA,CAAOP,yBAAgB,CAC3B,KAAA,CAAO,OACP,CAAA,KAAA,CAAOC,oBAAY,CAAA,KAAA,CAAM,KACzB,CAAA,WAAA,CAAaA,oBAAY,CAAA,KAAA,CAAM,WAC/B,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,EACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKO,EAAmBR,CAAAA,wBAAAA,CAAgB,CACvC,KAAA,CAAO,mBACP,CAAA,KAAA,CAAOC,oBAAY,CAAA,iBAAA,CAAkB,MACrC,WAAaA,CAAAA,oBAAAA,CAAY,iBAAkB,CAAA,WAAA,CAC3C,GAAK,CAAA,CAAA,CAAA,CACL,IAAK,CACL,CAAA,IAAA,CAAM,GACN,CAAA,OAAA,CAAS,CACX,CAAC,EAEKQ,EAAkBT,CAAAA,wBAAAA,CAAgB,CACtC,KAAA,CAAO,kBACP,CAAA,KAAA,CAAOC,oBAAY,CAAA,gBAAA,CAAiB,KACpC,CAAA,WAAA,CAAaA,oBAAY,CAAA,gBAAA,CAAiB,WAC1C,CAAA,GAAA,CAAK,GACL,GAAK,CAAA,CAAA,CACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEKS,EAAOV,CAAAA,wBAAAA,CAAgB,CAC3B,KAAA,CAAO,MACP,CAAA,KAAA,CAAOC,qBAAY,IAAK,CAAA,KAAA,CACxB,WAAaA,CAAAA,oBAAAA,CAAY,IAAK,CAAA,WAAA,CAC9B,GAAK,CAAA,CAAA,CACL,GAAK,CAAA,GAAA,CACL,IAAM,CAAA,CAAA,CACN,OAAS,CAAA,CACX,CAAC,CAEKU,CAAAA,EAAAA,CAAWC,gCAAwB,CAAA,CACvC,KAAO,CAAA,UAAA,CACP,KAAOX,CAAAA,oBAAAA,CAAY,SAAU,CAAA,KAAA,CAC7B,WAAaA,CAAAA,oBAAAA,CAAY,SAAU,CAAA,WAAA,CACnC,QAAS,CACX,CAAA,CAAC,CAEKY,CAAAA,EAAAA,CAAcb,wBAAgB,CAAA,CAClC,KAAO,CAAA,cAAA,CACP,KAAOC,CAAAA,oBAAAA,CAAY,aAAc,CAAA,KAAA,CACjC,WAAaA,CAAAA,oBAAAA,CAAY,cAAc,WACvC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,EACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAAS,CACX,CAAC,CAEKa,CAAAA,EAAAA,CAAaC,+BAAuB,CAAA,CACxC,MAAO,aACP,CAAA,KAAA,CAAO,aACP,CAAA,WAAA,CACE,uLACF,CAAA,OAAA,CAAS,MACT,CAAA,OAAA,CAAS,CAAC,MAAA,CAAQ,UAAY,CAAA,MAAM,CACtC,CAAC,EChFKC,IAAAA,CAAAA,CAA4B,CAACb,CAAAA,CAAyBE,CAC1DY,GAAAA,KAAAA,CAAE,OAAO,CACP,WAAA,CAAalB,EAAY,CAAA,MAAA,CACzB,SAAWG,CAAAA,EAAAA,CAAUC,CAAe,CAAE,CAAA,MAAA,CACtC,IAAMC,CAAAA,EAAAA,CAAKC,CAAY,CAAA,CAAE,MACzB,CAAA,IAAA,CAAME,EAAK,CAAA,MAAA,CACX,gBAAkBC,CAAAA,EAAAA,CAAiB,MACnC,CAAA,eAAA,CAAiBC,GAAgB,MACjC,CAAA,IAAA,CAAMC,EAAK,CAAA,MAAA,CAAO,SAAWQ,CAAAA,CAAAA,EAAWA,CAAU,GAAA,CAAA,CAAI,KAAYA,CAAAA,CAAAA,CAAM,CACxE,CAAA,QAAA,CAAUP,EAAS,CAAA,MAAA,CACnB,YAAaE,EAAY,CAAA,MAAA,CACzB,UAAYC,CAAAA,EAAAA,CAAW,MACzB,CAAC,CAEGK,CAAAA,CAAAA,CAAyB,CAAChB,CAAAA,CAAyBE,CACtD,IAAA,CACC,WAAaN,CAAAA,EAAAA,CAAY,IACzB,SAAWG,CAAAA,EAAAA,CAAUC,CAAe,CAAA,CAAE,GACtC,CAAA,IAAA,CAAMC,GAAKC,CAAY,CAAA,CAAE,GACzB,CAAA,IAAA,CAAME,EAAK,CAAA,GAAA,CACX,iBAAkBC,EAAiB,CAAA,GAAA,CACnC,eAAiBC,CAAAA,EAAAA,CAAgB,GACjC,CAAA,IAAA,CAAMC,EAAK,CAAA,GAAA,CACX,QAAUC,CAAAA,EAAAA,CAAS,GACnB,CAAA,WAAA,CAAaE,EAAY,CAAA,GAAA,CACzB,WAAYC,EAAW,CAAA,GACzB,CCzCF,ECKMM,IAAAA,EAAAA,CAAiBC,+BAAuB,CAAA,CAC5C,KAAO,CAAA,iBAAA,CACP,MAAOpB,oBAAY,CAAA,eAAA,CAAgB,KACnC,CAAA,WAAA,CAAaA,oBAAY,CAAA,eAAA,CAAgB,YACzC,YAAcqB,CAAAA,oBAChB,CAAC,CAAA,CAEKC,EAAiBR,CAAAA,+BAAAA,CAAuB,CAC5C,KAAO,CAAA,iBAAA,CACP,KAAOd,CAAAA,oBAAAA,CAAY,2BAA4B,CAAA,KAAA,CAC/C,WAAaA,CAAAA,oBAAAA,CAAY,2BAA4B,CAAA,WAAA,CACrD,OAAS,CAAA,MAAA,CACT,OAAS,CAAA,CAAC,OAAQ,aAAe,CAAA,aAAa,CAChD,CAAC,CAEKuB,CAAAA,EAAAA,CAAmC,CAACrB,CAAAA,CAAyBE,CAA0BoB,GAAAA,CAAAA,CAAAC,CAAA,CAAA,EAAA,CACxFP,CAAuBhB,CAAAA,CAAAA,CAAiBE,CAAY,CADoC,CAAA,CAAA,CAE3F,cAAgBkB,CAAAA,EAAAA,CAAe,GAC/B,CAAA,cAAA,CAAgBH,EAAe,CAAA,GACjC,CAEMO,CAAAA,CAAAA,EAAAA,CAAsC,CAACxB,CAAAA,CAAyBE,CACpEW,GAAAA,CAAAA,CAA0Bb,EAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CAC9D,cAAgBkB,CAAAA,EAAAA,CAAe,MAC/B,CAAA,cAAA,CAAgBH,EAAe,CAAA,MACjC,CAAC,EDzBGrB,IAAAA,EAAAA,CAAcC,yBAAgB,CAClC,KAAA,CAAO,aACP,CAAA,KAAA,CAAOC,oBAAY,CAAA,WAAA,CAAY,KAC/B,CAAA,WAAA,CAAaA,oBAAY,CAAA,WAAA,CAAY,WACrC,CAAA,GAAA,CAAK,CACL,CAAA,GAAA,CAAK,EACL,IAAM,CAAA,GAAA,CACN,OAAS,CAAA,CACX,CAAC,CAAA,CAEK2B,EAAkBb,CAAAA,+BAAAA,CAAuB,CAC7C,KAAA,CAAO,kBACP,CAAA,KAAA,CAAO,kBACP,CAAA,WAAA,CACE,kKACF,OAAS,CAAA,QAAA,CACT,OAAS,CAAA,CAAC,KAAO,CAAA,QAAA,CAAU,MAAM,CACnC,CAAC,CAAA,CACKc,EAA4B,CAAA,CAAC1B,CAAyBE,CAAAA,CAAAA,GAA0BoB,EAAAC,CAAA,CAAA,EAAA,CACjFF,EAAiCrB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAA,CADmB,CAEpF,WAAaN,CAAAA,EAAAA,CAAY,GACzB,CAAA,eAAA,CAAiB6B,EAAgB,CAAA,GACnC,GAEME,EAA+B,CAAA,CAAC3B,CAAyBE,CAAAA,CAAAA,GAC7DsB,EAAoCxB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CACxE,WAAaN,CAAAA,EAAAA,CAAY,MACzB,CAAA,eAAA,CAAiB6B,GAAgB,MACnC,CAAC,EE7BH,IAAML,EAAiBR,CAAAA,+BAAAA,CAAuB,CAC5C,KAAA,CAAO,kBACP,KAAOd,CAAAA,oBAAAA,CAAY,eAAgB,CAAA,KAAA,CACnC,WAAaA,CAAAA,oBAAAA,CAAY,eAAgB,CAAA,WAAA,CACzC,OAAS,CAAA,MAAA,CACT,OAAS,CAAA,CAAC,MAAQ,CAAA,aAAa,CACjC,CAAC,CAAA,CAEK8B,EAAmC,CAAA,CAAC5B,CAAyBE,CAAAA,CAAAA,GAA0BoB,EAAAC,CAAA,CAAA,EAAA,CACxFP,CAAuBhB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAA,CADoC,CAE3F,cAAgBkB,CAAAA,EAAAA,CAAe,GACjC,CAAA,CAAA,CAEMS,EAAsC,CAAA,CAAC7B,CAAyBE,CAAAA,CAAAA,GACpEW,CAA0Bb,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAAE,MAAO,CAAA,CAC9D,eAAgBkB,EAAe,CAAA,MACjC,CAAC,MClBGU,EAAiBlB,CAAAA,+BAAAA,CAAuB,CAC5C,KAAA,CAAO,iBACP,CAAA,KAAA,CAAO,iBACP,CAAA,WAAA,CAAa,oDACb,CAAA,OAAA,CAAS,OACT,CAAA,OAAA,CAAS,CAAC,OAAA,CAAS,QAAQ,CAC7B,CAAC,CAEKmB,CAAAA,EAAAA,CAAcC,CAClBnC,EAAAA,wBAAAA,CAAgB,CACd,KAAO,CAAA,YAAA,CACP,KAAO,CAAA,YAAA,CACP,WAAa,CAAA,yDAAA,CACb,IAAK,CACL,CAAA,GAAA,CAAKmC,CACL,CAAA,IAAA,CAAM,CACN,CAAA,OAAA,CAASA,CACX,CAAC,ECfH,IAAMC,EAAiC,CAAA,IACrCnB,KAAE,CAAA,MAAA,CAAO,CACP,cAAgBgB,CAAAA,EAAAA,CAAe,MACjC,CAAC,CAEGI,CAAAA,EAAAA,CAA8B,KACjC,CACC,cAAgBJ,CAAAA,EAAAA,CAAe,GACjC,CAAA,ECTIK,IAAAA,EAAAA,CAAwCH,GAC5CC,EAA+B,EAAA,CAAE,MAAO,CAAA,CACtC,UAAYF,CAAAA,EAAAA,CAAWC,CAAa,CAAA,CAAE,MACxC,CAAC,CAEGI,CAAAA,EAAAA,CAAqCJ,CACxCV,EAAAA,CAAAA,CAAAC,EAAA,EACIW,CAAAA,EAAAA,EADJ,CAAA,CAAA,CAEC,UAAYH,CAAAA,EAAAA,CAAWC,CAAa,CAAA,CAAE,GACxC,CAAA,ECKIK,IAAAA,CAAAA,CAAyB,CAC7B,IAAA,CAAM,CAACrC,CAAyBE,CAAAA,CAAAA,IAA0B,CACxD,GAAA,CAAKc,CAAuBhB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CACzD,MAAQW,CAAAA,CAAAA,CAA0Bb,CAAiBE,CAAAA,CAAY,CACjE,CAAA,CAAA,CACA,eAAgB,CAACF,CAAAA,CAAyBE,CAA0B,IAAA,CAClE,GAAK0B,CAAAA,EAAAA,CAAiC5B,CAAiBE,CAAAA,CAAY,CACnE,CAAA,MAAA,CAAQ2B,EAAoC7B,CAAAA,CAAAA,CAAiBE,CAAY,CAC3E,GACA,cAAgB,CAAA,CAACF,CAAyBE,CAAAA,CAAAA,IAA0B,CAClE,GAAA,CAAKmB,EAAiCrB,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CACnE,MAAQsB,CAAAA,EAAAA,CAAoCxB,CAAiBE,CAAAA,CAAY,CAC3E,CACA,CAAA,CAAA,OAAA,CAAS,CAACF,CAAAA,CAAyBE,CAA0B,IAAA,CAC3D,IAAKwB,EAA0B1B,CAAAA,CAAAA,CAAiBE,CAAY,CAAA,CAC5D,MAAQyB,CAAAA,EAAAA,CAA6B3B,EAAiBE,CAAY,CACpE,CACF,CAAA,CAAA,CAEMoC,CAA8B,CAAA,CAClC,IAAM,CAAA,KAAO,CACX,GAAA,CAAKJ,EAA4B,EAAA,CACjC,MAAQD,CAAAA,EAAAA,EACV,CACA,CAAA,CAAA,UAAA,CAAaD,CAA2B,GAAA,CACtC,GAAKI,CAAAA,EAAAA,CAAkCJ,CAAa,CAAA,CACpD,MAAQG,CAAAA,EAAAA,CAAqCH,CAAa,CAC5D,CACF,CAAA,EC7CA,IAAAO,EAAA,CACE,oBAAA,CAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,OAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,oBAAA,CAAsB,CACpB,SAAa,CAAA,oBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,eAAA,CAAiB,CACf,SAAA,CAAa,eACb,CAAA,QAAA,CAAY,MACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,oBAAA,CAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,YAAA,CAAc,CACZ,SAAA,CAAa,YACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,OAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,oBAAsB,CAAA,CACpB,UAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,wBAAA,CAA0B,CACxB,SAAA,CAAa,wBACb,CAAA,QAAA,CAAY,MACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,qBAAA,CAAuB,CACrB,SAAA,CAAa,qBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,UAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,aAAe,CAAA,CACb,SAAa,CAAA,aAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,OAAA,CAAS,CACP,SAAa,CAAA,OAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,mBAAqB,CAAA,CACnB,SAAa,CAAA,mBAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,CAAA,CACxB,sBAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,mBAAqB,CAAA,CACnB,SAAa,CAAA,mBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,GAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,wBAA0B,CAAA,CACxB,SAAa,CAAA,wBAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,aAAA,CAAe,CACb,SAAa,CAAA,aAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,GAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,QAAA,CAAU,CACR,SAAA,CAAa,QACb,CAAA,QAAA,CAAY,MACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,CAAA,CACxB,sBAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,eAAiB,CAAA,CACf,SAAa,CAAA,eAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,qBAAyB,CAAA,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,EAAM,CAAA,CACJ,SAAa,CAAA,IAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,KACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,EAAA,CACxB,sBAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,qBAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,SAAW,CAAA,CACT,SAAa,CAAA,SAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,GAAA,CACxB,sBAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,gBAAiB,CACf,SAAA,CAAa,eACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAA,CAAa,CACb,CAAA,SAAA,CAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,EAAA,CAAM,CACJ,SAAA,CAAa,IACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,qBAAsB,CACpB,SAAA,CAAa,oBACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,GACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,SAAW,CAAA,CACT,SAAa,CAAA,SAAA,CACb,SAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,IAAQ,CAAA,CACN,oBAAwB,CAAA,GAAA,CACxB,sBAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,SAAW,CAAA,CACT,SAAa,CAAA,SAAA,CACb,QAAY,CAAA,KAAA,CACZ,WAAe,CAAA,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,CACxB,CAAA,qBAAA,CAAyB,CAC3B,CACF,CACF,CACF,CACF,CACA,CAAA,cAAA,CAAgB,CACd,SAAA,CAAa,cACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,UAAa,IACb,CAAA,MAAA,CAAU,CACR,IAAA,CAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,GAC3B,CACF,CACF,CACF,CACF,CAAA,CACA,eAAgB,CACd,SAAA,CAAa,cACb,CAAA,QAAA,CAAY,KACZ,CAAA,WAAA,CAAe,CACb,CACE,SAAa,CAAA,CAAA,CACb,SAAa,CAAA,IAAA,CACb,MAAU,CAAA,CACR,KAAQ,CACN,oBAAA,CAAwB,EACxB,CAAA,qBAAA,CAAyB,EAC3B,CACF,CACF,CACF,CACF,CACF,CAAA,CC3ZA,IAAMC,EAAkB,CAAA,QAAA,CAClBC,CAAN,CAAA,KAAoI,CAApI,WAAA,EAAA,CACE,IAAS,CAAA,OAAA,CAAU,IACnB,CAAA,IAAA,CAAS,IAAOD,CAAAA,EAAAA,CAGhB,KAAiB,kBAOb,CAAA,CACF,CAAQE,EAAoB,EAAG,CAC7B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAiB,EAAG,CAC1B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAc,EAAG,CACvB,KAAA,CAAcC,GACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAmB,EAAG,CAC5B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACA,CAAA,CAAQC,EAAmB,EAAG,CAC5B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAA6B,EAAG,CACtC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAA0B,EAAG,CACnC,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAkB,EAAG,CAC3B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAY,EAAG,CACrB,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAAkB,EAAG,CAC3B,KAAcC,CAAAA,EAAAA,CACd,aAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAa,EAAG,CACtB,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,EACA,CAAQC,EAA6B,EAAG,CACtC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAwB,EAAG,CACjC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAS,EAAG,CAClB,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,GACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAoB,EAAG,CAC7B,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAuB,EAAG,CAChC,KAAA,CAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAa,EAAG,CACtB,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAAoB,EAAG,CAC7B,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAS,EAAG,CAClB,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACA,CAAA,CAAQC,EAAyB,EAAG,CAClC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAAc,EAAG,CACvB,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CACF,CAEA,CAAA,IAAA,CAAiB,uBAOb,CAAA,CACF,CAAQC,EAA4B,EAAG,CACrC,MAAcC,EACd,CAAA,YAAA,CAAqBC,EACrB,CAAA,WAAA,CAAoBC,EACtB,CAAA,CACA,CAAQC,EAA6B,EAAG,CACtC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,YAAoBC,EACtB,CAAA,CACA,CAAQC,EAA6B,EAAG,CACtC,KAAcC,CAAAA,EAAAA,CACd,YAAqBC,CAAAA,EAAAA,CACrB,WAAoBC,CAAAA,EACtB,CACF,EAAA,CAEA,mBAA8B,CAC5B,OAAO,MAAO,CAAA,IAAA,CAAK,IAAK,CAAA,kBAAkB,CAC5C,CAEA,gBAAwD,EAAA,CACtD,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,kBAAkB,CAAE,CAAA,MAAA,CAC1C,CAACC,CAAAA,CAAKC,CACJD,IAAAA,CAAAA,CAAIC,CAAG,CAAA,CAAI,IAAK,CAAA,kBAAA,CAAmBA,CAAG,CAAA,CAAE,WACjCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,SAAA,CAAUE,CAAyB,CAAA,CACjC,IAAMC,CAAAA,CAAYD,CAAQ,CAAA,SAAA,CAC1B,GAAI,EAAEC,CAAa,IAAA,IAAA,CAAK,oBACtB,MAAM,IAAIC,sBAAc,CAAA,CACtB,IAAM,CAAA,CAAA,mBAAA,EAAsBD,CAAS,CAAA,UAAA,CAAA,CACrC,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,mBAAA,EAAsBA,CAAS,CAAA;AAAA,WAAA,EAC3C,KAAK,iBAAkB,EAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC7C,CAAC,EAGH,IAAME,CAAAA,CAAQ,KAAK,kBAAmBF,CAAAA,CAAS,EAAE,KAC3CG,CAAAA,CAAAA,CAAgB,KAAK,kBAAmBH,CAAAA,CAAS,EAAE,YAAa,CAAA,KAAA,CAAMD,CAAO,CACnF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CAEA,sBAAA,EAAmC,CACjC,OAAO,MAAA,CAAO,KAAK,IAAK,CAAA,uBAAuB,CACjD,CAEA,qBAAA,EAAkE,CAChE,OAAO,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,uBAAuB,CAAE,CAAA,MAAA,CAC/C,CAACN,CAAKC,CAAAA,CAAAA,IACJD,EAAIC,CAAG,CAAA,CAAI,KAAK,uBAAwBA,CAAAA,CAAG,EAAE,WACtCD,CAAAA,CAAAA,CAAAA,CAET,EACF,CACF,CAEA,cAAeE,CAAAA,CAAAA,CAA8B,CAC3C,IAAMC,CAAAA,CAAYD,EAAQ,SAC1B,CAAA,GAAI,EAAEC,CAAa,IAAA,IAAA,CAAK,yBACtB,MAAM,IAAIC,uBAAc,CACtB,IAAA,CAAM,2BAA2BD,CAAS,CAAA,UAAA,CAAA,CAC1C,MAAO,IAAI,KAAA,CAAM,2BAA2BA,CAAS,CAAA;AAAA,WAChD,EAAA,IAAA,CAAK,sBAAuB,EAAA,CAAE,IAAK,CAAA,IAAI,CAAC,CAAG,CAAA,CAAA,CAClD,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAQ,KAAK,uBAAwBF,CAAAA,CAAS,CAAE,CAAA,KAAA,CAChDG,CAAgB,CAAA,IAAA,CAAK,uBAAwBH,CAAAA,CAAS,CAAE,CAAA,YAAA,CAAa,KAAMD,CAAAA,CAAO,CACxF,CAAA,OAAO,IAAIG,CAAMC,CAAAA,CAAa,CAChC,CACF,EAnOM3H,CAAAA,CAGY,OAAU,CAAA,2BAAA,CCN5B,IAAM4H,CAAuBvJ,CAAAA,KAAAA,CAAE,IAAK,CAAA,CAACwJ,uBAAmBC,CAAAA,qBAAAA,CAAiBC,2BAAsBC,qBAAe,CAAC,CAEzGC,CAAAA,CAAAA,CAA0B,CAC9B,MAAA,CAAQJ,uBACR,CAAA,IAAA,CAAMC,qBACN,CAAA,SAAA,CAAWC,0BACX,CAAA,IAAA,CAAMC,qBACR,ECNA,IAAME,EAA+D,CACnEC,yBAAAA,CACAC,0BACAC,CAAAA,6BAAAA,CACAC,iCACF,CAAA,CAEMC,CAAgClK,CAAAA,KAAAA,CAAE,IAAK,CAAA,CAC3C8J,yBACAC,CAAAA,0BAAAA,CACAC,6BACAC,CAAAA,iCACF,CAAC,CAEKE,CAAAA,EAAAA,CAAmE,CAACL,yBAAmB,CAEvFM,CAAAA,EAAAA,CAAoCpK,KAAE,CAAA,IAAA,CAAK,CAAC8J,yBAAmB,CAAC,CAAA,CAEhEO,CAAuE,CAAA,CAC3EP,0BACAE,6BACAC,CAAAA,iCACF,CAEMK,CAAAA,CAAAA,CAAwCtK,KAAE,CAAA,IAAA,CAAK,CAAC8J,yBAAAA,CAAqBE,6BAAyBC,CAAAA,iCAA2B,CAAC,EC3BhI,IAAMM,EAAoBvK,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACjC,KAAOA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAChB,OAASA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAClB,MAAOA,KAAE,CAAA,KAAA,CAAMA,KAAE,CAAA,MAAA,EAAQ,CAAA,CAAE,QAAS,EACtC,CAAC,CAAA,CAEKwK,EAAgBxK,CAAAA,KAAAA,CACnB,MAAO,CAAA,CACN,QAASA,KACN,CAAA,KAAA,CACCuK,EAAkB,CAAA,MAAA,CAAO,CACvB,YAAA,CAAcvK,KAAE,CAAA,KAAA,CAAMuK,EAAiB,CACzC,CAAC,CACH,CACC,CAAA,QAAA,GACA,QAAS,EAAA,CACZ,OAASvK,CAAAA,KAAAA,CACN,KACCuK,CAAAA,EAAAA,CAAkB,MAAO,CAAA,CACvB,YAAcvK,CAAAA,KAAAA,CAAE,KAAMuK,CAAAA,EAAiB,CACzC,CAAC,CACH,CACC,CAAA,QAAA,EACA,CAAA,QAAA,EACL,CAAC,CACA,CAAA,QAAA,EAEGE,CAAAA,EAAAA,CAAsCzK,KAAE,CAAA,KAAA,CAC5CA,KAAE,CAAA,MAAA,CAAO,CACP,EAAIA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACpB,CAAA,IAAA,CAAMA,KAAE,CAAA,IAAA,CAAK,CAAC,UAAU,CAAC,CAAA,CACzB,SAAUA,KAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,KAAE,CAAA,MAAA,EACR,CAAA,SAAA,CAAWA,KAAE,CAAA,MAAA,EACf,CAAC,CACH,CAAC,CACH,CAEM0K,CAAAA,EAAAA,CAA6B1K,KAAE,CAAA,MAAA,CAAO,CAC1C,EAAA,CAAIA,KAAE,CAAA,MAAA,EACN,CAAA,MAAA,CAAQA,KAAE,CAAA,OAAA,CAAQ,iBAAiB,CAAA,CACnC,QAASA,KAAE,CAAA,MAAA,EACX,CAAA,KAAA,CAAOA,KAAE,CAAA,MAAA,EACT,CAAA,kBAAA,CAAoBA,KAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAC/B,CAAA,OAAA,CAASA,MAAE,KACTA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACP,KAAOA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAChB,OAASA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CAChB,IAAMA,CAAAA,KAAAA,CAAE,QACR,CAAA,OAAA,CAASA,KAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAAW,CAAA,QAAA,EAC/B,CAAA,UAAA,CAAYyK,EAAoC,CAAA,QAAA,EAChD,CAAA,OAAA,CAASzK,MAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAC1C,CAAC,CAAA,CACD,QAAUwK,CAAAA,EAAAA,CAAc,QAAS,EAAA,CACjC,aAAexK,CAAAA,KAAAA,CAAE,QACnB,CAAC,CACH,CAAA,CACA,KAAOA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACd,aAAeA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CACxB,iBAAmBA,CAAAA,KAAAA,CAAE,QACrB,CAAA,YAAA,CAAcA,KAAE,CAAA,MAAA,EAClB,CAAC,CACH,CAAC,CAGK2K,CAAAA,EAAAA,CAAoC3K,KAAE,CAAA,KAAA,CAC1CA,KAAE,CAAA,MAAA,CAAO,CACP,KAAOA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CACtB,EAAIA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,GACtB,IAAMA,CAAAA,KAAAA,CAAE,IAAK,CAAA,CAAC,UAAU,CAAC,CAAE,CAAA,QAAA,EAC3B,CAAA,QAAA,CAAUA,KACP,CAAA,MAAA,CAAO,CACN,IAAA,CAAMA,MAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EACxB,CAAA,SAAA,CAAWA,KAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EACxB,CAAC,EACA,QAAS,EACd,CAAC,CACH,CAEM4K,CAAAA,EAAAA,CAA2B5K,KAAE,CAAA,MAAA,CAAO,CACxC,EAAA,CAAIA,KAAE,CAAA,MAAA,EACN,CAAA,MAAA,CAAQA,MAAE,MAAO,EAAA,CACjB,OAASA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAClB,KAAOA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAChB,kBAAoBA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,UAAW,CAAA,QAAA,EAC1C,CAAA,OAAA,CAASA,KAAE,CAAA,KAAA,CACTA,KAAE,CAAA,MAAA,CAAO,CACP,KAAA,CAAOA,KAAE,CAAA,MAAA,EACT,CAAA,KAAA,CAAOA,MACJ,MAAO,CAAA,CACN,OAASA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CACxC,UAAY2K,CAAAA,EAAAA,CAAkC,QAAS,EAAA,CACvD,QAAS3K,KAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAAW,CAAA,QAAA,EACjC,CAAC,CACA,CAAA,EAAA,CAAGA,KAAE,CAAA,MAAA,CAAO,EAAE,CAAC,CAClB,CAAA,QAAA,CAAUwK,EAAc,CAAA,QAAA,EACxB,CAAA,aAAA,CAAexK,KAAE,CAAA,MAAA,EAAS,CAAA,QAAA,EAC5B,CAAC,CACH,CAAA,CACA,MAAOA,KACJ,CAAA,MAAA,CAAO,CACN,aAAA,CAAeA,KAAE,CAAA,MAAA,GACjB,iBAAmBA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAC5B,YAAcA,CAAAA,KAAAA,CAAE,QAClB,CAAC,CACA,CAAA,QAAA,EACA,CAAA,QAAA,EACL,CAAC,EC3GD,IAAM6K,GAAwB7K,KAAE,CAAA,MAAA,CAAO,CACrC,IAAA,CAAMA,KAAE,CAAA,OAAA,CAAQ,UAAU,CAAA,CAC1B,QAAUA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACjB,IAAMA,CAAAA,KAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,WAAaA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAC/B,CAAA,MAAA,CAAQA,MAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAC7B,UAAYA,CAAAA,KAAAA,CAAE,GAAI,EACpB,CAAC,CACH,CAAC,CAAA,CAGK8K,EAAkC9K,CAAAA,KAAAA,CAAE,KAAK,CAAC,MAAA,CAAQ,MAAQ,CAAA,UAAU,CAAC,CAAA,CAGrE+K,EAAsC/K,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACnD,IAAMA,CAAAA,KAAAA,CAAE,OAAQ,CAAA,UAAU,EAC1B,QAAUA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACjB,IAAMA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACxB,CAAC,CACH,CAAC,EAGKgL,EAAkChL,CAAAA,KAAAA,CACrC,MAAO,CAAA,CACN,IAAMA,CAAAA,KAAAA,CAAE,IAAK,CAAA,CAAC,MAAQ,CAAA,aAAa,CAAC,CACtC,CAAC,CAAA,CACA,GACCA,KAAE,CAAA,MAAA,CAAO,CACP,IAAA,CAAMA,KAAE,CAAA,OAAA,CAAQ,aAAa,CAAA,CAC7B,WAAaA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACpB,IAAMA,CAAAA,KAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACtB,WAAaA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAC/B,CAAA,MAAA,CAAQA,MAAE,OAAQ,EAAA,CAAE,QAAS,EAAA,CAC7B,MAAQA,CAAAA,KAAAA,CAAE,GAAI,EAChB,CAAC,CACH,CAAC,CACH,CAGIiL,CAAAA,EAAAA,CAA+BjL,MAAE,MAAO,CAAA,CAC5C,IAAMA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACtB,CAAA,IAAA,CAAMA,KAAE,CAAA,OAAA,CAAQ,MAAM,CACxB,CAAC,CAGKkL,CAAAA,EAAAA,CAAgClL,KAAE,CAAA,MAAA,CAAO,CAC7C,IAAA,CAAMA,KAAE,CAAA,OAAA,CAAQ,WAAW,CAAA,CAC3B,SAAWA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CAClB,IAAKA,KAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,GAAA,CAAI,CAAC,CAAA,CAC3B,MAAQA,CAAAA,KAAAA,CAAE,IAAK,CAAA,CAAC,KAAO,CAAA,MAAA,CAAQ,MAAM,CAAC,CAAA,CAAE,QAAS,EACnD,CAAC,CACH,CAAC,CAAA,CAGKmL,EAAmCnL,CAAAA,KAAAA,CAAE,MAAO,CAAA,CAChD,EAAIA,CAAAA,KAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CACpB,IAAMA,CAAAA,KAAAA,CAAE,OAAQ,CAAA,UAAU,CAC1B,CAAA,QAAA,CAAUA,KAAE,CAAA,MAAA,CAAO,CACjB,IAAA,CAAMA,MAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CACtB,CAAA,SAAA,CAAWA,KAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAC7B,CAAC,CACH,CAAC,CAGKoL,CAAAA,EAAAA,CAAiCpL,KAAE,CAAA,MAAA,CAAO,CAC9C,IAAA,CAAMA,KAAE,CAAA,OAAA,CAAQ,QAAQ,CAAA,CACxB,OAASA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CAAE,EAAGA,CAAAA,KAAAA,CAAE,KAAMiL,CAAAA,EAA4B,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAC5E,CAAC,CAGKI,CAAAA,EAAAA,CAA+BrL,MAAE,MAAO,CAAA,CAC5C,IAAMA,CAAAA,KAAAA,CAAE,OAAQ,CAAA,MAAM,CACtB,CAAA,OAAA,CAASA,KACN,CAAA,MAAA,EACA,CAAA,GAAA,CAAI,CAAC,CAAA,CACL,GAAGA,KAAE,CAAA,KAAA,CAAMA,KAAE,CAAA,KAAA,CAAM,CAACiL,EAAAA,CAA8BC,EAA6B,CAAC,CAAC,CAAA,CAAE,GAAI,CAAA,CAAC,CAAC,CAC9F,CAAC,CAGKI,CAAAA,EAAAA,CAAoCtL,KAAE,CAAA,MAAA,CAAO,CACjD,IAAA,CAAMA,KAAE,CAAA,OAAA,CAAQ,WAAW,CAAA,CAC3B,OAASA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CAAE,EAAGA,CAAAA,KAAAA,CAAE,KAAMiL,CAAAA,EAA4B,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAE,CAAA,QAAA,EAC5E,CAAA,UAAA,CAAYjL,MAAE,KAAMmL,CAAAA,EAAgC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EACxE,CAAC,CAAA,CAGKI,EAA+BvL,CAAAA,KAAAA,CAAE,MAAO,CAAA,CAC5C,KAAMA,KAAE,CAAA,OAAA,CAAQ,MAAM,CAAA,CACtB,YAAcA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAC9B,CAAA,OAAA,CAASA,KAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAC,CAC3B,CAAC,CAGKwL,CAAAA,EAAAA,CAA2BxL,KAAE,CAAA,KAAA,CAAM,CACvCoL,EAAAA,CACAC,EACAC,CAAAA,EAAAA,CACAC,EACF,CAAC,EAGKE,EAAoBzL,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACjC,KAAOA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EACzB,CAAA,QAAA,CAAUA,MAAE,KAAMwL,CAAAA,EAAwB,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CACjD,iBAAmBxL,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAA,CAAE,CAAE,CAAA,GAAA,CAAI,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACxD,CAAA,QAAA,CAAUA,KAAE,CAAA,OAAA,EAAU,CAAA,QAAA,EAAW,CAAA,QAAA,EACjC,CAAA,YAAA,CAAcA,MAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,CAAE,CAAA,GAAA,CAAI,EAAE,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAC5D,qBAAuBA,CAAAA,KAAAA,CAAE,QAAS,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAC7D,gBAAkBA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAA,CAAE,EAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EACvD,CAAA,eAAA,CAAiBgL,EAAgC,CAAA,QAAA,EACjD,CAAA,IAAA,CAAMhL,KAAE,CAAA,MAAA,GAAS,QAAS,EAAA,CAAE,QAAS,EAAA,CACrC,IAAMA,CAAAA,KAAAA,CAAE,QAAS,CAAA,EAAA,CAAGA,KAAE,CAAA,KAAA,CAAMA,KAAE,CAAA,MAAA,EAAQ,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EAC3D,CAAA,WAAA,CAAaA,KAAE,CAAA,MAAA,EAAS,CAAA,GAAA,CAAI,CAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAAE,QAAS,EAAA,CAC1D,KAAOA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,CAAA,CAAC,EAAE,GAAI,CAAA,CAAC,CAAE,CAAA,QAAA,EAAW,CAAA,QAAA,EAC3C,CAAA,KAAA,CAAOA,KAAE,CAAA,KAAA,CAAM6K,EAAqB,CAAA,CAAE,QAAS,EAAA,CAC/C,YAAaC,EAAgC,CAAA,EAAA,CAAGC,EAAmC,CAAA,CAAE,QAAS,EAChG,CAAC,ECtDKW,IAAAA,CAAAA,CAAuB1L,KAAE,CAAA,MAAA,CAAO,CACpC,SAAA,CAAWA,MAAE,MAAO,EAAA,CACpB,MAAQA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CACjB,OAASA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,QAAS,EAAA,CACnC,gBAAiBA,KAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,QAAA,EAClC,CAAA,aAAA,CAAeA,KAAE,CAAA,MAAA,EAAS,CAAA,GAAA,EAAM,CAAA,QAAA,GAChC,YAAcA,CAAAA,KAAAA,CAAE,MAAO,EAAA,CAAE,QAAS,EACpC,CAAC,CAAA,CAGK2L,CAAN,CAAA,KAAgE,CAW9D,WAAA,CAAYC,CAAkC1C,CAAAA,CAAAA,CAAmC,CAVjF,IAAS,CAAA,OAAA,CAAU,IAWjB,CAAA,IAAMI,CAAgBoC,CAAAA,CAAAA,CAAqB,KAAMxC,CAAAA,CAAO,CACxD,CAAA,IAAA,CAAK,WAAc0C,CAAAA,CAAAA,CACnB,IAAK,CAAA,SAAA,CAAYtC,EAAc,SAC/B,CAAA,IAAA,CAAK,MAASA,CAAAA,CAAAA,CAAc,MAC5B,CAAA,IAAA,CAAK,OAAUuC,CAAAA,gCAAAA,CAAwBvC,CAAc,CAAA,OAAA,EAAW3H,CAAO,CAAA,OAAO,CAC9E,CAAA,IAAA,CAAK,cAAgBkK,gCAAwBvC,CAAAA,CAAAA,CAAc,aAAiB,EAAA,CAAA,EAAG,IAAK,CAAA,OAAO,CAAmB,iBAAA,CAAA,CAAA,CAC9G,IAAK,CAAA,eAAA,CAAkBuC,gCAAwBvC,CAAAA,CAAAA,CAAc,eAAmB,EAAA,CAAA,EAAG,KAAK,OAAO,CAAA,iBAAA,CAAmB,CAClH,CAAA,IAAA,CAAK,YAAeA,CAAAA,CAAAA,CAAc,aACpC,CAEA,iBAA6B,EAAA,CAC3B,OAAO,IAAA,CAAK,OACd,CAEA,mBAAiC,CAC/B,OAAO7I,CAAA,CAAA,CACL,aAAe,CAAA,CAAA,OAAA,EAAU,IAAK,CAAA,MAAM,CACpC,CAAA,CAAA,cAAA,CAAgB,kBACZ,CAAA,CAAA,IAAA,CAAK,YAAe,CAAA,CAAE,sBAAuB,IAAK,CAAA,YAAa,CAAI,CAAA,EAE3E,CAAA,CAEA,gBAA+B,EAAA,CAC7B,OAAO,CACL,KAAO,CAAA,IAAA,CAAK,SACd,CACF,CAQA,aAAcqL,CAAAA,CAAAA,CAAyE,CAErF,IAAMC,CAAiBC,CAAAA,CAAAA,EAA6B,CAClD,IAAMC,CAAQ,CAAA,kBAAA,CACRC,CAAwC,CAAA,CAC5C,CAAG,CAAA,IAAA,CACH,EAAG,GACH,CAAA,CAAA,CAAG,GACH,CAAA,EAAA,CAAI,CACN,CAAA,CAEIC,CACAC,CAAAA,CAAAA,CAAU,CACd,CAAA,KAAA,CAAQD,CAAQF,CAAAA,CAAAA,CAAM,IAAKD,CAAAA,CAAQ,KAAO,IAAM,EAAA,CAC9C,IAAM/L,CAAAA,CAAQ,QAASkM,CAAAA,CAAAA,CAAM,CAAC,CAAC,CACzBE,CAAAA,CAAAA,CAAOF,CAAM,CAAA,CAAC,CACpBC,CAAAA,CAAAA,EAAWnM,EAAQiM,CAAUG,CAAAA,CAAI,EACnC,CAEA,OAAOD,CACT,CAEIE,CAAAA,CAAAA,CAAuB,CACvBC,CAAAA,CAAAA,CAAqB,CACnBC,CAAAA,CAAAA,CAAc,CAChBV,CAAAA,CAAAA,CAAAA,CAAgB,4BAA4B,CAC9CQ,GAAAA,CAAAA,CAAuBP,CAAcD,CAAAA,CAAAA,CAAgB,4BAA4B,CAAC,CAEhFA,CAAAA,CAAAA,CAAAA,CAAgB,0BAA0B,CAAA,GAC5CS,CAAqBR,CAAAA,CAAAA,CAAcD,CAAgB,CAAA,0BAA0B,CAAC,CAIhF,CAAA,CAAA,IAAMW,CAAU,CAAA,IAAA,CAAK,GAAIH,CAAAA,CAAAA,CAAsBC,CAAkB,CAAA,CACjE,OAAO,CAAE,WAAAC,CAAAA,CAAAA,CAAa,OAAAC,CAAAA,CAAQ,CAChC,CAEA,aAAA,CAAcC,CAAiC,CAAA,CAC7C,OAAOA,CAAAA,CAAS,MAAO,CAAA,CAAC1D,CAAK2D,CAAAA,CAAAA,GACpB3D,CAAM2D,CAAAA,CAAAA,CAAQ,OAAQ,CAAA,GAAA,CAAKC,GAAaA,CAAQ,CAAA,QAAA,GAAa,MAASA,CAAAA,CAAAA,CAAQ,KAAQ,CAAA,EAAG,CAAE,CAAA,IAAA,CAAK,GAAG,CAAA,CAAE,MAC3G,CAAA,CAAC,CACN,CAEA,sBAAsBC,CAKpB,CAAA,CACA,IAAMC,CAAAA,CAAcrB,EAAkB,CAAA,SAAA,CAAUoB,CAAO,CAAA,CACvD,GAAI,CAACC,CAAY,CAAA,OAAA,CACf,MAAM,IAAIC,kCAAyB,CAAE,IAAA,CAAM,uBAAyB,CAAA,KAAA,CAAOD,CAAY,CAAA,KAAM,CAAC,CAAA,CAGhG,IAAME,CAAAA,CAAgBF,CAAY,CAAA,IAAA,CAE5B3D,CAAY6D,CAAAA,CAAAA,CAAc,MAEhC,GAAIA,CAAAA,CAAc,WAAgB,GAAA,CAACA,CAAc,CAAA,KAAA,EAASA,CAAc,CAAA,KAAA,CAAM,MAAW,GAAA,CAAA,CAAA,CACvF,MAAM,IAAID,iCAAyB,CAAA,CACjC,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CAC1D,KAAO,CAAA,IAAI,KAAM,CAAA,sDAAsD,CACzE,CAAC,CAGH,CAAA,IAAME,CAAsB,CAAA,GACxBD,CAAc,CAAA,eAAA,GAChBC,CAAQ,CAAA,cAAA,CAAiBD,CAAc,CAAA,eAAA,CAAgB,IACnDA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,IAAA,GAAS,aACzCC,GAAAA,CAAAA,CAAQ,cAAiB,CAAA,CACvB,KAAMD,CAAc,CAAA,eAAA,CAAgB,WAAY,CAAA,IAAA,CAChD,WAAaA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,WAAe,EAAA,EAAA,CACtE,MAAQA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,OAClD,MAAQA,CAAAA,CAAAA,CAAc,eAAgB,CAAA,WAAA,CAAY,MACpD,CAAA,CAAA,CAAA,CAIAA,CAAc,CAAA,WAAA,GACZ,OAAOA,CAAAA,CAAc,WAAgB,EAAA,QAAA,CACvCC,CAAQ,CAAA,UAAA,CAAaD,EAAc,WAEnCC,CAAAA,CAAAA,CAAQ,UAAaD,CAAAA,CAAAA,CAAc,WAAY,CAAA,QAAA,CAAS,IAI5DC,CAAAA,CAAAA,CAAAA,CAAQ,IAAOD,CAAAA,CAAAA,CAAc,IAC7BC,CAAAA,CAAAA,CAAQ,SAAYD,CAAAA,CAAAA,CAAc,sBAClCC,CAAQ,CAAA,WAAA,CAAcD,CAAc,CAAA,WAAA,CACpCC,CAAQ,CAAA,IAAA,CAAOD,CAAc,CAAA,KAAA,CAC7BC,CAAQ,CAAA,eAAA,CAAkBD,CAAc,CAAA,gBAAA,CACxCC,CAAQ,CAAA,gBAAA,CAAmBD,EAAc,iBACzCC,CAAAA,CAAAA,CAAQ,IAAOD,CAAAA,CAAAA,CAAc,IAC7BC,CAAAA,CAAAA,CAAQ,QAAWD,CAAAA,CAAAA,CAAc,QACjCC,CAAAA,CAAAA,CAAQ,WAAcD,CAAAA,CAAAA,CAAc,YAEpC,CAAA,IAAME,EAASC,YAAO,EAAA,CAAE,KAAMC,CAAAA,+BAAAA,CAAuBH,CAAO,CAAC,EAEvDP,CAA0B,CAAA,EAC1BW,CAAAA,CAAAA,CAAqD,EAAC,CAC5DL,EAAc,QAAS,CAAA,OAAA,CAASL,CAAY,EAAA,CAC1C,IAAMW,CAAAA,CAAOX,CAAQ,CAAA,IAAA,CACrB,OAAQW,CAAAA,EACN,IAAK,QACH,CAAA,CACE,IAAMV,CAAUD,CAAAA,CAAAA,CAAQ,OACxB,CAAA,GAAI,OAAOC,CAAAA,EAAY,QACrBF,CAAAA,CAAAA,CAAS,IAAK,CAAA,CACZ,IAAMY,CAAAA,CAAAA,CACN,OAAS,CAAA,CAAC,CAAE,QAAUxD,CAAAA,yBAAAA,CAAqB,KAAO8C,CAAAA,CAAQ,CAAC,CAC7D,CAAC,CAAA,CAAA,KACI,CACL,IAAMW,CAAWX,CAAAA,CAAAA,CAAQ,GAAKY,CAAAA,CAAAA,GACrB,CAAE,QAAU1D,CAAAA,yBAAAA,CAAqB,KAAO0D,CAAAA,CAAAA,CAAE,IAAK,CAAA,CACvD,CACDd,CAAAA,CAAAA,CAAS,IAAK,CAAA,CAAE,IAAMY,CAAAA,CAAAA,CAAM,OAASC,CAAAA,CAAS,CAAC,EACjD,CACF,CACA,MAEF,IAAK,MAAA,CACH,CACE,IAAMX,CAAUD,CAAAA,CAAAA,CAAQ,OACxB,CAAA,GAAI,OAAOC,CAAAA,EAAY,SACrBF,CAAS,CAAA,IAAA,CAAK,CACZ,IAAA,CAAMY,CACN,CAAA,OAAA,CAAS,CAAC,CAAE,QAAUxD,CAAAA,yBAAAA,CAAqB,KAAO8C,CAAAA,CAAQ,CAAC,CAC7D,CAAC,CACI,CAAA,KAAA,CACL,IAAMW,CAAAA,CAAWX,CAAQ,CAAA,GAAA,CAAKY,CACxBA,EAAAA,CAAAA,CAAE,IAAS,GAAA,MAAA,CACN,CAAE,QAAA,CAAU1D,yBAAqB,CAAA,KAAA,CAAO0D,EAAE,IAAK,CAAA,CAElDA,CAAE,CAAA,SAAA,CAAU,GAAI,CAAA,UAAA,CAAW,OAAO,CAAA,CAC7B,CACL,QAAA,CAAUzD,0BACV,CAAA,MAAA,CAAQyD,CAAE,CAAA,SAAA,CAAU,QAAU,MAC9B,CAAA,KAAA,CAAO,CACL,IAAA,CAAMC,mCACN,CAAA,MAAA,CAAQD,CAAE,CAAA,SAAA,CAAU,GACpB,CAAA,SAAA,CAAWE,8BAAsBF,CAAAA,CAAAA,CAAE,SAAU,CAAA,GAAG,CAClD,CACF,CAAA,CAEO,CACL,QAAA,CAAUzD,0BACV,CAAA,MAAA,CAAQyD,CAAE,CAAA,SAAA,CAAU,MAAU,EAAA,MAAA,CAC9B,KAAO,CAAA,CAAE,IAAMG,CAAAA,gCAAAA,CAA4B,IAAKH,CAAE,CAAA,SAAA,CAAU,GAAI,CAClE,CAGL,CAAA,CACDd,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMY,CAAM,CAAA,OAAA,CAASC,CAAS,CAAC,EACjD,CACF,CACA,MAEF,IAAK,WACH,CAAA,CACE,IAAMK,CAAAA,CAAkC,EAAC,CAEzC,GAAI,CAACjB,CAAQ,CAAA,OAAA,EAAW,CAACA,CAAQ,CAAA,UAAA,CAC/B,MAAM,IAAII,iCAAyB,CAAA,CACjC,IAAM,CAAA,CAAA,mCAAA,EAAsC,IAAK,CAAA,SAAS,CAC1D,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,kDAAkD,CACrE,CAAC,CAGH,CAAA,GAAIJ,CAAQ,CAAA,OAAA,CAAS,CACnB,IAAMC,CAAUD,CAAAA,CAAAA,CAAQ,OACpB,CAAA,OAAOC,CAAY,EAAA,QAAA,CACrBgB,EAAiB,IAAK,CAAA,CAAE,QAAU9D,CAAAA,yBAAAA,CAAqB,KAAO8C,CAAAA,CAAQ,CAAC,CAAA,CAEvEA,CAAQ,CAAA,OAAA,CAASY,CAAM,EAAA,CACrBI,CAAiB,CAAA,IAAA,CAAK,CAAE,QAAU9D,CAAAA,yBAAAA,CAAqB,KAAO0D,CAAAA,CAAAA,CAAE,IAAK,CAAC,EACxE,CAAC,EAEL,CAEIb,CAAQ,CAAA,UAAA,EACQA,CAAQ,CAAA,UAAA,CAChB,QAAQ,CAACkB,CAAAA,CAAUC,CAAU,GAAA,CACrC,IAAMC,CAAAA,CAAuC,CAC3C,QAAA,CAAU/D,6BACV,CAAA,EAAA,CAAI6D,CAAS,CAAA,EAAA,CACb,KAAOC,CAAAA,CAAAA,CACP,KAAMD,CAAS,CAAA,QAAA,CAAS,IACxB,CAAA,SAAA,CAAWA,CAAS,CAAA,QAAA,CAAS,SAC/B,CAAA,CACAD,CAAiB,CAAA,IAAA,CAAKG,CAAe,CAAA,CACrCV,CAAYU,CAAAA,CAAAA,CAAgB,EAAE,CAAIA,CAAAA,EACpC,CAAC,CAAA,CAEHrB,CAAS,CAAA,IAAA,CAAK,CAAE,IAAA,CAAMY,CAAM,CAAA,OAAA,CAASM,CAAiB,CAAC,EACzD,CACA,MAEF,IAAK,MAAA,CACH,CACE,IAAMI,CAAerB,CAAAA,CAAAA,CACrBD,CAAS,CAAA,IAAA,CAAK,CACZ,IAAA,CAAMY,CACN,CAAA,OAAA,CAAS,CACP,CACE,SAAUrD,iCACV,CAAA,EAAA,CAAI+D,CAAa,CAAA,YAAA,CACjB,KAAOX,CAAAA,CAAAA,CAAYW,CAAa,CAAA,YAAY,CAAE,CAAA,KAAA,CAC9C,IAAMX,CAAAA,CAAAA,CAAYW,CAAa,CAAA,YAAY,EAAE,IAC7C,CAAA,IAAA,CAAMA,CAAa,CAAA,OACrB,CACF,CACF,CAAC,EACH,CACA,KACJ,CACF,CAAC,CAED,CAAA,IAAMC,EAAoB,EAAC,CAC3B,OAAIjB,CAAAA,CAAc,KAChBA,EAAAA,CAAAA,CAAc,KAAM,CAAA,OAAA,CAASkB,CAAoC,EAAA,CAC/DD,CAAM,CAAA,IAAA,CAAK,CACT,IAAA,CAAM,WACN,UAAY,CAAA,CACV,MAAQ,CAAA,CACN,IAAMC,CAAAA,CAAAA,CAAK,QAAS,CAAA,IAAA,CACpB,WAAaA,CAAAA,CAAAA,CAAK,QAAS,CAAA,WAAA,EAAe,EAC1C,CAAA,MAAA,CAAQA,EAAK,QAAS,CAAA,MAAA,CACtB,UAAYA,CAAAA,CAAAA,CAAK,QAAS,CAAA,UAC5B,CACF,CACF,CAAC,EACH,CAAC,CAAA,CAGI,CACL,SAAA,CAAA/E,EACA,MAAA+D,CAAAA,CAAAA,CACA,QAAAR,CAAAA,CAAAA,CACA,KAAOuB,CAAAA,CAAAA,CAAM,MAAS,CAAA,CAAA,CAAIA,CAAQ,CAAA,KAAA,CACpC,CACF,CAGA,eAAgBf,CAAAA,CAAAA,CAAoBR,EAA0BuB,CAAgC,CAAA,CAC5F,IAAME,CAAAA,CAAcjB,CAAO,CAAA,UAAA,CAC3B,OAAOA,CAAAA,CAAO,UAEd,CAAA,IAAMkB,CAAgB,CAAA,IAAA,CAAK,WAAY,CAAA,MAAA,CAAO,OAAO,SAAUlB,CAAAA,CAAM,CACrE,CAAA,GAAI,CAACkB,CAAAA,CAAc,OACjB,CAAA,MAAM,IAAIC,2BAAAA,CAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAOD,CAAc,CAAA,KACvB,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAeF,CAAc,CAAA,IAAA,CAC/BD,CAAgB,GAAA,KAAA,CAAA,GAClBG,CAAa,CAAA,UAAA,CAAaH,GAG5B,MAAO,CAAA,IAAA,CAAKG,CAAY,CAAA,CAAE,OAASrF,CAAAA,CAAAA,EAAQ,CACzC,GAAI,EAAEA,CAAAA,IAAO,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,GAAA,CAAA,CACnC,MAAM,IAAIoF,2BAAAA,CAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAA,CACnD,KAAO,CAAA,IAAI,KAAM,CAAA,CAAA,sBAAA,EAAyBpF,CAAG,CAAA;AAAA,8BAAA,EACvB,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,MAAO,CAAA,GAAG,EAAE,IAAK,CAAA,IAAI,CAAC,CAAA,CAAA,CAAG,CAC9E,CAAC,CAEL,CAAC,CAED,CAAA,IAAMsF,EAAoB,MAAO,CAAA,IAAA,CAAKD,CAAY,CAAA,CAAE,OAAO,CAACtF,CAAAA,CAAKC,IAAQ,CACvE,IAAMuF,EAAM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIvF,CAAAA,CAAG,EACrCwF,CAAWD,CAAAA,CAAAA,CAAI,MACfE,CAAcJ,CAAAA,CAAAA,CAA4BrF,CAAG,CAEnD,CAAA,OAAIwF,CAAa,GAAA,uBAAA,EAA2BD,EAAI,IAAS,GAAA,OAAA,EAAWE,IAAe,CACjF1F,CAAAA,CAAAA,CAAIyF,CAAQ,CAAID,CAAAA,CAAAA,CAAI,GAEpBxF,CAAAA,CAAAA,CAAIyF,CAAQ,CAAIC,CAAAA,CAAAA,CAGX1F,CACT,CAAG,CAAA,EAAgB,CAEnB,CAAA,GAAIuF,CAAkB,CAAA,YAAA,EAAgB,CAACA,CAAkB,CAAA,QAAA,CACvD,MAAM,IAAIF,2BAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAO,IAAI,KAAA,CAAM,4DAA4D,CAC/E,CAAC,EAGH,GAAI,aAAA,GAAiBE,CAAqBA,EAAAA,CAAAA,CAAkB,cAAgB,KAAW,CAAA,CAAA,CACrF,IAAM1O,CAAa0O,CAAAA,CAAAA,CAAkB,YACrC,GAAI,CAACN,CAAUA,EAAAA,CAAAA,EAASA,EAAM,MAAW,GAAA,CAAA,CACvC,MAAM,IAAII,2BAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,IAAK,CAAA,SAAS,IACnD,KAAO,CAAA,IAAI,MAAM,qDAAqD,CACxE,CAAC,CACI,CAAA,GAAIJ,GAASA,CAAM,CAAA,MAAA,CAAS,EAAG,CACpC,IAAMU,EAAmB,IAAK,CAAA,WAAA,CAAY,OAAO,GAAI,CAAA,UAAA,CACrD,GAAI,CAACA,EAAiB,OAAQ,CAAA,QAAA,CAAS9O,CAAU,CAC/C,CAAA,GAAIoO,EAAM,GAAKC,CAAAA,CAAAA,EAASA,CAAK,CAAA,UAAA,CAAW,OAAO,IAAI,CAAA,CAAE,SAASrO,CAAU,CAAA,CACtE0O,EAAkB,WAAc,CAAA,CAAE,IAAM,CAAA,UAAA,CAAY,SAAU,CAAE,IAAA,CAAM1O,CAAW,CAAE,CAAA,CAAA,WAE7E,IAAIwO,2BAAAA,CAAmB,CAC3B,IAAM,CAAA,CAAA,4BAAA,EAA+B,KAAK,SAAS,CAAA,CAAA,CAAA,CACnD,MAAO,IAAI,KAAA,CAAM,iBAAiBxO,CAAU,CAAA;AAAA,wBAAA,EAChC8O,CAAiB,CAAA,OAAA,CAAQ,IAAK,CAAA,IAAI,CAAC,CAAG,CAAA,CAAA,CACpD,CAAC,CAGP,CACF,CAEA,GAAI,iBAAqBJ,GAAAA,CAAAA,EAAqBA,EAAkB,eAAoB,GAAA,KAAA,CAAA,CAAW,CAC7F,IAAMjO,CAAiBiO,CAAAA,CAAAA,CAAkB,eACzC,CAAA,GAAIjO,IAAmB,aACrB,CAAA,GAAM,iBAAqBiO,GAAAA,CAAAA,CAMzBA,EAAkB,eAAkB,CAAA,CAClC,IAAM,CAAA,aAAA,CACN,YAAaA,CAAkB,CAAA,eACjC,CACA,CAAA,OAAOA,CAAkB,CAAA,eAAA,CAAA,KATnB,MAAA,IAAIF,4BAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,SAAS,CACnD,CAAA,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,+EAA+E,CAClG,CAAC,CASHE,CAAAA,KAAAA,CAAAA,CAAkB,gBAAkB,CAAE,IAAA,CAAMjO,CAAe,EAE/D,CAEA,OAAOiO,CACT,CAEA,iBAAA,CAAkB7B,EAAqC,CACrD,GAAI,CAACA,CAAAA,EAAaA,GAAYA,CAAS,CAAA,MAAA,GAAW,CAChD,CAAA,OAAO,CAAE,QAAA,CAAU,EAAG,EAGxB,IAAMkC,CAAAA,CAAiBlC,CAAS,CAAA,GAAA,CAAKC,GAAY,CAC/C,IAAMkC,CAAgBC,CAAAA,aAAAA,GAAU,SAAUnC,CAAAA,CAAO,CACjD,CAAA,GAAI,CAACkC,CAAc,CAAA,OAAA,CACjB,MAAM,IAAIE,8BAAqB,CAAE,IAAA,CAAM,kBAAoB,CAAA,KAAA,CAAOF,EAAc,KAAM,CAAC,CAEzF,CAAA,OAAOA,EAAc,IACvB,CAAC,CAED,CAAA,OAAAD,CAAe,CAAA,OAAA,CAASjC,CAAY,EAAA,CAClCA,EAAQ,OAAQ,CAAA,OAAA,CAASC,CAAY,EAAA,CACnC,GAAI,CAAC,IAAA,CAAK,WAAY,CAAA,UAAA,CAAW,SAASA,CAAQ,CAAA,QAAQ,CACxD,CAAA,MAAM,IAAImC,6BAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,KAAO,CAAA,IAAI,MAAM,CAAY,SAAA,EAAA,IAAA,CAAK,SAAS,CAAA,+BAAA,EAAkCnC,EAAQ,QAAQ,CAAA;AAAA,sCACjE,EAAA,IAAA,CAAK,YAAY,UAAW,CAAA,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACvE,CAAC,CAEL,CAAC,EACH,CAAC,EAEDgC,CAAe,CAAA,OAAA,CAASjC,GAAY,CAClC,GAAI,CAAC,MAAA,CAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,SAASA,CAAQ,CAAA,IAAI,EAC5D,MAAM,IAAIoC,6BAAqB,CAAA,CAC7B,IAAM,CAAA,CAAA,qCAAA,EAAwC,KAAK,SAAS,CAAA,CAAA,CAAA,CAC5D,MAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAA8BpC,2BAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAAA;AAAA,+BAAA,EAC9D,OAAO,IAAK,CAAA,IAAA,CAAK,YAAY,KAAK,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC1E,CAAC,CAEL,CAAC,CAAA,CAiHM,CAAE,QA/GmBiC,CAAAA,CAAAA,CAAe,IAAKjC,CAAY,EAAA,CAC1D,OAAQA,CAAQ,CAAA,IAAA,EACd,KAAKnD,uBAAAA,CAAmB,CACtB,IAAMwF,CAAAA,CAAgD,EACtD,CAAA,OAAArC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAa9C,GAAAA,yBAAAA,CACvBkF,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,OAEhD,MAAA,IAAImC,8BAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWpC,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EAEM,CACL,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMD,EAAQ,IAAI,CAAA,CACzC,QAASqC,CACX,CACF,CAEA,KAAKtF,0BAAAA,CAAsB,CACzB,IAAMsF,CAAAA,CAAgD,EAChDC,CAAAA,CAAAA,CAA+F,EACrG,CAAA,OAAAtC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAa9C,GAAAA,yBAAAA,CACvBkF,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,UAC7CA,CAAQ,CAAA,QAAA,GAAa5C,8BAC9BiF,CAAU,CAAA,IAAA,CAAK,CACb,EAAIrC,CAAAA,CAAAA,CAAQ,GACZ,IAAM,CAAA,UAAA,CACN,SAAU,CAAE,IAAA,CAAMA,EAAQ,IAAM,CAAA,SAAA,CAAWA,EAAQ,SAAU,CAC/D,CAAC,CAED,CAAA,KAAA,MAAM,IAAImC,6BAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA,uCAAA,EAA0CC,EAAQ,QAAQ,CAAA,CAAA,CAAG,CACvG,CAAC,CAEL,CAAC,CAEMnM,CAAAA,CAAAA,CAAA,CACL,IAAM,CAAA,IAAA,CAAK,YAAY,KAAMkM,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,OAAA,CAASqC,GACLC,CAAU,CAAA,MAAA,CAAS,EAAI,CAAE,UAAA,CAAYA,CAAU,CAAI,CAAA,GAE3D,CAEA,KAAKxF,sBAAiB,CACpB,IAAMuF,EAAgD,EAAC,CACjDE,EAAoF,EAAC,CAC3FvC,EAAQ,OAAQ,CAAA,OAAA,CAASC,GAAY,CACnC,GAAIA,EAAQ,QAAa9C,GAAAA,yBAAAA,CACvBkF,EAAY,IAAK,CAAA,CAAE,KAAM,MAAQ,CAAA,IAAA,CAAMpC,EAAQ,KAAM,CAAC,UAC7CA,CAAQ,CAAA,QAAA,GAAa7C,2BAC9BmF,CAAa,CAAA,IAAA,CAAK,CAChB,IAAM,CAAA,WAAA,CACN,UAAW,CACT,GAAA,CAAKtC,EAAQ,KAAM,CAAA,IAAA,GAAS,MAAQA,CAAQ,CAAA,KAAA,CAAM,IAAMA,CAAQ,CAAA,KAAA,CAAM,OACtE,MAAQA,CAAAA,CAAAA,CAAQ,MAClB,CACF,CAAC,OAEK,MAAA,IAAImC,8BAAqB,CAC7B,IAAA,CAAM,iEAAiE,IAAK,CAAA,SAAS,GACrF,KAAO,CAAA,IAAI,MAAM,CAAWpC,QAAAA,EAAAA,CAAAA,CAAQ,IAAI,CAA0CC,uCAAAA,EAAAA,CAAAA,CAAQ,QAAQ,CAAG,CAAA,CAAA,CACvG,CAAC,CAEL,CAAC,EAED,IAAMuC,CAAAA,CAAkB,CAAC,GAAGH,CAAAA,CAAa,GAAGE,CAAY,CAAA,CAExD,OAAO,CACL,IAAA,CAAM,KAAK,WAAY,CAAA,KAAA,CAAMvC,EAAQ,IAAI,CAAA,CACzC,QAASwC,CACX,CACF,CAEA,KAAKxF,qBAAAA,CAAiB,CACpB,GAAIgD,CAAAA,CAAQ,QAAQ,MAAW,GAAA,CAAA,CAC7B,MAAM,IAAIoC,6BAAAA,CAAqB,CAC7B,IAAM,CAAA,CAAA,4BAAA,EAA+BpC,EAAQ,IAAI,CAAA,CAAA,CAAA,CACjD,MAAO,IAAI,KAAA,CAAM,WAAWA,CAAQ,CAAA,IAAI,sCAAsC,CAChF,CAAC,EAGH,GAAIA,CAAAA,CAAQ,QAAQ,CAAC,CAAA,CAAE,WAAa1C,iCAClC,CAAA,MAAM,IAAI8E,6BAAqB,CAAA,CAC7B,KAAM,CAAiE,8DAAA,EAAA,IAAA,CAAK,SAAS,CACrF,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA,qCAAA,EAAwC1C,iCAA2B,CAAG,CAAA,CAAA,CAChH,CAAC,CAGH,CAAA,IAAM+D,EAAerB,CAAQ,CAAA,OAAA,CAAQ,CAAC,CACtC,CAAA,OAAO,CACL,IAAM,CAAA,IAAA,CAAK,YAAY,KAAMA,CAAAA,CAAAA,CAAQ,IAAI,CACzC,CAAA,YAAA,CAAcqB,EAAa,EAC3B,CAAA,OAAA,CAASA,EAAa,IACxB,CACF,CAEA,QACE,MAAM,IAAIe,6BAAqB,CAAA,CAC7B,KAAM,CAAsC,mCAAA,EAAA,IAAA,CAAK,SAAS,CAC1D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAM,CAAA,CAAA,QAAA,EAAWpC,EAAQ,IAAI,CAAA;AAAA,iCAAA,EACjB,MAAO,CAAA,IAAA,CAAK,IAAK,CAAA,WAAA,CAAY,KAAK,CAAE,CAAA,IAAA,CAAK,IAAI,CAAC,CAAG,CAAA,CAAA,CAC1E,CAAC,CAEL,CACF,CAAC,CAEsC,CACzC,CAEA,cAAesB,CAAAA,CAAAA,CAA+B,CAC5C,GAAI,CAAC,IAAK,CAAA,WAAA,CAAY,UAAW,CAAA,QAAA,CAASjE,6BAAuB,CAC/D,CAAA,MAAM,IAAIoF,0BAAAA,CAAkB,CAC1B,IAAM,CAAA,CAAA,oCAAA,EAAuC,IAAK,CAAA,SAAS,CAC3D,CAAA,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,YAAY,IAAK,CAAA,SAAS,CAAuCpF,oCAAAA,EAAAA,6BAAuB,CAAG,CAAA,CAAA,CAC9G,CAAC,CAAA,CAGH,OAAI,CAACiE,CAAAA,EAAUA,CAASA,EAAAA,CAAAA,CAAM,MAAW,GAAA,CAAA,CAChC,CAAE,KAAA,CAAO,EAAiB,CAAA,CAgB5B,CAAE,KAAA,CAbWA,EAAM,GAAKC,CAAAA,CAAAA,EAAS,CACtC,IAAMmB,EAAaC,UAAK,EAAA,CAAE,SAAUpB,CAAAA,CAAI,CACxC,CAAA,GAAI,CAACmB,CAAAA,CAAW,QACd,MAAM,IAAID,0BAAkB,CAAA,CAAE,IAAM,CAAA,eAAA,CAAiB,KAAOC,CAAAA,CAAAA,CAAW,KAAM,CAAC,CAAA,CAEhF,OAAOA,CAAAA,CAAW,IACpB,CAAC,CAEoC,CAAA,GAAA,CAAKnB,IAAU,CAClD,IAAA,CAAM,UACN,CAAA,QAAA,CAAUA,EAAK,UAAW,CAAA,MAC5B,CAAE,CAAA,CAE+B,CACnC,CAGM,kBAAA,CAAmBhB,CAAqBR,CAAAA,CAAAA,CAA0BuB,CAAsC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,OAAO,IAAI,OAAA,CAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,eAAe,EAC9B,CAAC,CACH,CAAA,CAAA,CAGM,sBAAuBtC,CAAAA,CAAAA,CAAqBR,CAA0BuB,CAAAA,CAAAA,CAA0C,CAAAsB,OAAAA,CAAAA,CAAA,sBACpH,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ,CAAA,IAAA,CAAK,iBAAkB,EAAC,EAClC,CAAC,CACH,CAEM,CAAA,CAAA,mBAAA,CAAoBtC,CAAoBR,CAAAA,CAAAA,CAAyBuB,CAAyC,CAAA,CAAA,OAAAsB,EAAA,IAC9G,CAAA,IAAA,CAAA,WAAA,CAAA,IAAMhB,CAAoB,CAAA,IAAA,CAAK,eAAgBrB,CAAAA,CAAAA,CAAQR,CAAUuB,CAAAA,CAAK,EAChEwB,CAAsB,CAAA,IAAA,CAAK,iBAAkB/C,CAAAA,CAAQ,CAC3D,CAAA,GAAI+C,CAAoB,CAAA,QAAA,EAAaA,EAAoB,QAA2B,CAAA,MAAA,GAAW,CAC7F,CAAA,MAAM,IAAIV,6BAAqB,CAAA,CAC7B,IAAM,CAAA,uBAAA,CACN,MAAO,IAAI,KAAA,CAAM,uBAAuB,CAC1C,CAAC,CAAA,CAGH,IAAMW,CAAAA,CAAmBzB,EAAQ,IAAK,CAAA,cAAA,CAAeA,CAAK,CAAA,CAAI,EAAC,CAE/D,OAAO,IAAI,QAASuB,CAAY,EAAA,CAC9BA,CAAQ/O,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,EACH,CAAA,IAAA,CAAK,gBAAiB,EAAA,CAAA,CACtB8N,GACAkB,CACAC,CAAAA,CAAAA,CAAAA,CACJ,EACH,CAAC,CACH,CAEA,CAAA,CAAA,6BAAA,CAA8BC,CAAiC,CAAA,CAC7D,IAAMC,CAAOlF,CAAAA,EAAAA,CAA2B,SAAUiF,CAAAA,CAAQ,CAC1D,CAAA,GAAIC,CAAK,CAAA,OAAA,CAAS,CAChB,GAAIA,CAAAA,CAAK,IAAK,CAAA,OAAA,CAAQ,MAAW,GAAA,CAAA,CAC/B,MAAM,IAAIC,4BAAmB,CAC3B,IAAA,CAAM,6BACN,CAAA,KAAA,CAAO,IAAI,KAAA,CAAM,CAA4B,yBAAA,EAAA,IAAA,CAAK,UAAUD,CAAK,CAAA,IAAI,CAAC,CAAA,CAAE,CAC1E,CAAC,CAAA,CAGH,IAAME,CAAAA,CAAiDF,EAAK,IACtDlD,CAAAA,CAAAA,CAA0B,CAC9B,CACE,IAAMhD,CAAAA,0BAAAA,CACN,OAAS,CAAA,EACX,CACF,CAAA,CACMiD,CAAUmD,CAAAA,CAAAA,CAAe,QAAQ,CAAC,CAAA,CAAE,OACtCnD,CAAAA,CAAAA,CAAQ,SACVD,CAAS,CAAA,CAAC,CAAE,CAAA,OAAA,CAAQ,IAAKqD,CAAAA,uBAAAA,CAAkBpD,CAAQ,CAAA,OAAO,CAAC,CAGzDA,CAAAA,CAAAA,CAAQ,OACVD,EAAAA,CAAAA,CAAS,CAAC,CAAE,CAAA,OAAA,CAAQ,IAAKqD,CAAAA,uBAAAA,CAAkBpD,EAAQ,OAAO,CAAC,CAGzDA,CAAAA,CAAAA,CAAQ,UACVA,EAAAA,CAAAA,CAAQ,UAAW,CAAA,OAAA,CAAQ,CAACkB,CAAUC,CAAAA,CAAAA,GAAU,CAC9CpB,CAAAA,CAAS,CAAC,CAAA,CAAE,OAAQ,CAAA,IAAA,CAAKsD,4BAAsBlC,CAAOD,CAAAA,CAAAA,CAAS,EAAIA,CAAAA,CAAAA,CAAS,QAAS,CAAA,IAAA,CAAMA,CAAS,CAAA,QAAA,CAAS,SAAS,CAAC,EACzH,CAAC,CAAA,CAGH,IAAMoC,CAAuB,CAAA,CAC3B,YAAcH,CAAAA,CAAAA,CAAe,MAAM,aACnC,CAAA,gBAAA,CAAkBA,CAAe,CAAA,KAAA,CAAM,iBACvC,CAAA,WAAA,CAAaA,CAAe,CAAA,KAAA,CAAM,YACpC,CAEMpQ,CAAAA,CAAAA,CAA6B,EAAC,CAC9BwQ,CAAYJ,CAAAA,CAAAA,CAAe,OAAQ,CAAA,CAAC,EAAE,QAC5C,CAAA,OAAII,CACEA,GAAAA,CAAAA,CAAU,OACZxQ,EAAAA,CAAAA,CAAS,IACP,CAAA,GAAGwQ,EAAU,OAAQ,CAAA,GAAA,CAAKC,CAAa,GAAA,CACrC,MAAOA,CAAQ,CAAA,KAAA,CACf,OAASA,CAAAA,CAAAA,CAAQ,QACjB,KAAOA,CAAAA,CAAAA,CAAQ,KACf,CAAA,WAAA,CAAaA,CAAQ,CAAA,YAAA,CAAa,GAAKC,CAAAA,CAAAA,GAAgB,CACrD,KAAOA,CAAAA,CAAAA,CAAW,KAClB,CAAA,OAAA,CAASA,CAAW,CAAA,OAAA,CACpB,KAAOA,CAAAA,CAAAA,CAAW,KACpB,CAAE,CAAA,CACJ,CAAE,CAAA,CACJ,CAEEF,CAAAA,CAAAA,CAAU,OACZxQ,EAAAA,CAAAA,CAAS,KACP,GAAGwQ,CAAAA,CAAU,OAAQ,CAAA,GAAA,CAAKC,IAAa,CACrC,KAAA,CAAOA,CAAQ,CAAA,KAAA,CACf,QAASA,CAAQ,CAAA,OAAA,CACjB,KAAOA,CAAAA,CAAAA,CAAQ,KACf,CAAA,WAAA,CAAaA,CAAQ,CAAA,YAAA,CAAa,IAAKC,CAAgB,GAAA,CACrD,KAAOA,CAAAA,CAAAA,CAAW,MAClB,OAASA,CAAAA,CAAAA,CAAW,OACpB,CAAA,KAAA,CAAOA,EAAW,KACpB,CAAA,CAAE,CACJ,CAAA,CAAE,CACJ,CAAA,CAAA,CAIG,CACL,QAAA,CAAU1D,EACV,KAAOuD,CAAAA,CAAAA,CACP,QAAUvQ,CAAAA,CACZ,CACF,CAEA,MAAM,IAAImQ,2BAAAA,CAAmB,CAAE,IAAM,CAAA,6BAAA,CAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CACzF,CAGM,iBAAiB1C,CAAqBR,CAAAA,CAAAA,CAA0BuB,CAAsC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1G,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,aAAa,EAC5B,CAAC,CACH,GAGM,oBAAqBtC,CAAAA,CAAAA,CAAqBR,CAA0BuB,CAAAA,CAAAA,CAA0C,QAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAClH,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,CAAQ,CAAA,IAAA,CAAK,iBAAkB,EAAC,EAClC,CAAC,CACH,CAEM,CAAA,CAAA,iBAAA,CAAkBtC,CAAoBR,CAAAA,CAAAA,CAAyBuB,CAAyC,CAAA,CAAA,OAAAsB,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC5G,IAAMhB,CAAoB,CAAA,IAAA,CAAK,eAAgBrB,CAAAA,CAAAA,CAAQR,CAAUuB,CAAAA,CAAK,CAChEwB,CAAAA,CAAAA,CAAsB,KAAK,iBAAkB/C,CAAAA,CAAQ,CAC3D,CAAA,GAAI+C,EAAoB,QAAaA,EAAAA,CAAAA,CAAoB,QAA2B,CAAA,MAAA,GAAW,EAC7F,MAAM,IAAIV,6BAAqB,CAAA,CAC7B,IAAM,CAAA,uBAAA,CACN,KAAO,CAAA,IAAI,MAAM,uBAAuB,CAC1C,CAAC,CAAA,CAGH,IAAMW,CAAAA,CAAmBzB,CAAQ,CAAA,IAAA,CAAK,eAAeA,CAAK,CAAA,CAAI,EAAC,CAE/D,OAAO,IAAI,OAASuB,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ/O,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,CACN,MAAA,CAAQ,GACR,cAAgB,CAAA,CAAE,aAAe,CAAA,CAAA,CAAK,GACnC,IAAK,CAAA,gBAAA,EACL8N,CAAAA,CAAAA,CAAAA,CAAAA,CACAkB,CACAC,CAAAA,CAAAA,CAAAA,CACJ,EACH,CAAC,CACH,CAEO,CAAA,CAAA,gCAAA,CACLW,CACAC,CAAAA,CAAAA,CAC8E,QAAAC,EAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAxxBlF,IAAAC,CAAAA,CAAAC,EAyxBI,IAAMC,CAAAA,CAAOJ,CAASD,CAAAA,CAAAA,CAClBM,CAAkB,CAAA,EAClBC,CAAAA,CAAAA,CAAY,GAGZC,CAAe,CAAA,CAAA,CACnB,KAAOA,CAAAA,CAAeH,EAAK,MAAQ,EAAA,CACjC,IAAMI,CAAAA,CAAeJ,EAAK,OAAQ,CAAA,CAAA;AAAA,CAAA,CAAMG,CAAY,CACpD,CAAA,GAAIC,CAAiB,GAAA,CAAA,CAAA,CAAI,CACvBF,CAAYF,CAAAA,CAAAA,CAAK,SAAUG,CAAAA,CAAY,EACvC,KACF,CAAA,KAAO,CACL,IAAME,CAAAA,CAAOL,EAAK,SAAUG,CAAAA,CAAAA,CAAcC,CAAY,CAAA,CAAE,MACpDC,CAAAA,CAAAA,EACFJ,CAAM,CAAA,IAAA,CAAKI,CAAI,CAEjBF,CAAAA,CAAAA,CAAeC,CAAe,CAAA,EAChC,CACF,CAGA,IAAA,IAAWC,KAAQJ,CAAO,CAAA,CACxB,GAAII,CAAS,GAAA,cAAA,CACX,OAGF,GAAIA,EAAK,UAAW,CAAA,QAAQ,CAAG,CAAA,CAC7B,IAAMC,CAAUD,CAAAA,CAAAA,CAAK,SAAU,CAAA,CAAe,EAC9C,GAAI,CACF,IAAME,CAAiB,CAAA,IAAA,CAAK,MAAMD,CAAO,CAAA,CACnCpB,CAAOhF,CAAAA,EAAAA,CAAyB,UAAUqG,CAAc,CAAA,CAC9D,GAAIrB,CAAAA,CAAK,QAAS,CAChB,IAAMsB,CAA2C,CAAA,CAAE,gBAAiB,EAAG,EACjEpB,CAA+CF,CAAAA,CAAAA,CAAK,KAE1D,GAAIE,CAAAA,CAAe,OAAQ,CAAA,MAAA,CAAS,EAAG,CACrC,IAAMnD,CAAUmD,CAAAA,CAAAA,CAAe,QAAQ,CAAC,CAAA,CAAE,KAC1C,CAAA,GAAInD,IAAY,KAAa,CAAA,EAAA,MAAA,CAAO,KAAKA,CAAO,CAAA,CAAE,SAAW,CAC3D,CAAA,CAAA,GAAI,SAAaA,GAAAA,CAAAA,EAAWA,EAAQ,OAAY,GAAA,IAAA,CAC9CuE,CAAgB,CAAA,eAAA,CAAgB,KAAKC,8BAAyBzH,CAAAA,0BAAAA,CAAsBiD,CAAQ,CAAA,OAAiB,CAAC,CACrG,CAAA,KAAA,GAAA,SAAA,GAAaA,GAAWA,CAAQ,CAAA,OAAA,GAAY,KACrDuE,CAAgB,CAAA,eAAA,CAAgB,IAAKC,CAAAA,8BAAAA,CAAyBzH,2BAAsBiD,CAAQ,CAAA,OAAiB,CAAC,CAAA,CAAA,KAAA,GACrG,eAAgBA,CAAWA,EAAAA,CAAAA,CAAQ,UAAe,GAAA,KAAA,CAAA,CAAW,CACtE,IAAMkB,CAAAA,CAAWlB,EAAQ,UAAW,CAAA,EAAA,CAAG,CAAC,CACxCuE,CAAAA,CAAAA,CAAgB,eAAgB,CAAA,IAAA,CAC9BE,mCACE1H,0BACAmE,CAAAA,CAAAA,CAAS,KACTA,CAAAA,CAAAA,CAAS,IACT2C,CAAA3C,CAAAA,CAAAA,CAAS,QAAT,GAAA,IAAA,CAAA,KAAA,CAAA,CAAA2C,EAAmB,IACnBC,CAAAA,CAAAA,CAAAA,CAAA5C,EAAS,QAAT,GAAA,IAAA,CAAA,KAAA,CAAA,CAAA4C,EAAmB,SACrB,CACF,EACF,CAAA,CAEJ,CAEIX,CAAe,CAAA,KAAA,GACjBoB,CAAgB,CAAA,KAAA,CAAQ,CACtB,YAAcpB,CAAAA,CAAAA,CAAe,KAAM,CAAA,aAAA,CACnC,iBAAkBA,CAAe,CAAA,KAAA,CAAM,kBACvC,WAAaA,CAAAA,CAAAA,CAAe,MAAM,YACpC,CAAA,CAAA,CAEF,MAAM,CAAE,gBAAiBoB,CAAiB,CAAA,MAAA,CAAQN,CAAU,EAC9D,MACQ,MAAA,IAAIf,2BAAmB,CAAA,CAAE,KAAM,6BAA+B,CAAA,KAAA,CAAOD,EAAK,KAAM,CAAC,CAE3F,CAASyB,MAAAA,CAAAA,CAAO,CACd,MAAM,IAAIxB,2BAAmB,CAAA,CAC3B,IAAM,CAAA,CAAA,mCAAA,EAAsCmB,CAAO,CACnD,CAAA,CAAA,KAAA,CAAOK,CACT,CAAC,CACH,CACF,CACF,CAGA,MAAM,CAAE,gBAAiB,CAAE,eAAA,CAAiB,EAAG,EAAG,MAAQT,CAAAA,CAAU,EACtE,CAAA,CAAA,CACO,sCACLP,CACAC,CAAAA,CAAAA,CACAI,CACAY,CAAAA,CAAAA,CACAC,EAC8E,CAAAhB,OAAAA,EAAAA,CAAA,sBAE9E,MAAAiB,EAAAA,CAAO,KAAK,gCAAiCnB,CAAAA,CAAAA,CAAOC,CAAM,CAAA,EAC5D,GACM,qBAAsBI,CAAAA,CAAAA,CAAYY,CAAkCC,CAAAA,CAAAA,CAAkD,QAAAhC,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAC1H,OAAO,IAAI,QAASC,CAAY,EAAA,CAC9BA,EAAQ,IAAK,CAAA,aAAa,EAC5B,CAAC,CACH,CACM,CAAA,CAAA,uBAAA,CAAwBkB,EAAYY,CAAkCC,CAAAA,CAAAA,CAAkD,CAAAhC,OAAAA,CAAAA,CAAA,sBAC5H,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ,CAAA,IAAA,CAAK,eAAe,EAC9B,CAAC,CACH,CAEM,CAAA,CAAA,2BAAA,CAA4BkB,CAAYY,CAAAA,CAAAA,CAAkCC,EAAsD,CAAAhC,OAAAA,CAAAA,CAAA,IACpI,CAAA,IAAA,CAAA,WAAA,CAAA,GAAI,CAAC+B,CACH,CAAA,OAAO,EAAC,CAEV,IAAMG,CAA2ChR,CAAAA,CAAAA,CAAA,GAAK6Q,CAEtD,CAAA,CAAA,OAAA,OAAOG,EAAiB,IACxB,CAAA,OAAOA,CAAiB,CAAA,gBAAgB,EACjCA,CACT,CAAA,CAAA,CACM,yBAA0Bf,CAAAA,CAAAA,CAAYY,EAAkCC,CAAsD,CAAA,CAAA,OAAAhC,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CAElI,OAAO,MAAM,IAAA,CAAK,4BAA4BmB,CAAMY,CAAAA,CAAAA,CAASC,CAAK,CACpE,CAAA,CAAA,CAEA,eAAsC,EAAA,CAEpC,GAAI,EAAE,IAAA,CAAK,SAAa9P,IAAAA,CAAAA,CAAAA,CACtB,MAAM,IAAIoO,2BAAAA,CAAmB,CAC3B,IAAA,CAAM,sCAAsC,IAAK,CAAA,SAAS,IAC1D,KAAO,CAAA,IAAI,MAAM,CAA6C,0CAAA,EAAA,IAAA,CAAK,SAAS,CAAA,CAAA,CAAG,CACjF,CAAC,CAAA,CAIH,OADcpO,CAAAA,CAAY,KAAK,SAAqC,CAEtE,CACF,EC34BMO,IAAAA,EAAAA,CAA4B,qBAC5B0P,EACJ,CAAA,yNAAA,CAGIvP,EAA2BwP,CAAAA,wBAAAA,CAAgBpI,EAAsBe,CAAqC,CAAA,CAAE,KAAM,CAAA,CAClH,KAAMtI,EACN,CAAA,WAAA,CAAa0P,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,MAAO9H,CACP,CAAA,UAAA,CAAYS,EACZ,MAAQ,CAAA,CACN,GAAK9I,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CACpD,OAAQA,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,EAAE,MACzD,CAAA,CACA,MAAOE,CAAYO,CAAAA,EAAyB,CAC9C,CAAC,CAAA,CAEKE,EAA4BwJ,CAAAA,CAAAA,CAG5BzJ,GAAN,cAAiC0J,CAAc,CAC7C,WAAA,CAAYzC,EAAwC,CAClD,KAAA,CAAM/G,EAA0B+G,CAAAA,CAAO,EACzC,CACF,EC1BM9G,IAAAA,EAAAA,CAA4B,oBAC5BwP,CAAAA,EAAAA,CACJ,uNAGIrP,EAA2BoP,CAAAA,wBAAAA,CAAgBpI,CAAsBe,CAAAA,CAAqC,EAAE,KAAM,CAAA,CAClH,IAAMlI,CAAAA,EAAAA,CACN,YAAawP,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,KAAA,CACjB,MAAOhI,CACP,CAAA,UAAA,CAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAK9I,CAAAA,CAAAA,CAAuB,cAAe,CAAA,KAAA,CAAO,CAAC,CAAE,CAAA,GAAA,CACrD,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,KAAO,CAAA,CAAC,EAAE,MAC1D,CAAA,CACA,MAAOE,CAAYW,CAAAA,EAAyB,CAC9C,CAAC,EAEKE,EAA4BoJ,CAAAA,CAAAA,CAG5BrJ,EAAN,CAAA,cAAiCsJ,CAAc,CAC7C,WAAA,CAAYzC,CAAwC,CAAA,CAClD,MAAM3G,EAA0B2G,CAAAA,CAAO,EACzC,CACF,EC1BA,IAAMtH,GAAuB,eACvBiQ,CAAAA,EAAAA,CAA2B,wEAE3B9P,CAAAA,EAAAA,CAAsB4P,yBAAgBpI,CAAsBe,CAAAA,CAAqC,CAAE,CAAA,KAAA,CAAM,CAC7G,IAAM1I,CAAAA,EAAAA,CACN,YAAaiQ,EACb,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,KAAOjI,CAAAA,CAAAA,CACP,WAAYS,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAK9I,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,EAAE,MACzD,CAAA,CACA,KAAOE,CAAAA,CAAAA,CAAYG,EAAoB,CACzC,CAAC,CAEKE,CAAAA,EAAAA,CAAuB4J,EAGvB7J,EAAN,CAAA,cAA4B8J,CAAc,CACxC,YAAYzC,CAAmC,CAAA,CAC7C,MAAMnH,EAAqBmH,CAAAA,CAAO,EACpC,CACF,ECxBA,IAAM1G,EAA4B,CAAA,oBAAA,CAC5BsP,GACJ,qJAEInP,CAAAA,EAAAA,CAA2BgP,wBAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CAClH,IAAM9H,CAAAA,EAAAA,CACN,YAAasP,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,KACjB,KAAOlI,CAAAA,CAAAA,CACP,UAAYS,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAK9I,CAAuB,CAAA,IAAA,CAAK,KAAM,CAAC,CAAA,CAAE,IAC1C,MAAQA,CAAAA,CAAAA,CAAuB,KAAK,IAAM,CAAA,CAAC,CAAE,CAAA,MAC/C,EACA,KAAOE,CAAAA,CAAAA,CAAYe,EAAyB,CAC9C,CAAC,CAEKE,CAAAA,EAAAA,CAA4BgJ,CAG5BjJ,CAAAA,EAAAA,CAAN,cAAiCkJ,CAAc,CAC7C,YAAYzC,CAAwC,CAAA,CAClD,MAAMvG,EAA0BuG,CAAAA,CAAO,EACzC,CACF,MCzBMtG,EAAoB,CAAA,YAAA,CACpBmP,EACJ,CAAA,8GAAA,CAEIhP,GAAmB4O,wBAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CAC1G,IAAM1H,CAAAA,EAAAA,CACN,WAAamP,CAAAA,EAAAA,CACb,eAAgB,IAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAOnI,EACP,UAAYS,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAK9I,CAAuB,CAAA,IAAA,CAAK,KAAM,CAAC,CAAA,CAAE,IAC1C,MAAQA,CAAAA,CAAAA,CAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MAC/C,CACA,CAAA,KAAA,CAAOE,EAAYmB,EAAiB,CACtC,CAAC,CAAA,CAEKE,GAAoB4I,CAGpB7I,CAAAA,EAAAA,CAAN,cAAyB8I,CAAc,CACrC,YAAYzC,CAAgC,CAAA,CAC1C,KAAMnG,CAAAA,EAAAA,CAAkBmG,CAAO,EACjC,CACF,ECzBMlG,IAAAA,EAAAA,CAA4B,qBAC5BgP,EACJ,CAAA,0QAAA,CAGI7O,GAA2BwO,wBAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CAClH,IAAA,CAAMtH,GACN,WAAagP,CAAAA,EAAAA,CACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAOpI,CACP,CAAA,UAAA,CAAYS,EACZ,MAAQ,CAAA,CACN,IAAK9I,CAAuB,CAAA,IAAA,CAAK,KAAM,CAAC,CAAA,CAAE,GAC1C,CAAA,MAAA,CAAQA,EAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MAC/C,CACA,CAAA,KAAA,CAAOE,CAAYuB,CAAAA,EAAyB,CAC9C,CAAC,CAAA,CAEKE,GAA4BwI,CAG5BzI,CAAAA,EAAAA,CAAN,cAAiC0I,CAAc,CAC7C,WAAYzC,CAAAA,CAAAA,CAAwC,CAClD,KAAM/F,CAAAA,EAAAA,CAA0B+F,CAAO,EACzC,CACF,EC/BM9F,IAAAA,EAAAA,CAAiB,UACjB6O,EACJ,CAAA,yHAAA,CAGI1O,GAAgBoO,wBAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CAC/F,IAAA,CAAM9G,EACN,CAAA,WAAA,CAAa6O,GACb,cAAgB,CAAA,OAAA,CAChB,eAAiB,CAAA,KAAA,CACjB,MAAOrI,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,IAAKtI,CAAuB,CAAA,cAAA,CAAe,KAAO,CAAA,CAAC,EAAE,GACrD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,MAAO,CAAC,CAAA,CAAE,MAC1D,CAAA,CACA,MAAOE,CAAY2B,CAAAA,EAAc,CACnC,CAAC,CAAA,CAEKE,GAAiBoI,CAGjBrI,CAAAA,EAAAA,CAAN,cAAsBsI,CAAc,CAClC,WAAYzC,CAAAA,CAAAA,CAA6B,CACvC,KAAA,CAAM3F,GAAe2F,CAAO,EAC9B,CACF,EC1BM1F,IAAAA,EAAAA,CAAsB,eACtB0O,EACJ,CAAA,gJAAA,CAGIvO,EAAqBgO,CAAAA,wBAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CACpG,KAAM1G,EACN,CAAA,WAAA,CAAa0O,EACb,CAAA,cAAA,CAAgB,QAChB,eAAiB,CAAA,KAAA,CACjB,MAAOtI,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,eAAe,KAAO,CAAA,CAAC,CAAE,CAAA,GAAA,CACrD,OAAQA,CAAuB,CAAA,cAAA,CAAe,KAAO,CAAA,CAAC,EAAE,MAC1D,CAAA,CACA,MAAOE,CAAY+B,CAAAA,EAAmB,CACxC,CAAC,CAAA,CAEKE,EAAsBgI,CAAAA,CAAAA,CAGtBjI,GAAN,cAA2BkI,CAAc,CACvC,WAAA,CAAYzC,EAAkC,CAC5C,KAAA,CAAMvF,EAAoBuF,CAAAA,CAAO,EACnC,CACF,EC1BMtF,IAAAA,EAAAA,CAAsB,cACtBuO,CAAAA,EAAAA,CACJ,8EAGIpO,EAAqB4N,CAAAA,wBAAAA,CAAgBpI,CAAsBW,CAAAA,CAA6B,EAAE,KAAM,CAAA,CACpG,IAAMtG,CAAAA,EAAAA,CACN,YAAauO,EACb,CAAA,cAAA,CAAgB,QAChB,eAAiB,CAAA,KAAA,CACjB,MAAOvI,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,cAAe,CAAA,KAAA,CAAO,CAAC,CAAE,CAAA,GAAA,CACrD,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,KAAO,CAAA,CAAC,EAAE,MAC1D,CAAA,CACA,MAAOE,CAAYmC,CAAAA,EAAmB,CACxC,CAAC,EAEKE,EAAsB4H,CAAAA,CAAAA,CAGtB7H,EAAN,CAAA,cAA2B8H,CAAc,CACvC,WAAA,CAAYzC,CAAkC,CAAA,CAC5C,MAAMnF,EAAoBmF,CAAAA,CAAO,EACnC,CACF,EC1BA,IAAMlF,GAAgC,wBAChCoO,CAAAA,EAAAA,CACJ,0KAGIjO,CAAAA,EAAAA,CAA+BwN,yBAAgBpI,CAAsBW,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CAC9G,IAAMlG,CAAAA,EAAAA,CACN,YAAaoO,EACb,CAAA,cAAA,CAAgB,MAChB,eAAiB,CAAA,IAAA,CACjB,KAAOxI,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKtI,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,EAAE,MACzD,CAAA,CACA,KAAOE,CAAAA,CAAAA,CAAYuC,EAA6B,CAClD,CAAC,CAEKE,CAAAA,EAAAA,CAAgCwH,EAGhCzH,EAAN,CAAA,cAAqC0H,CAAc,CACjD,YAAYzC,CAA4C,CAAA,CACtD,MAAM/E,EAA8B+E,CAAAA,CAAO,EAC7C,CACF,ECrBA,IAAM9E,EAA6B,CAAA,qBAAA,CAC7BiO,GAAiC,uEAEjC9N,CAAAA,EAAAA,CAA4BoN,wBAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CACnH,IAAMlG,CAAAA,EAAAA,CACN,YAAaiO,EACb,CAAA,cAAA,CAAgB,KAChB,CAAA,eAAA,CAAiB,KACjB,KAAOzI,CAAAA,CAAAA,CACP,UAAYS,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAK9I,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,CAAE,CAAA,MACzD,EACA,KAAOE,CAAAA,CAAAA,CAAY2C,EAA0B,CAC/C,CAAC,CAEKE,CAAAA,EAAAA,CAA6BoH,CAG7BrH,CAAAA,EAAAA,CAAN,cAAkCsH,CAAc,CAC9C,YAAYzC,CAAyC,CAAA,CACnD,MAAM3E,EAA2B2E,CAAAA,CAAO,EAC1C,CACF,MC7BM1E,EAAqB,CAAA,aAAA,CACrB8N,EACJ,CAAA,gMAAA,CAGI3N,GAAoBgN,wBAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAE,CAAA,KAAA,CAAM,CACnG,IAAM1F,CAAAA,EAAAA,CACN,WAAa8N,CAAAA,EAAAA,CACb,eAAgB,KAChB,CAAA,eAAA,CAAiB,IACjB,CAAA,KAAA,CAAO1I,EACP,UAAYC,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAKtI,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,IACpD,MAAQA,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,MACzD,CACA,CAAA,KAAA,CAAOE,EAAY+C,EAAkB,CACvC,CAAC,CAAA,CAEKE,GAAqBgH,CAGrBjH,CAAAA,EAAAA,CAAN,cAA0BkH,CAAc,CACtC,YAAYzC,CAAiC,CAAA,CAC3C,KAAMvE,CAAAA,EAAAA,CAAmBuE,CAAO,EAClC,CACF,ECrBMtE,IAAAA,EAAAA,CAAe,QACf2N,EAAmB,CAAA,gEAAA,CAEnBxN,GAAc4M,wBAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CACrG,IAAA,CAAM1F,GACN,WAAa2N,CAAAA,EAAAA,CACb,cAAgB,CAAA,IAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAO3I,CACP,CAAA,UAAA,CAAYS,EACZ,MAAQ,CAAA,CACN,IAAK9I,CAAuB,CAAA,IAAA,CAAK,KAAM,CAAC,CAAA,CAAE,GAC1C,CAAA,MAAA,CAAQA,EAAuB,IAAK,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MAC/C,CACA,CAAA,KAAA,CAAOE,CAAYmD,CAAAA,EAAY,CACjC,CAAC,CAAA,CAEKE,GAAe4G,CAGf7G,CAAAA,EAAAA,CAAN,cAAoB8G,CAAc,CAChC,WAAYzC,CAAAA,CAAAA,CAA2B,CACrC,KAAMnE,CAAAA,EAAAA,CAAamE,CAAO,EAC5B,CACF,EC7BMlD,IAAAA,EAAAA,CAA2B,oBAC3BwM,EAA+B,CAAA,2FAAA,CAE/BrM,GAA0BwL,wBAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CACzG,IAAA,CAAMlE,EACN,CAAA,WAAA,CAAawM,GACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,MAAO5I,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,IAAKtI,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,EAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CAAA,CACA,MAAOE,CAAYuE,CAAAA,EAAwB,CAC7C,CAAC,CAAA,CAEKE,GAA2BwF,CAG3BzF,CAAAA,EAAAA,CAAN,cAAgC0F,CAAc,CAC5C,WAAYzC,CAAAA,CAAAA,CAAuC,CACjD,KAAA,CAAM/C,GAAyB+C,CAAO,EACxC,CACF,ECxBMlE,IAAAA,EAAAA,CAA2B,oBAC3ByN,EAA+B,CAAA,2FAAA,CAE/BtN,EAA0BwM,CAAAA,wBAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CACzG,KAAMlF,EACN,CAAA,WAAA,CAAayN,EACb,CAAA,cAAA,CAAgB,MAChB,eAAiB,CAAA,IAAA,CACjB,MAAO7I,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,EAAE,GACpD,CAAA,MAAA,CAAQA,EAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAA,CAAE,MACzD,CACA,CAAA,KAAA,CAAOE,EAAYuD,EAAwB,CAC7C,CAAC,CAEKE,CAAAA,EAAAA,CAA2BwG,CAG3BzG,CAAAA,EAAAA,CAAN,cAAgC0G,CAAc,CAC5C,WAAYzC,CAAAA,CAAAA,CAAuC,CACjD,KAAM/D,CAAAA,EAAAA,CAAyB+D,CAAO,EACxC,CACF,MCxBMtD,EAAgC,CAAA,wBAAA,CAChC8M,EACJ,CAAA,8JAAA,CAGI3M,GAA+B4L,wBAAgBpI,CAAAA,CAAAA,CAAsBW,CAA6B,CAAA,CAAE,MAAM,CAC9G,IAAA,CAAMtE,EACN,CAAA,WAAA,CAAa8M,GACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAO9I,EACP,UAAYC,CAAAA,CAAAA,CACZ,MAAQ,CAAA,CACN,IAAKtI,CAAuB,CAAA,cAAA,CAAe,IAAM,CAAA,CAAC,EAAE,GACpD,CAAA,MAAA,CAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CACA,CAAA,KAAA,CAAOE,EAAYmE,EAA6B,CAClD,CAAC,CAAA,CAEKE,GAAgC4F,CAGhC7F,CAAAA,EAAAA,CAAN,cAAqC8F,CAAc,CACjD,WAAYzC,CAAAA,CAAAA,CAA4C,CACtD,KAAA,CAAMnD,GAA8BmD,CAAO,EAC7C,CACF,EC1BM9D,IAAAA,EAAAA,CAAqB,cACrBsN,EACJ,CAAA,8JAAA,CAGInN,EAAoBoM,CAAAA,wBAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CACnG,KAAM9E,EACN,CAAA,WAAA,CAAasN,GACb,cAAgB,CAAA,KAAA,CAChB,gBAAiB,IACjB,CAAA,KAAA,CAAO9I,CACP,CAAA,UAAA,CAAYC,EACZ,MAAQ,CAAA,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,eAAe,IAAM,CAAA,CAAC,CAAE,CAAA,GAAA,CACpD,OAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CACA,CAAA,KAAA,CAAOE,CAAY2D,CAAAA,EAAkB,CACvC,CAAC,CAAA,CAEKE,EAAqBoG,CAAAA,CAAAA,CAGrBrG,GAAN,cAA0BsG,CAAc,CACtC,WAAA,CAAYzC,EAAiC,CAC3C,KAAA,CAAM3D,GAAmB2D,CAAO,EAClC,CACF,EC1BM1D,IAAAA,EAAAA,CAAgB,QAChBmN,CAAAA,EAAAA,CACJ,+JAGIhN,EAAegM,CAAAA,wBAAAA,CAAgBpI,CAAsBW,CAAAA,CAA6B,EAAE,KAAM,CAAA,CAC9F,KAAM1E,EACN,CAAA,WAAA,CAAamN,GACb,cAAgB,CAAA,KAAA,CAChB,eAAiB,CAAA,IAAA,CACjB,MAAO/I,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,cAAe,CAAA,IAAA,CAAM,CAAC,CAAE,CAAA,GAAA,CACpD,OAAQA,CAAuB,CAAA,cAAA,CAAe,KAAM,CAAC,CAAA,CAAE,MACzD,CAAA,CACA,MAAOE,CAAY+D,CAAAA,EAAa,CAClC,CAAC,EAEKE,EAAgBgG,CAAAA,CAAAA,CAGhBjG,EAAN,CAAA,cAAqBkG,CAAc,CACjC,WAAA,CAAYzC,EAA4B,CACtC,KAAA,CAAMvD,GAAcuD,CAAO,EAC7B,CACF,EC1BA,IAAM1C,GAAuB,eACvBoM,CAAAA,EAAAA,CACJ,kIAEIjM,CAAAA,EAAAA,CAAsBgL,yBAAgBpI,CAAsBW,CAAAA,CAA6B,EAAE,KAAM,CAAA,CACrG,KAAM1D,EACN,CAAA,WAAA,CAAaoM,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,GAAA,CACjB,KAAOhJ,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKtI,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,GAAA,CAC/C,OAAQA,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,EAAE,MACpD,CAAA,CACA,KAAOE,CAAAA,CAAAA,CAAY+E,EAAoB,CACzC,CAAC,CAEKE,CAAAA,EAAAA,CAAuBgF,EAGvBjF,EAAN,CAAA,cAA4BkF,CAAc,CACxC,WAAA,CAAYzC,EAAmC,CAC7C,KAAA,CAAMvC,EAAqBuC,CAAAA,CAAO,EACpC,CACF,ECzBA,IAAM9C,EAAY,CAAA,IAAA,CACZyM,GACJ,6IAEItM,CAAAA,EAAAA,CAAWoL,yBAAgBpI,CAAsBW,CAAAA,CAA6B,EAAE,KAAM,CAAA,CAC1F,IAAM9D,CAAAA,EAAAA,CACN,YAAayM,EACb,CAAA,cAAA,CAAgB,GAChB,CAAA,eAAA,CAAiB,IACjB,KAAOjJ,CAAAA,CAAAA,CACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKtI,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,GAAA,CAC/C,MAAQA,CAAAA,CAAAA,CAAuB,QAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,MACpD,EACA,KAAOE,CAAAA,CAAAA,CAAY2E,EAAS,CAC9B,CAAC,CAEKE,CAAAA,EAAAA,CAAYoF,EAGZrF,EAAN,CAAA,cAAiBsF,CAAc,CAC7B,WAAA,CAAYzC,CAAwB,CAAA,CAClC,MAAM3C,EAAU2C,CAAAA,CAAO,EACzB,CACF,MC1BM9B,EAAuB,CAAA,eAAA,CACvB0L,GACJ,qGAEIvL,CAAAA,EAAAA,CAAsBoK,yBAAgBpI,CAAsBW,CAAAA,CAA6B,CAAE,CAAA,KAAA,CAAM,CACrG,IAAM9C,CAAAA,EAAAA,CACN,WAAa0L,CAAAA,EAAAA,CACb,eAAgB,GAChB,CAAA,eAAA,CAAiB,GACjB,CAAA,KAAA,CAAOlJ,EACP,UAAYC,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAKtI,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAA,CAAE,IAC/C,MAAQA,CAAAA,CAAAA,CAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,MACpD,CACF,CAAC,EAEK+F,EAAuBoE,CAAAA,CAAAA,CAGvBrE,GAAN,cAA4BsE,CAAc,CACxC,WAAYzC,CAAAA,CAAAA,CAAmC,CAC7C,KAAA,CAAM3B,GAAqB2B,CAAO,EACpC,CACF,ECxBA,IAAM1B,GAAY,IACZuL,CAAAA,EAAAA,CACJ,sGAEIpL,EAAWgK,CAAAA,wBAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,KAAM,CAAA,CAC1F,KAAM1C,EACN,CAAA,WAAA,CAAauL,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,GAAA,CACjB,KAAOnJ,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,QAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,GAAA,CAC/C,OAAQA,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,EAAE,MACpD,CACF,CAAC,CAAA,CAEKmG,GAAYgE,CAGZjE,CAAAA,EAAAA,CAAN,cAAiBkE,CAAc,CAC7B,YAAYzC,CAAwB,CAAA,CAClC,KAAMvB,CAAAA,EAAAA,CAAUuB,CAAO,EACzB,CACF,ECxBMlC,IAAAA,EAAAA,CAAgB,UAChBgM,EACJ,CAAA,yJAAA,CAEI7L,GAAewK,wBAAgBpI,CAAAA,CAAAA,CAAsBe,CAAqC,CAAE,CAAA,KAAA,CAAM,CACtG,IAAA,CAAMtD,GACN,WAAagM,CAAAA,EAAAA,CACb,cAAgB,CAAA,GAAA,CAChB,gBAAiB,GACjB,CAAA,KAAA,CAAOpJ,CACP,CAAA,UAAA,CAAYS,EACZ,MAAQ,CAAA,CACN,IAAK9I,CAAuB,CAAA,OAAA,CAAQ,IAAQ,CAAC,CAAA,CAAE,GAC/C,CAAA,MAAA,CAAQA,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAA,CAAE,MACpD,CACF,CAAC,CAEK2F,CAAAA,EAAAA,CAAgBwE,EAGhBzE,EAAN,CAAA,cAAqB0E,CAAc,CACjC,WAAA,CAAYzC,EAA4B,CACtC,KAAA,CAAM/B,EAAc+B,CAAAA,CAAO,EAC7B,CACF,ECxBA,IAAMtC,EAA0B,CAAA,oBAAA,CAC1BqM,GACJ,yJAEIlM,CAAAA,EAAAA,CAAyB4K,yBAAgBpI,CAAsBe,CAAAA,CAAqC,EAAE,KAAM,CAAA,CAChH,IAAM1D,CAAAA,EAAAA,CACN,YAAaqM,EACb,CAAA,cAAA,CAAgB,GAChB,CAAA,eAAA,CAAiB,IACjB,KAAOrJ,CAAAA,CAAAA,CACP,UAAYS,CAAAA,CAAAA,CACZ,OAAQ,CACN,GAAA,CAAK9I,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,GAAA,CAC/C,MAAQA,CAAAA,CAAAA,CAAuB,QAAQ,GAAQ,CAAA,CAAC,CAAE,CAAA,MACpD,CACF,CAAC,CAAA,CAEKuF,EAA0B4E,CAAAA,CAAAA,CAG1B7E,GAAN,cAA+B8E,CAAc,CAC3C,WAAYzC,CAAAA,CAAAA,CAAsC,CAChD,KAAMnC,CAAAA,EAAAA,CAAwBmC,CAAO,EACvC,CACF,ECnBMtB,IAAAA,EAAAA,CAA4B,oBAC5BsL,CAAAA,EAAAA,CACJ,6IAEInL,EAA2B4J,CAAAA,wBAAAA,CAAgBpI,EAAsBW,CAA6B,CAAA,CAAE,MAAM,CAC1G,IAAA,CAAMtC,EACN,CAAA,WAAA,CAAasL,GACb,cAAgB,CAAA,GAAA,CAChB,eAAiB,CAAA,GAAA,CACjB,MAAOtJ,CACP,CAAA,UAAA,CAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAKtI,CAAAA,CAAAA,CAAuB,QAAQ,GAAQ,CAAA,CAAC,EAAE,GAC/C,CAAA,MAAA,CAAQA,CAAuB,CAAA,OAAA,CAAQ,IAAQ,CAAC,CAAA,CAAE,MACpD,CACF,CAAC,CAEKuG,CAAAA,EAAAA,CAA4B4D,CAG5B7D,CAAAA,EAAAA,CAAN,cAAiC8D,CAAc,CAC7C,YAAYzC,CAAwC,CAAA,CAClD,MAAMnB,EAA0BmB,CAAAA,CAAO,EACzC,CACF,ECxBA,IAAMlB,GAAiB,SACjBmL,CAAAA,EAAAA,CACJ,4IAEIhL,CAAAA,EAAAA,CAAgBwJ,yBAAgBpI,CAAsBW,CAAAA,CAA6B,EAAE,KAAM,CAAA,CAC/F,KAAMlC,EACN,CAAA,WAAA,CAAamL,EACb,CAAA,cAAA,CAAgB,IAChB,eAAiB,CAAA,GAAA,CACjB,KAAOvJ,CAAAA,CAAAA,CACP,WAAYC,CACZ,CAAA,MAAA,CAAQ,CACN,GAAA,CAAKtI,EAAuB,OAAQ,CAAA,GAAA,CAAQ,CAAC,CAAE,CAAA,GAAA,CAC/C,OAAQA,CAAuB,CAAA,OAAA,CAAQ,GAAQ,CAAA,CAAC,EAAE,MACpD,CACF,CAAC,CAAA,CAEK2G,GAAiBwD,CAGjBzD,CAAAA,EAAAA,CAAN,cAAsB0D,CAAc,CAClC,WAAYzC,CAAAA,CAAAA,CAA6B,CACvC,KAAMf,CAAAA,EAAAA,CAAee,CAAO,EAC9B,CACF,EChCA,IAAMkK,EAAyE,CAC7EC,kCAAAA,CACAC,mCACF,CAEMC,CAAAA,CAAAA,CAAqCvT,MAAE,IAAK,CAAA,CAACqT,kCAA8BC,CAAAA,mCAA6B,CAAC,ECRzGE,IAAAA,EAAAA,CAA8BxT,KAAE,CAAA,MAAA,CAAO,CAC3C,MAAQA,CAAAA,KAAAA,CAAE,QAAQ,MAAM,CAAA,CACxB,MAAOA,KAAE,CAAA,MAAA,EACT,CAAA,IAAA,CAAMA,MAAE,KACNA,CAAAA,KAAAA,CAAE,MAAO,CAAA,CACP,MAAOA,KAAE,CAAA,MAAA,EACT,CAAA,MAAA,CAAQA,MAAE,OAAQ,CAAA,WAAW,EAC7B,SAAWA,CAAAA,KAAAA,CAAE,MAAMA,KAAE,CAAA,MAAA,EAAQ,CAAA,CAAE,GAAGA,KAAE,CAAA,MAAA,EAAS,CAAA,MAAA,EAAQ,CACvD,CAAC,CACH,CAAA,CACA,MAAOA,KAAE,CAAA,MAAA,CAAO,CACd,aAAeA,CAAAA,KAAAA,CAAE,QAAS,CAAA,WAAA,EAC1B,CAAA,YAAA,CAAcA,MAAE,MAAO,EAAA,CAAE,WAAY,EACvC,CAAC,CACH,CAAC,MCdKyT,EAA8BzT,CAAAA,KAAAA,CACjC,QACA,CAAA,GAAA,CAAI,CAAC,CAAA,CACL,GAAGA,KAAE,CAAA,KAAA,CAAMA,KAAE,CAAA,MAAA,GAAS,GAAI,CAAA,CAAC,CAAC,CAAA,CAAE,IAAI,CAAC,CAAC,EACpC,EAAGA,CAAAA,KAAAA,CAAE,MAAMA,KAAE,CAAA,MAAA,EAAS,CAAA,GAAA,GAAM,WAAY,EAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAA,CACjD,EAAGA,CAAAA,KAAAA,CAAE,MAAMA,KAAE,CAAA,KAAA,CAAMA,MAAE,MAAO,EAAA,CAAE,KAAM,CAAA,WAAA,EAAa,CAAA,CAAE,IAAI,CAAC,CAAC,CAAE,CAAA,GAAA,CAAI,CAAC,CAAC,CAAA,CAG9D0T,EAAyB1T,CAAAA,KAAAA,CAAE,OAAO,CACtC,KAAA,CAAOA,MAAE,MAAO,EAAA,CAAE,IAAI,CAAC,CAAA,CAAE,QAAS,EAAA,CAClC,MAAOyT,EACP,CAAA,eAAA,CAAiBzT,KAAE,CAAA,IAAA,CAAK,CAAC,OAAS,CAAA,QAAQ,CAAC,CAAA,CAAE,UAC7C,CAAA,UAAA,CAAYA,MAAE,MAAO,EAAA,CAAE,KAAM,CAAA,GAAA,CAAI,CAAC,CAAA,CAAE,UACtC,CAAC,ECmBD,IAAM2T,EAA4B3T,KAAE,CAAA,MAAA,CAAO,CACzC,SAAA,CAAWA,MAAE,MAAO,EAAA,CACpB,MAAQA,CAAAA,KAAAA,CAAE,QACV,CAAA,OAAA,CAASA,KAAE,CAAA,MAAA,GAAS,GAAI,EAAA,CAAE,UAC1B,CAAA,gBAAA,CAAkBA,MAAE,MAAO,EAAA,CAAE,GAAI,EAAA,CAAE,UACrC,CAAC,CAGK4T,CAAAA,CAAAA,CAAN,KAA+E,CAS7E,WAAA,CAAYhI,CAAuC1C,CAAAA,CAAAA,CAAwC,CAR3F,IAAS,CAAA,OAAA,CAAU,KASjB,IAAMI,CAAAA,CAAgBqK,EAA0B,KAAMzK,CAAAA,CAAO,CAC7D,CAAA,IAAA,CAAK,YAAc0C,CACnB,CAAA,IAAA,CAAK,SAAYtC,CAAAA,CAAAA,CAAc,UAC/B,IAAK,CAAA,MAAA,CAASA,CAAc,CAAA,MAAA,CAC5B,KAAK,OAAUuC,CAAAA,gCAAAA,CAAwBvC,EAAc,OAAW3H,EAAAA,CAAAA,CAAO,OAAO,CAC9E,CAAA,IAAA,CAAK,gBAAmBkK,CAAAA,gCAAAA,CAAwBvC,EAAc,gBAAoB,EAAA,CAAA,EAAG,IAAK,CAAA,OAAO,aAAa,EAChH,CAEA,iBAA6B,EAAA,CAC3B,OAAO,IAAK,CAAA,OACd,CAEA,iBAAiC,EAAA,CAC/B,OAAO,CACL,aAAA,CAAe,CAAU,OAAA,EAAA,IAAA,CAAK,MAAM,CACpC,CAAA,CAAA,cAAA,CAAgB,kBAClB,CACF,CAEA,gBAA+B,EAAA,CAC7B,OAAO,CACL,MAAO,IAAK,CAAA,WAAA,CAAY,IAC1B,CACF,CAQA,cAAcwC,CAAyE,CAAA,CAErF,IAAMC,CAAAA,CAAiBC,GAA6B,CAClD,IAAMC,CAAQ,CAAA,kBAAA,CACRC,EAAwC,CAC5C,CAAA,CAAG,IACH,CAAA,CAAA,CAAG,IACH,CAAG,CAAA,GAAA,CACH,GAAI,CACN,CAAA,CAEIC,EACAC,CAAU,CAAA,CAAA,CACd,KAAQD,CAAAA,CAAAA,CAAQF,EAAM,IAAKD,CAAAA,CAAQ,CAAO,IAAA,IAAA,EAAM,CAC9C,IAAM/L,CAAAA,CAAQ,QAASkM,CAAAA,CAAAA,CAAM,CAAC,CAAC,CAAA,CACzBE,EAAOF,CAAM,CAAA,CAAC,EACpBC,CAAWnM,EAAAA,CAAAA,CAAQiM,CAAUG,CAAAA,CAAI,EACnC,CAEA,OAAOD,CACT,CAAA,CAEIE,EAAuB,CACvBC,CAAAA,CAAAA,CAAqB,CACnBC,CAAAA,CAAAA,CAAc,GAChBV,CAAgB,CAAA,4BAA4B,IAC9CQ,CAAuBP,CAAAA,CAAAA,CAAcD,EAAgB,4BAA4B,CAAC,CAEhFA,CAAAA,CAAAA,CAAAA,CAAgB,0BAA0B,CAC5CS,GAAAA,CAAAA,CAAqBR,CAAcD,CAAAA,CAAAA,CAAgB,0BAA0B,CAAC,CAAA,CAAA,CAIhF,IAAMW,CAAAA,CAAU,KAAK,GAAIH,CAAAA,CAAAA,CAAsBC,CAAkB,CACjE,CAAA,OAAO,CAAE,WAAAC,CAAAA,CAAAA,CAAa,OAAAC,CAAAA,CAAQ,CAChC,CAEA,aAAA,CAAcoH,CAAyC,CAAA,CACrD,OAAOA,CAAS,CAAA,QAAA,CAAS,MAAO,CAAA,CAAC7K,EAAK6D,CAAY7D,GAAAA,CAAAA,CAAM6D,EAAQ,MAAQ,CAAA,CAAC,CAC3E,CAEA,qBAAA,CAAsBA,CAIpB,CAAA,CACA,IAAMC,CAAc4G,CAAAA,EAAAA,CAAuB,SAAU7G,CAAAA,CAAO,EAC5D,GAAI,CAACC,CAAY,CAAA,OAAA,CACf,MAAM,IAAIC,iCAAAA,CAAyB,CAAE,IAAM,CAAA,uBAAA,CAAyB,MAAOD,CAAY,CAAA,KAAM,CAAC,CAAA,CAGhG,IAAME,CAAgBF,CAAAA,CAAAA,CAAY,IAE5B3D,CAAAA,CAAAA,CAAY6D,EAAc,KAE1BC,CAAAA,CAAAA,CAAU,CACd,cAAA,CAAgBD,EAAc,eAC9B,CAAA,UAAA,CAAYA,EAAc,UAC5B,CAAA,CACME,EAASC,YAAO,EAAA,CAAE,KAAMC,CAAAA,+BAAAA,CAAuBH,CAAO,CAAC,CAAA,CAEzD6G,CACAC,CAAAA,CAAAA,CACJ,OAAI,OAAO/G,CAAAA,CAAc,KAAU,EAAA,QAAA,CACjC+G,EAAkBV,kCAEd,CAAA,OAAOrG,EAAc,KAAM,CAAA,CAAC,GAAM,QACpC+G,CAAAA,CAAAA,CAAkBV,kCAElBU,CAAAA,CAAAA,CAAkBT,oCAIlBS,CAAoBV,GAAAA,kCAAAA,CAClB,OAAOrG,CAAAA,CAAc,OAAU,QACjC8G,CAAAA,CAAAA,CAAoB,CAClB,QAAA,CAAUC,EACV,QAAU,CAAA,CAAC/G,EAAc,KAAK,CAChC,EAEA8G,CAAoB,CAAA,CAClB,QAAUC,CAAAA,CAAAA,CACV,SAAU/G,CAAc,CAAA,KAC1B,CAGE,CAAA,OAAOA,EAAc,KAAM,CAAA,CAAC,CAAM,EAAA,QAAA,CACpC8G,EAAoB,CAClB,QAAA,CAAUC,EACV,QAAU,CAAA,CAAC/G,EAAc,KAAiB,CAC5C,CAEA8G,CAAAA,CAAAA,CAAoB,CAClB,QAAUC,CAAAA,CAAAA,CACV,QAAU/G,CAAAA,CAAAA,CAAc,KAC1B,CAIG,CAAA,CACL,SAAA7D,CAAAA,CAAAA,CACA,OAAA+D,CACA,CAAA,iBAAA,CAAA4G,CACF,CACF,CAGA,gBAAgB5G,CAAoB2G,CAAAA,CAAAA,CAA8C,CAChF,IAAMzF,EAAgB,IAAK,CAAA,WAAA,CAAY,MAAO,CAAA,MAAA,CAAO,UAAUlB,CAAM,CAAA,CACrE,GAAI,CAACkB,EAAc,OACjB,CAAA,MAAM,IAAIC,2BAAmB,CAAA,CAC3B,KAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,WAAY,CAAA,IAAI,IAC1D,KAAOD,CAAAA,CAAAA,CAAc,KACvB,CAAC,EAGH,IAAME,CAAAA,CAAeF,CAAc,CAAA,IAAA,CACnC,cAAO,IAAKE,CAAAA,CAA0B,EAAE,OAASrF,CAAAA,CAAAA,EAAQ,CACvD,GAAI,CAAC,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIA,CAAAA,CAAG,EAClC,MAAM,IAAIoF,4BAAmB,CAC3B,IAAA,CAAM,CAA+B,4BAAA,EAAA,IAAA,CAAK,YAAY,IAAI,CAAA,CAAA,CAAA,CAC1D,MAAO,IAAI,KAAA,CAAM,yBAAyBpF,CAAG,CAAA;AAAA,8BACvB,EAAA,MAAA,CAAO,KAAK,IAAK,CAAA,WAAA,CAAY,OAAO,GAAG,CAAA,CAAE,KAAK,IAAI,CAAC,GAAG,CAC9E,CAAC,CAEL,CAAC,CAAA,CAEyB,OAAO,IAAKqF,CAAAA,CAAY,CAAE,CAAA,MAAA,CAAO,CAACtF,CAAAA,CAAKC,IAAQ,CAEvE,IAAMwF,EADM,IAAK,CAAA,WAAA,CAAY,OAAO,GAAIxF,CAAAA,CAAG,EACtB,KACfyF,CAAAA,CAAAA,CAAaJ,EAAarF,CAAG,CAAA,CACnC,OAAAD,CAAIyF,CAAAA,CAAQ,EAAIC,CACT1F,CAAAA,CACT,CAAG,CAAA,EAAgB,CAGrB,CAEA,0BAA2B6K,CAAAA,CAAAA,CAA6C,CACtE,IAAMG,CAAAA,CAAkBC,yBAAoB,CAAA,SAAA,CAAUJ,CAAQ,CAC9D,CAAA,GAAI,CAACG,CAAgB,CAAA,OAAA,CACnB,MAAM,IAAIE,sCAAAA,CAA8B,CAAE,IAAM,CAAA,4BAAA,CAA8B,KAAOF,CAAAA,CAAAA,CAAgB,KAAM,CAAC,EAS9G,OAAO,CACL,MAFqBA,CAAgB,CAAA,IAAA,CAEf,QACxB,CACF,CAGM,oBAAoB9G,CAAqB2G,CAAAA,CAAAA,CAAoD,QAAAtE,CAAA,CAAA,IAAA,CAAA,IAAA,CAAA,WAAA,CACjG,OAAO,IAAI,OAAA,CAASC,GAAY,CAC9BA,CAAAA,CAAQ,IAAK,CAAA,gBAAgB,EAC/B,CAAC,CACH,CAGM,CAAA,CAAA,uBAAA,CAAwBtC,EAAqB2G,CAAwD,CAAA,CAAA,OAAAtE,EAAA,IACzG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ,CAAA,IAAA,CAAK,mBAAmB,EAClC,CAAC,CACH,CAAA,CAAA,CAEM,oBAAqBtC,CAAAA,CAAAA,CAAoB2G,CAAsD,CAAA,CAAA,OAAAtE,EAAA,IACnG,CAAA,IAAA,CAAA,WAAA,CAAA,OAAO,IAAI,OAASC,CAAAA,CAAAA,EAAY,CAC9BA,CAAQ/O,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAAA,CAAA,GACH,IAAK,CAAA,gBAAA,IACL,IAAK,CAAA,eAAA,CAAgByM,EAAQ2G,CAAQ,CAAA,CAAA,CACrC,KAAK,0BAA2BA,CAAAA,CAAQ,CAC5C,CAAA,EACH,CAAC,CACH,GAEA,8BAA+BlE,CAAAA,CAAAA,CAAsC,CACnE,IAAI3O,CAAAA,CACE4O,EAAO4D,EAA4B,CAAA,SAAA,CAAU7D,CAAQ,CAC3D,CAAA,GAAIC,EAAK,OAAS,CAAA,CAChB,IAAME,CAAiBF,CAAAA,CAAAA,CAAK,KAC5B5O,CAAiB,CAAA,OAAO8O,CAAe,CAAA,IAAA,CAAK,CAAC,CAAA,CAAE,WAAc,QAAWqE,CAAAA,4BAAAA,CAAyBC,4BACjG,IAAMC,CAAAA,CAAavE,EAAe,IAAK,CAAA,GAAA,CAAKwE,CACtC,EAAA,OAAOA,CAAK,CAAA,SAAA,EAAc,SACrB,CACL,KAAA,CAAOA,EAAK,KACZ,CAAA,SAAA,CAAWA,EAAK,SAClB,CAAA,CAEO,CACL,KAAA,CAAOA,CAAK,CAAA,KAAA,CACZ,UAAWA,CAAK,CAAA,SAClB,CAEH,CAED,CAAA,OAAO,CACL,cAAgBtT,CAAAA,CAAAA,CAChB,WAAYqT,CACZ,CAAA,KAAA,CAAO,CACL,WAAavE,CAAAA,CAAAA,CAAe,MAAM,YACpC,CACF,CACF,CAEA,MAAM,IAAID,2BAAAA,CAAmB,CAAE,IAAA,CAAM,8BAA+B,KAAOD,CAAAA,CAAAA,CAAK,KAAM,CAAC,CACzF,CACF,MC7RMxH,EAA+B,CAAA,wBAAA,CAC/BmM,GAAmC,mFAEnChM,CAAAA,EAAAA,CAA8BiM,8BAAqBjB,CAAkC,CAAA,CAAE,KAAM,CAAA,CACjG,IAAMnL,CAAAA,EAAAA,CACN,YAAamM,EACb,CAAA,UAAA,CAAYnB,EACZ,cAAgB,CAAA,IAAA,CAChB,gBAAiB,IACjB,CAAA,MAAA,CAAQ,CACN,GAAK5R,CAAAA,CAAAA,CAA4B,MAAO,CAAA,GAAA,CACxC,OAAQA,CAA4B,CAAA,IAAA,GAAO,MAC7C,CACF,CAAC,CAAA,CAEK8G,EAAgCqL,CAAAA,CAAAA,CAGhCtL,GAAN,cAAoCuL,CAAmB,CACrD,WAAY1K,CAAAA,CAAAA,CAA4C,CACtD,KAAMX,CAAAA,EAAAA,CAA6BW,CAAO,EAC5C,CACF,ECtBMV,IAAAA,EAAAA,CAAgC,yBAChCiM,EAAoC,CAAA,+DAAA,CAEpC9L,EAA+B6L,CAAAA,6BAAAA,CAAqBjB,CAAkC,CAAA,CAAE,MAAM,CAClG,IAAA,CAAM/K,GACN,WAAaiM,CAAAA,EAAAA,CACb,WAAYrB,CACZ,CAAA,cAAA,CAAgB,KAChB,eAAiB,CAAA,IAAA,CACjB,OAAQ,CACN,GAAA,CAAK5R,EAA4B,UAAW,CAAA,IAAI,EAAE,GAClD,CAAA,MAAA,CAAQA,CAA4B,CAAA,UAAA,CAAW,IAAI,CAAA,CAAE,MACvD,CACF,CAAC,EAEKkH,EAAiCiL,CAAAA,CAAAA,CAGjClL,GAAN,cAAqCmL,CAAmB,CACtD,WAAY1K,CAAAA,CAAAA,CAA6C,CACvD,KAAMP,CAAAA,EAAAA,CAA8BO,CAAO,EAC7C,CACF,ECtBMN,IAAAA,EAAAA,CAAgC,yBAChC8L,EAAoC,CAAA,qEAAA,CAEpC3L,GAA+ByL,6BAAqBjB,CAAAA,CAAkC,EAAE,KAAM,CAAA,CAClG,KAAM3K,EACN,CAAA,WAAA,CAAa8L,GACb,UAAYtB,CAAAA,CAAAA,CACZ,eAAgB,IAChB,CAAA,eAAA,CAAiB,KACjB,MAAQ,CAAA,CACN,GAAK5R,CAAAA,CAAAA,CAA4B,UAAW,CAAA,IAAI,EAAE,GAClD,CAAA,MAAA,CAAQA,EAA4B,UAAW,CAAA,IAAI,EAAE,MACvD,CACF,CAAC,CAAA,CAEKsH,EAAiC6K,CAAAA,CAAAA,CAGjC9K,GAAN,cAAqC+K,CAAmB,CACtD,WAAY1K,CAAAA,CAAAA,CAA6C,CACvD,KAAMH,CAAAA,EAAAA,CAA8BG,CAAO,EAC7C,CACF","file":"index.js","sourcesContent":["import { CHAT_CONFIG, MultiStringConfigItem, RangeConfigItem, SelectBooleanConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nconst temperature = RangeConfigItem({\n  param: \"temperature\",\n  title: CHAT_CONFIG.TEMPERATURE.title,\n  description: CHAT_CONFIG.TEMPERATURE.description,\n  min: 0,\n  max: 2,\n  step: 0.01,\n  default: 1,\n});\n\nconst maxTokens = (maxOutputTokens: number) =>\n  RangeConfigItem({\n    param: \"max_completion_tokens\",\n    title: CHAT_CONFIG.MAX_TOKENS.title,\n    description: CHAT_CONFIG.MAX_TOKENS.description,\n    min: 0,\n    max: maxOutputTokens,\n    step: 1,\n    default: 0,\n  });\n\nconst stop = (maxSequences: number) =>\n  MultiStringConfigItem({\n    param: \"stop\",\n    title: CHAT_CONFIG.STOP(maxSequences).title,\n    description: CHAT_CONFIG.STOP(maxSequences).description,\n    max: maxSequences,\n  });\n\nconst topP = RangeConfigItem({\n  param: \"top_p\",\n  title: CHAT_CONFIG.TOP_P.title,\n  description: CHAT_CONFIG.TOP_P.description,\n  min: 0,\n  max: 1,\n  step: 0.01,\n  default: 1,\n});\n\nconst frequencyPenalty = RangeConfigItem({\n  param: \"frequency_penalty\",\n  title: CHAT_CONFIG.FREQUENCY_PENALTY.title,\n  description: CHAT_CONFIG.FREQUENCY_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst presencePenalty = RangeConfigItem({\n  param: \"presence_penalty\",\n  title: CHAT_CONFIG.PRESENCE_PENALTY.title,\n  description: CHAT_CONFIG.PRESENCE_PENALTY.description,\n  min: -2,\n  max: 2,\n  step: 0.01,\n  default: 0,\n});\n\nconst seed = RangeConfigItem({\n  param: \"seed\",\n  title: CHAT_CONFIG.SEED.title,\n  description: CHAT_CONFIG.SEED.description,\n  min: 0,\n  max: 1000000,\n  step: 1,\n  default: 0,\n});\n\nconst logProbs = SelectBooleanConfigItem({\n  param: \"logprobs\",\n  title: CHAT_CONFIG.LOG_PROBS.title,\n  description: CHAT_CONFIG.LOG_PROBS.description,\n  default: false,\n});\n\nconst topLogProbs = RangeConfigItem({\n  param: \"top_logprobs\",\n  title: CHAT_CONFIG.TOP_LOG_PROBS.title,\n  description: CHAT_CONFIG.TOP_LOG_PROBS.description,\n  min: 0,\n  max: 20,\n  step: 1,\n  default: 0,\n});\n\nconst toolChoice = SelectStringConfigItem({\n  param: \"tool_choice\",\n  title: \"Tool choice\",\n  description:\n    \"Controls which (if any) tool is called by the model. 'none' means the model will not call a function. 'auto' means the model can pick between generating a message or calling a tool.\",\n  default: \"auto\",\n  choices: [\"auto\", \"required\", \"none\"],\n});\n\nexport { frequencyPenalty, logProbs, maxTokens, presencePenalty, seed, stop, temperature, toolChoice, topLogProbs, topP };\n","import { z } from \"zod\";\n\nimport {\n  frequencyPenalty,\n  logProbs,\n  maxTokens,\n  presencePenalty,\n  seed,\n  stop,\n  temperature,\n  toolChoice,\n  topLogProbs,\n  topP,\n} from \"./common.config.chat-model.openai\";\n\nconst ChatModelBaseConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  z.object({\n    temperature: temperature.schema,\n    maxTokens: maxTokens(maxOutputTokens).schema,\n    stop: stop(maxSequences).schema,\n    topP: topP.schema,\n    frequencyPenalty: frequencyPenalty.schema,\n    presencePenalty: presencePenalty.schema,\n    seed: seed.schema.transform((value) => (value === 0 ? undefined : value)),\n    logProbs: logProbs.schema,\n    topLogProbs: topLogProbs.schema,\n    toolChoice: toolChoice.schema,\n  });\n\nconst ChatModelBaseConfigDef = (maxOutputTokens: number, maxSequences: number) =>\n  ({\n    temperature: temperature.def,\n    maxTokens: maxTokens(maxOutputTokens).def,\n    stop: stop(maxSequences).def,\n    topP: topP.def,\n    frequencyPenalty: frequencyPenalty.def,\n    presencePenalty: presencePenalty.def,\n    seed: seed.def,\n    logProbs: logProbs.def,\n    topLogProbs: topLogProbs.def,\n    toolChoice: toolChoice.def,\n  }) as const;\n\nexport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema };\n","import { CHAT_CONFIG, RangeConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nimport { ChatModelResponseSchemaConfigDef, ChatModelResponseSchemaConfigSchema } from \"./response-schema.config.chat-model.openai\";\n\n// o1 models only support temperature = 1.0\nconst temperature = RangeConfigItem({\n  param: \"temperature\",\n  title: CHAT_CONFIG.TEMPERATURE.title,\n  description: CHAT_CONFIG.TEMPERATURE.description,\n  min: 1,\n  max: 1,\n  step: 0.01,\n  default: 1,\n});\n\nconst reasoningEffort = SelectStringConfigItem({\n  param: \"reasoning_effort\",\n  title: \"Reasoning Effort\",\n  description:\n    \"Constrains effort on reasoning for reasoning models. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\",\n  default: \"medium\",\n  choices: [\"low\", \"medium\", \"high\"],\n});\nconst ChatModelOSeriesConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelResponseSchemaConfigDef(maxOutputTokens, maxSequences),\n  temperature: temperature.def,\n  reasoningEffort: reasoningEffort.def,\n});\n\nconst ChatModelOSeriesConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelResponseSchemaConfigSchema(maxOutputTokens, maxSequences).extend({\n    temperature: temperature.schema,\n    reasoningEffort: reasoningEffort.schema,\n  });\n\nexport { ChatModelOSeriesConfigDef, ChatModelOSeriesConfigSchema };\n","import { CHAT_CONFIG, ObjectSchemaConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\nimport { ResponseSchema } from \"@adaline/types\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.openai\";\n\nconst responseSchema = ObjectSchemaConfigItem({\n  param: \"response_schema\",\n  title: CHAT_CONFIG.RESPONSE_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_SCHEMA.description,\n  objectSchema: ResponseSchema,\n});\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT_WITH_SCHEMA.description,\n  default: \"text\",\n  choices: [\"text\", \"json_object\", \"json_schema\"],\n});\n\nconst ChatModelResponseSchemaConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n  responseFormat: responseFormat.def,\n  responseSchema: responseSchema.def,\n});\n\nconst ChatModelResponseSchemaConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelBaseConfigSchema(maxOutputTokens, maxSequences).extend({\n    responseFormat: responseFormat.schema,\n    responseSchema: responseSchema.schema,\n  });\n\nexport { ChatModelResponseSchemaConfigDef, ChatModelResponseSchemaConfigSchema };\n","import { CHAT_CONFIG, SelectStringConfigItem } from \"@adaline/provider\";\n\nimport { ChatModelBaseConfigDef, ChatModelBaseConfigSchema } from \"./base.config.chat-model.openai\";\n\nconst responseFormat = SelectStringConfigItem({\n  param: \"response_format\",\n  title: CHAT_CONFIG.RESPONSE_FORMAT.title,\n  description: CHAT_CONFIG.RESPONSE_FORMAT.description,\n  default: \"text\",\n  choices: [\"text\", \"json_object\"],\n});\n\nconst ChatModelResponseFormatConfigDef = (maxOutputTokens: number, maxSequences: number) => ({\n  ...ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n  responseFormat: responseFormat.def,\n});\n\nconst ChatModelResponseFormatConfigSchema = (maxOutputTokens: number, maxSequences: number) =>\n  ChatModelBaseConfigSchema(maxOutputTokens, maxSequences).extend({\n    responseFormat: responseFormat.schema,\n  });\n\nexport { ChatModelResponseFormatConfigDef, ChatModelResponseFormatConfigSchema };\n","import { RangeConfigItem, SelectStringConfigItem } from \"@adaline/provider\";\n\nconst encodingFormat = SelectStringConfigItem({\n  param: \"encoding_format\",\n  title: \"Encoding format\",\n  description: \"Select the encoding format for the word embedding.\",\n  default: \"float\",\n  choices: [\"float\", \"base64\"],\n});\n\nconst dimensions = (maxDimensions: number) =>\n  RangeConfigItem({\n    param: \"dimensions\",\n    title: \"Dimensions\",\n    description: \"Select the number of dimensions for the word embedding.\",\n    min: 1,\n    max: maxDimensions,\n    step: 1,\n    default: maxDimensions,\n  });\n\nexport { encodingFormat, dimensions };\n","import { z } from \"zod\";\n\nimport { encodingFormat } from \"./common.config.embedding-model.openai\";\n\nconst EmbeddingModelBaseConfigSchema = () =>\n  z.object({\n    encodingFormat: encodingFormat.schema,\n  });\n\nconst EmbeddingModelBaseConfigDef = () =>\n  ({\n    encodingFormat: encodingFormat.def,\n  }) as const;\n\nexport { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema };\n","import { EmbeddingModelBaseConfigDef, EmbeddingModelBaseConfigSchema } from \"./base.config.embedding-model.openai\";\nimport { dimensions } from \"./common.config.embedding-model.openai\";\n\nconst EmbeddingModelDimensionsConfigSchema = (maxDimensions: number) =>\n  EmbeddingModelBaseConfigSchema().extend({\n    dimensions: dimensions(maxDimensions).schema,\n  });\n\nconst EmbeddingModelDimensionsConfigDef = (maxDimensions: number) =>\n  ({\n    ...EmbeddingModelBaseConfigDef(),\n    dimensions: dimensions(maxDimensions).def,\n  }) as const;\n\nexport { EmbeddingModelDimensionsConfigDef, EmbeddingModelDimensionsConfigSchema };\n","import {\n  ChatModelBaseConfigDef,\n  ChatModelBaseConfigSchema,\n  ChatModelOSeriesConfigDef,\n  ChatModelOSeriesConfigSchema,\n  ChatModelResponseFormatConfigDef,\n  ChatModelResponseFormatConfigSchema,\n  ChatModelResponseSchemaConfigDef,\n  ChatModelResponseSchemaConfigSchema,\n} from \"./chat-model\";\nimport {\n  EmbeddingModelBaseConfigDef,\n  EmbeddingModelBaseConfigSchema,\n  EmbeddingModelDimensionsConfigDef,\n  EmbeddingModelDimensionsConfigSchema,\n} from \"./embedding-model\";\n\nconst OpenAIChatModelConfigs = {\n  base: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelBaseConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelBaseConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  responseFormat: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelResponseFormatConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelResponseFormatConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  responseSchema: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelResponseSchemaConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelResponseSchemaConfigSchema(maxOutputTokens, maxSequences),\n  }),\n  oSeries: (maxOutputTokens: number, maxSequences: number) => ({\n    def: ChatModelOSeriesConfigDef(maxOutputTokens, maxSequences),\n    schema: ChatModelOSeriesConfigSchema(maxOutputTokens, maxSequences),\n  }),\n} as const;\n\nconst OpenAIEmbeddingModelConfigs = {\n  base: () => ({\n    def: EmbeddingModelBaseConfigDef(),\n    schema: EmbeddingModelBaseConfigSchema(),\n  }),\n  dimensions: (maxDimensions: number) => ({\n    def: EmbeddingModelDimensionsConfigDef(maxDimensions),\n    schema: EmbeddingModelDimensionsConfigSchema(maxDimensions),\n  }),\n} as const;\n\nexport { OpenAIChatModelConfigs, OpenAIEmbeddingModelConfigs };\n","{\n  \"gpt-3.5-turbo-0125\": {\n    \"modelName\": \"gpt-3.5-turbo-0125\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-3.5-turbo-1106\": {\n    \"modelName\": \"gpt-3.5-turbo-1106\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-3.5-turbo\": {\n    \"modelName\": \"gpt-3.5-turbo\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.5,\n            \"outputPricePerMillion\": 1.5\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-0125-preview\": {\n    \"modelName\": \"gpt-4-0125-preview\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-0613\": {\n    \"modelName\": \"gpt-4-0613\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-1106-preview\": {\n    \"modelName\": \"gpt-4-1106-preview\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-turbo-2024-04-09\": {\n    \"modelName\": \"gpt-4-turbo-2024-04-09\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10,\n            \"outputPricePerMillion\": 30\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-turbo-preview\": {\n    \"modelName\": \"gpt-4-turbo-preview\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10,\n            \"outputPricePerMillion\": 30\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4-turbo\": {\n    \"modelName\": \"gpt-4-turbo\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10,\n            \"outputPricePerMillion\": 30\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4\": {\n    \"modelName\": \"gpt-4\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 30,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-2024-05-13\": {\n    \"modelName\": \"gpt-4o-2024-05-13\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 5,\n            \"outputPricePerMillion\": 20\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-2024-08-06\": {\n    \"modelName\": \"gpt-4o-2024-08-06\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.5,\n            \"outputPricePerMillion\": 10\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-mini-2024-07-18\": {\n    \"modelName\": \"gpt-4o-mini-2024-07-18\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.6,\n            \"outputPricePerMillion\": 2.4\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o-mini\": {\n    \"modelName\": \"gpt-4o-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.6,\n            \"outputPricePerMillion\": 2.4\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4o\": {\n    \"modelName\": \"gpt-4o\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 5,\n            \"outputPricePerMillion\": 20\n          }\n        }\n      }\n    ]\n  },\n  \"o1-2024-12-17\": {\n    \"modelName\": \"o1-2024-12-17\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 15,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"o1\": {\n    \"modelName\": \"o1\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 15,\n            \"outputPricePerMillion\": 60\n          }\n        }\n      }\n    ]\n  },\n  \"o3-mini-2025-01-31\": {\n    \"modelName\": \"o3-mini-2025-01-31\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"o3-mini\": {\n    \"modelName\": \"o3-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"o3-2025-04-16\": {\n    \"modelName\": \"o3-2025-04-16\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10.0,\n            \"outputPricePerMillion\": 40.0\n          }\n        }\n      }\n    ]\n  },\n  \"o3\": {\n    \"modelName\": \"o3\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 10.0,\n            \"outputPricePerMillion\": 40.0\n          }\n        }\n      }\n    ]\n  },\n  \"o4-mini-2025-04-16\": {\n    \"modelName\": \"o4-mini-2025-04-16\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"o4-mini\": {\n    \"modelName\": \"o4-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 1.1,\n            \"outputPricePerMillion\": 4.4\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4.1\": {\n    \"modelName\": \"gpt-4.1\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 2.0,\n            \"outputPricePerMillion\": 8.0\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4.1-mini\": {\n    \"modelName\": \"gpt-4.1-mini\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.4,\n            \"outputPricePerMillion\": 1.6\n          }\n        }\n      }\n    ]\n  },\n  \"gpt-4.1-nano\": {\n    \"modelName\": \"gpt-4.1-nano\",\n    \"currency\": \"USD\",\n    \"tokenRanges\": [\n      {\n        \"minTokens\": 0,\n        \"maxTokens\": null,\n        \"prices\": {\n          \"base\": {\n            \"inputPricePerMillion\": 0.1,\n            \"outputPricePerMillion\": 0.4\n          }\n        }\n      }\n    ]\n  }\n}","import { z } from \"zod\";\n\nimport { ChatModelSchemaType, ChatModelV1, EmbeddingModelSchemaType, EmbeddingModelV1, ProviderError, ProviderV1 } from \"@adaline/provider\";\n\nimport * as Models from \"../models\";\n\nconst ProviderLiteral = \"openai\";\nclass OpenAI<C extends Models.BaseChatModelOptionsType, E extends Models.BaseEmbeddingModelOptionsType> implements ProviderV1<C, E> {\n  readonly version = \"v1\" as const;\n  readonly name = ProviderLiteral;\n  static readonly baseUrl = \"https://api.openai.com/v1\";\n\n  private readonly chatModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): ChatModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: ChatModelSchemaType;\n    }\n  > = {\n    [Models.GPT_3_5_TurboLiteral]: {\n      model: Models.GPT_3_5_Turbo,\n      modelOptions: Models.GPT_3_5_TurboOptions,\n      modelSchema: Models.GPT_3_5_TurboSchema,\n    },\n    [Models.GPT_3_5_Turbo_0125Literal]: {\n      model: Models.GPT_3_5_Turbo_0125,\n      modelOptions: Models.GPT_3_5_Turbo_0125Options,\n      modelSchema: Models.GPT_3_5_Turbo_0125Schema,\n    },\n    [Models.GPT_3_5_Turbo_1106Literal]: {\n      model: Models.GPT_3_5_Turbo_1106,\n      modelOptions: Models.GPT_3_5_Turbo_1106Options,\n      modelSchema: Models.GPT_3_5_Turbo_1106Schema,\n    },\n    [Models.GPT_4_0125_PreviewLiteral]: {\n      model: Models.GPT_4_0125_Preview,\n      modelOptions: Models.GPT_4_0125_PreviewOptions,\n      modelSchema: Models.GPT_4_0125_PreviewSchema,\n    },\n    [Models.GPT_4_0613Literal]: {\n      model: Models.GPT_4_0613,\n      modelOptions: Models.GPT_4_0613Options,\n      modelSchema: Models.GPT_4_0613Schema,\n    },\n    [Models.GPT_4_1106_PreviewLiteral]: {\n      model: Models.GPT_4_1106_Preview,\n      modelOptions: Models.GPT_4_1106_PreviewOptions,\n      modelSchema: Models.GPT_4_1106_PreviewSchema,\n    },\n    [Models.GPT_4_1Literal]: {\n      model: Models.GPT_4_1,\n      modelOptions: Models.GPT_4_1Options,\n      modelSchema: Models.GPT_4_1Schema,\n    },\n    [Models.GPT_4_1_MiniLiteral]: {\n      model: Models.GPT_4_1_Mini,\n      modelOptions: Models.GPT_4_1_MiniOptions,\n      modelSchema: Models.GPT_4_1_MiniSchema,\n    },\n    [Models.GPT_4_1_NanoLiteral]: {\n      model: Models.GPT_4_1_Nano,\n      modelOptions: Models.GPT_4_1_NanoOptions,\n      modelSchema: Models.GPT_4_1_NanoSchema,\n    },\n    [Models.GPT_4_Turbo_2024_04_09Literal]: {\n      model: Models.GPT_4_Turbo_2024_04_09,\n      modelOptions: Models.GPT_4_Turbo_2024_04_09Options,\n      modelSchema: Models.GPT_4_Turbo_2024_04_09Schema,\n    },\n    [Models.GPT_4_Turbo_PreviewLiteral]: {\n      model: Models.GPT_4_Turbo_Preview,\n      modelOptions: Models.GPT_4_Turbo_PreviewOptions,\n      modelSchema: Models.GPT_4_Turbo_PreviewSchema,\n    },\n    [Models.GPT_4_TurboLiteral]: {\n      model: Models.GPT_4_Turbo,\n      modelOptions: Models.GPT_4_TurboOptions,\n      modelSchema: Models.GPT_4_TurboSchema,\n    },\n    [Models.GPT_4Literal]: {\n      model: Models.GPT_4,\n      modelOptions: Models.GPT_4Options,\n      modelSchema: Models.GPT_4Schema,\n    },\n    [Models.GPT_4o_2024_08_06Literal]: {\n      model: Models.GPT_4o_2024_08_06,\n      modelOptions: Models.GPT_4o_2024_08_06Options,\n      modelSchema: Models.GPT_4o_2024_08_06Schema,\n    },\n    [Models.GPT_4o_MiniLiteral]: {\n      model: Models.GPT_4o_Mini,\n      modelOptions: Models.GPT_4o_MiniOptions,\n      modelSchema: Models.GPT_4o_MiniSchema,\n    },\n    [Models.GPT_4oLiteral]: {\n      model: Models.GPT_4o,\n      modelOptions: Models.GPT_4oOptions,\n      modelSchema: Models.GPT_4oSchema,\n    },\n    [Models.GPT_4o_Mini_2024_07_18Literal]: {\n      model: Models.GPT_4o_Mini_2024_07_18,\n      modelOptions: Models.GPT_4o_Mini_2024_07_18Options,\n      modelSchema: Models.GPT_4o_Mini_2024_07_18Schema,\n    },\n    [Models.GPT_4o_2024_05_13Literal]: {\n      model: Models.GPT_4o_2024_05_13,\n      modelOptions: Models.GPT_4o_2024_05_13Options,\n      modelSchema: Models.GPT_4o_2024_05_13Schema,\n    },\n    [Models.O1Literal]: {\n      model: Models.O1,\n      modelOptions: Models.O1Options,\n      modelSchema: Models.O1Schema,\n    },\n    [Models.O1_2024_12_17Literal]: {\n      model: Models.O1_2024_12_17,\n      modelOptions: Models.O1_2024_12_17Options,\n      modelSchema: Models.O1_2024_12_17Schema,\n    },\n    [Models.O3Mini2025_01_31Literal]: {\n      model: Models.O3Mini2025_01_31,\n      modelOptions: Models.O3Mini2025_01_31Options,\n      modelSchema: Models.O3Mini2025_01_31Schema,\n    },\n    [Models.O3MiniLiteral]: {\n      model: Models.O3Mini,\n      modelOptions: Models.O3MiniOptions,\n      modelSchema: Models.O3MiniSchema,\n    },\n    [Models.O3_2025_04_16Literal]: {\n      model: Models.O3_2025_04_16,\n      modelOptions: Models.O3_2025_04_16Options,\n      modelSchema: Models.O3_2025_04_16Schema,\n    },\n    [Models.O3Literal]: {\n      model: Models.O3,\n      modelOptions: Models.O3Options,\n      modelSchema: Models.O3Schema,\n    },\n    [Models.O4_Mini_2025_04_16Literal]: {\n      model: Models.O4_Mini_2025_04_16,\n      modelOptions: Models.O4_Mini_2025_04_16Options,\n      modelSchema: Models.O4_Mini_2025_04_16Schema,\n    },\n    [Models.O4_MiniLiteral]: {\n      model: Models.O4_Mini,\n      modelOptions: Models.O4_MiniOptions,\n      modelSchema: Models.O4_MiniSchema,\n    },\n  };\n\n  private readonly embeddingModelFactories: Record<\n    string,\n    {\n      model: { new (options: any): EmbeddingModelV1 };\n      modelOptions: z.ZodType<any>;\n      modelSchema: EmbeddingModelSchemaType;\n    }\n  > = {\n    [Models.Text_Embedding_Ada002Literal]: {\n      model: Models.Text_Embedding_Ada002,\n      modelOptions: Models.Text_Embedding_Ada002_Options,\n      modelSchema: Models.Text_Embedding_Ada002Schema,\n    },\n    [Models.Text_Embedding_3_SmallLiteral]: {\n      model: Models.Text_Embedding_3_Small,\n      modelOptions: Models.Text_Embedding_3_Small_Options,\n      modelSchema: Models.Text_Embedding_3_SmallSchema,\n    },\n    [Models.Text_Embedding_3_LargeLiteral]: {\n      model: Models.Text_Embedding_3_Large,\n      modelOptions: Models.Text_Embedding_3_Large_Options,\n      modelSchema: Models.Text_Embedding_3_LargeSchema,\n    },\n  };\n\n  chatModelLiterals(): string[] {\n    return Object.keys(this.chatModelFactories);\n  }\n\n  chatModelSchemas(): Record<string, ChatModelSchemaType> {\n    return Object.keys(this.chatModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.chatModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, ChatModelSchemaType>\n    );\n  }\n\n  chatModel(options: C): ChatModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.chatModelFactories)) {\n      throw new ProviderError({\n        info: `OpenAI chat model: ${modelName} not found`,\n        cause: new Error(`OpenAI chat model: ${modelName} not found, available chat models: \n          [${this.chatModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.chatModelFactories[modelName].model;\n    const parsedOptions = this.chatModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n\n  embeddingModelLiterals(): string[] {\n    return Object.keys(this.embeddingModelFactories);\n  }\n\n  embeddingModelSchemas(): Record<string, EmbeddingModelSchemaType> {\n    return Object.keys(this.embeddingModelFactories).reduce(\n      (acc, key) => {\n        acc[key] = this.embeddingModelFactories[key].modelSchema;\n        return acc;\n      },\n      {} as Record<string, EmbeddingModelSchemaType>\n    );\n  }\n\n  embeddingModel(options: E): EmbeddingModelV1 {\n    const modelName = options.modelName;\n    if (!(modelName in this.embeddingModelFactories)) {\n      throw new ProviderError({\n        info: `OpenAI embedding model: ${modelName} not found`,\n        cause: new Error(`OpenAI embedding model: ${modelName} not found, available embedding models: \n          [${this.embeddingModelLiterals().join(\", \")}]`),\n      });\n    }\n\n    const model = this.embeddingModelFactories[modelName].model;\n    const parsedOptions = this.embeddingModelFactories[modelName].modelOptions.parse(options);\n    return new model(parsedOptions);\n  }\n}\n\nexport { OpenAI, ProviderLiteral };\n","import { z } from \"zod\";\n\nimport { AssistantRoleLiteral, SystemRoleLiteral, ToolRoleLiteral, UserRoleLiteral } from \"@adaline/types\";\n\nconst OpenAIChatModelRoles = z.enum([SystemRoleLiteral, UserRoleLiteral, AssistantRoleLiteral, ToolRoleLiteral]);\n\nconst OpenAIChatModelRolesMap = {\n  system: SystemRoleLiteral,\n  user: UserRoleLiteral,\n  assistant: AssistantRoleLiteral,\n  tool: ToolRoleLiteral,\n} as const;\n\nexport { OpenAIChatModelRoles, OpenAIChatModelRolesMap };\n","import { z } from \"zod\";\n\nimport { ChatModelSchemaType } from \"@adaline/provider\";\nimport { ImageModalityLiteral, TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral } from \"@adaline/types\";\n\nconst OpenAIChatModelModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst OpenAIChatModelModalitiesEnum = z.enum([\n  TextModalityLiteral,\n  ImageModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n]);\n\nconst OpenAIChatModelTextModalities: ChatModelSchemaType[\"modalities\"] = [TextModalityLiteral];\n\nconst OpenAIChatModelTextModalitiesEnum = z.enum([TextModalityLiteral]);\n\nconst OpenAIChatModelTextToolModalities: ChatModelSchemaType[\"modalities\"] = [\n  TextModalityLiteral,\n  ToolCallModalityLiteral,\n  ToolResponseModalityLiteral,\n];\n\nconst OpenAIChatModelTextToolModalitiesEnum = z.enum([TextModalityLiteral, ToolCallModalityLiteral, ToolResponseModalityLiteral]);\n\nexport {\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelModalities,\n  OpenAIChatModelTextModalitiesEnum,\n  OpenAIChatModelTextModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n  OpenAIChatModelTextToolModalities,\n};\n","import { z } from \"zod\";\n\nconst OpenAIBaseLogProb = z.object({\n  token: z.string(),\n  logprob: z.number(),\n  bytes: z.array(z.number()).nullable(),\n});\n\nconst OpenAILogProb = z\n  .object({\n    content: z\n      .array(\n        OpenAIBaseLogProb.extend({\n          top_logprobs: z.array(OpenAIBaseLogProb),\n        })\n      )\n      .nullable()\n      .optional(),\n    refusal: z\n      .array(\n        OpenAIBaseLogProb.extend({\n          top_logprobs: z.array(OpenAIBaseLogProb),\n        })\n      )\n      .nullable()\n      .optional(),\n  })\n  .nullable();\n\nconst OpenAIToolCallsCompleteChatResponse = z.array(\n  z.object({\n    id: z.string().min(1),\n    type: z.enum([\"function\"]),\n    function: z.object({\n      name: z.string(),\n      arguments: z.string(),\n    }),\n  })\n);\n\nconst OpenAICompleteChatResponse = z.object({\n  id: z.string(),\n  object: z.literal(\"chat.completion\"),\n  created: z.number(),\n  model: z.string(),\n  system_fingerprint: z.string().nullable(),\n  choices: z.array(\n    z.object({\n      index: z.number(),\n      message: z.object({\n        role: z.string(),\n        content: z.string().nullable().optional(),\n        tool_calls: OpenAIToolCallsCompleteChatResponse.optional(),\n        refusal: z.string().nullable().optional(),\n      }),\n      logprobs: OpenAILogProb.optional(),\n      finish_reason: z.string(),\n    })\n  ),\n  usage: z.object({\n    prompt_tokens: z.number(),\n    completion_tokens: z.number(),\n    total_tokens: z.number(),\n  }),\n});\ntype OpenAICompleteChatResponseType = z.infer<typeof OpenAICompleteChatResponse>;\n\nconst OpenAIToolCallsStreamChatResponse = z.array(\n  z.object({\n    index: z.number().int(),\n    id: z.string().min(1).optional(),\n    type: z.enum([\"function\"]).optional(),\n    function: z\n      .object({\n        name: z.string().min(1).optional(),\n        arguments: z.string().optional(),\n      })\n      .optional(),\n  })\n);\n\nconst OpenAIStreamChatResponse = z.object({\n  id: z.string(),\n  object: z.string(),\n  created: z.number(),\n  model: z.string(),\n  system_fingerprint: z.string().nullable().optional(),\n  choices: z.array(\n    z.object({\n      index: z.number(),\n      delta: z\n        .object({\n          content: z.string().nullable().optional(),\n          tool_calls: OpenAIToolCallsStreamChatResponse.optional(),\n          refusal: z.string().nullable().optional(),\n        })\n        .or(z.object({})),\n      logprobs: OpenAILogProb.optional(),\n      finish_reason: z.string().nullable(),\n    })\n  ),\n  usage: z\n    .object({\n      prompt_tokens: z.number(),\n      completion_tokens: z.number(),\n      total_tokens: z.number(),\n    })\n    .nullable()\n    .optional(),\n});\ntype OpenAIStreamChatResponseType = z.infer<typeof OpenAIStreamChatResponse>;\n\nexport {\n  OpenAICompleteChatResponse,\n  OpenAIStreamChatResponse,\n  OpenAIToolCallsCompleteChatResponse,\n  OpenAIToolCallsStreamChatResponse,\n  type OpenAICompleteChatResponseType,\n  type OpenAIStreamChatResponseType,\n};\n","import { z } from \"zod\";\n\nconst OpenAIChatRequestTool = z.object({\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n    description: z.string().min(1).optional(),\n    strict: z.boolean().optional(),\n    parameters: z.any(),\n  }),\n});\ntype OpenAIChatRequestToolType = z.infer<typeof OpenAIChatRequestTool>;\n\nconst OpenAIChatRequestToolChoiceEnum = z.enum([\"none\", \"auto\", \"required\"]);\ntype OpenAIChatRequestToolChoiceEnumType = z.infer<typeof OpenAIChatRequestToolChoiceEnum>;\n\nconst OpenAIChatRequestToolChoiceFunction = z.object({\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n  }),\n});\ntype OpenAIChatRequestToolChoiceFunctionType = z.infer<typeof OpenAIChatRequestToolChoiceFunction>;\n\nconst OpenAIChatRequestResponseFormat = z\n  .object({\n    type: z.enum([\"text\", \"json_object\"]),\n  })\n  .or(\n    z.object({\n      type: z.literal(\"json_schema\"),\n      json_schema: z.object({\n        name: z.string().min(1),\n        description: z.string().min(1).optional(),\n        strict: z.boolean().optional(),\n        schema: z.any(),\n      }),\n    })\n  );\ntype OpenAIChatRequestResponseFormatType = z.infer<typeof OpenAIChatRequestResponseFormat>;\n\nconst OpenAIChatRequestTextContent = z.object({\n  text: z.string().min(1),\n  type: z.literal(\"text\"),\n});\ntype OpenAIChatRequestTextContentType = z.infer<typeof OpenAIChatRequestTextContent>;\n\nconst OpenAIChatRequestImageContent = z.object({\n  type: z.literal(\"image_url\"),\n  image_url: z.object({\n    url: z.string().url().min(1),\n    detail: z.enum([\"low\", \"high\", \"auto\"]).optional(),\n  }),\n});\ntype OpenAIChatRequestImageContentType = z.infer<typeof OpenAIChatRequestImageContent>;\n\nconst OpenAIChatRequestToolCallContent = z.object({\n  id: z.string().min(1),\n  type: z.literal(\"function\"),\n  function: z.object({\n    name: z.string().min(1),\n    arguments: z.string().min(1),\n  }),\n});\ntype OpenAIChatRequestToolCallContentType = z.infer<typeof OpenAIChatRequestToolCallContent>;\n\nconst OpenAIChatRequestSystemMessage = z.object({\n  role: z.literal(\"system\"),\n  content: z.string().min(1).or(z.array(OpenAIChatRequestTextContent).min(1)),\n});\ntype OpenAIChatRequestSystemMessageType = z.infer<typeof OpenAIChatRequestSystemMessage>;\n\nconst OpenAIChatRequestUserMessage = z.object({\n  role: z.literal(\"user\"),\n  content: z\n    .string()\n    .min(1)\n    .or(z.array(z.union([OpenAIChatRequestTextContent, OpenAIChatRequestImageContent])).min(1)),\n});\ntype OpenAIChatRequestUserMessageType = z.infer<typeof OpenAIChatRequestUserMessage>;\n\nconst OpenAIChatRequestAssistantMessage = z.object({\n  role: z.literal(\"assistant\"),\n  content: z.string().min(1).or(z.array(OpenAIChatRequestTextContent).min(1)).optional(),\n  tool_calls: z.array(OpenAIChatRequestToolCallContent).min(1).optional(),\n});\ntype OpenAIChatRequestAssistantMessageType = z.infer<typeof OpenAIChatRequestAssistantMessage>;\n\nconst OpenAIChatRequestToolMessage = z.object({\n  role: z.literal(\"tool\"),\n  tool_call_id: z.string().min(1),\n  content: z.string().min(1),\n});\ntype OpenAIChatRequestToolMessageType = z.infer<typeof OpenAIChatRequestToolMessage>;\n\nconst OpenAIChatRequestMessage = z.union([\n  OpenAIChatRequestSystemMessage,\n  OpenAIChatRequestUserMessage,\n  OpenAIChatRequestAssistantMessage,\n  OpenAIChatRequestToolMessage,\n]);\ntype OpenAIChatRequestMessageType = z.infer<typeof OpenAIChatRequestMessage>;\n\nconst OpenAIChatRequest = z.object({\n  model: z.string().min(1).optional(),\n  messages: z.array(OpenAIChatRequestMessage).min(1),\n  frequency_penalty: z.number().min(-2).max(2).nullable().optional(),\n  logprobs: z.boolean().nullable().optional(),\n  top_logprobs: z.number().min(0).max(20).nullable().optional(),\n  max_completion_tokens: z.number().min(0).nullable().optional(),\n  presence_penalty: z.number().min(-2).max(2).nullable().optional(),\n  response_format: OpenAIChatRequestResponseFormat.optional(),\n  seed: z.number().nullable().optional(),\n  stop: z.string().or(z.array(z.string()).max(4)).nullable().optional(),\n  temperature: z.number().min(0).max(2).nullable().optional(),\n  top_p: z.number().min(0).max(1).nullable().optional(),\n  tools: z.array(OpenAIChatRequestTool).optional(),\n  tool_choice: OpenAIChatRequestToolChoiceEnum.or(OpenAIChatRequestToolChoiceFunction).optional(),\n});\ntype OpenAIChatRequestType = z.infer<typeof OpenAIChatRequest>;\n\nexport {\n  OpenAIChatRequest,\n  OpenAIChatRequestAssistantMessage,\n  OpenAIChatRequestImageContent,\n  OpenAIChatRequestMessage,\n  OpenAIChatRequestResponseFormat,\n  OpenAIChatRequestSystemMessage,\n  OpenAIChatRequestTextContent,\n  OpenAIChatRequestTool,\n  OpenAIChatRequestToolCallContent,\n  OpenAIChatRequestToolChoiceEnum,\n  OpenAIChatRequestToolChoiceFunction,\n  OpenAIChatRequestToolMessage,\n  OpenAIChatRequestUserMessage,\n  type OpenAIChatRequestAssistantMessageType,\n  type OpenAIChatRequestImageContentType,\n  type OpenAIChatRequestMessageType,\n  type OpenAIChatRequestResponseFormatType,\n  type OpenAIChatRequestSystemMessageType,\n  type OpenAIChatRequestTextContentType,\n  type OpenAIChatRequestToolCallContentType,\n  type OpenAIChatRequestToolChoiceEnumType,\n  type OpenAIChatRequestToolChoiceFunctionType,\n  type OpenAIChatRequestToolMessageType,\n  type OpenAIChatRequestToolType,\n  type OpenAIChatRequestType,\n  type OpenAIChatRequestUserMessageType,\n};\n","import { z } from \"zod\";\n\nimport {\n  ChatModelSchemaType,\n  ChatModelV1,\n  getMimeTypeFromBase64,\n  HeadersType,\n  InvalidConfigError,\n  InvalidMessagesError,\n  InvalidModelRequestError,\n  InvalidToolsError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  SelectStringConfigItemDefType,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\nimport {\n  AssistantRoleLiteral,\n  Base64ImageContentTypeLiteral,\n  Base64ImageContentValueType,\n  ChatLogProbsType,\n  ChatModelPriceType,\n  ChatResponseType,\n  ChatUsageType,\n  Config,\n  ConfigType,\n  ContentType,\n  createPartialTextMessage,\n  createPartialToolCallMessage,\n  createTextContent,\n  createToolCallContent,\n  ImageModalityLiteral,\n  Message,\n  MessageType,\n  PartialChatResponseType,\n  SystemRoleLiteral,\n  TextModalityLiteral,\n  Tool,\n  ToolCallContentType,\n  ToolCallModalityLiteral,\n  ToolResponseContentType,\n  ToolResponseModalityLiteral,\n  ToolRoleLiteral,\n  ToolType,\n  UrlImageContentTypeLiteral,\n  UserRoleLiteral,\n} from \"@adaline/types\";\n\nimport pricingData from \"../pricing.json\";\nimport { OpenAI } from \"./../../provider/provider.openai\";\nimport {\n  OpenAIChatRequest,\n  OpenAIChatRequestImageContentType,\n  OpenAIChatRequestTextContentType,\n  OpenAIChatRequestToolType,\n  OpenAIChatRequestType,\n  OpenAICompleteChatResponse,\n  OpenAICompleteChatResponseType,\n  OpenAIStreamChatResponse,\n  OpenAIStreamChatResponseType,\n} from \"./types\";\n\nconst BaseChatModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  completeChatUrl: z.string().url().optional(),\n  streamChatUrl: z.string().url().optional(),\n  organization: z.string().optional(),\n});\ntype BaseChatModelOptionsType = z.infer<typeof BaseChatModelOptions>;\n\nclass BaseChatModel implements ChatModelV1<ChatModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: ChatModelSchemaType;\n  modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly streamChatUrl: string;\n  private readonly completeChatUrl: string;\n  private readonly organization: string | undefined;\n\n  constructor(modelSchema: ChatModelSchemaType, options: BaseChatModelOptionsType) {\n    const parsedOptions = BaseChatModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || OpenAI.baseUrl);\n    this.streamChatUrl = urlWithoutTrailingSlash(parsedOptions.streamChatUrl || `${this.baseUrl}/chat/completions`);\n    this.completeChatUrl = urlWithoutTrailingSlash(parsedOptions.completeChatUrl || `${this.baseUrl}/chat/completions`);\n    this.organization = parsedOptions.organization;\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      Authorization: `Bearer ${this.apiKey}`,\n      \"Content-Type\": \"application/json\",\n      ...(this.organization ? { \"OpenAI-Organization\": this.organization } : {}),\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelName,\n    };\n  }\n\n  // x-ratelimit-limit-requests\tThe maximum number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-limit-tokens\tThe maximum number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-requests The remaining number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-tokens\tThe remaining number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-reset-requests\tThe time until the rate limit (based on requests) resets to its initial state.\n  // x-ratelimit-reset-tokens\tThe time until the rate limit (based on tokens) resets to its initial state.\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    // parse duration from header value of format \"6m0s\" or \"21s\" or \"41ms\" or \"2s81ms\" or \"5h50m30ms\" and such\n    const parseDuration = (duration: string): number => {\n      const regex = /(\\d+)(h|m|s|ms)/g;\n      const timeUnits: { [unit: string]: number } = {\n        h: 3600000, // 1 hour = 60 * 60 * 1000 ms\n        m: 60000, // 1 minute = 60 * 1000 ms\n        s: 1000, // 1 second = 1000 ms\n        ms: 1, // milliseconds\n      };\n\n      let match;\n      let totalMs = 0;\n      while ((match = regex.exec(duration)) !== null) {\n        const value = parseInt(match[1]);\n        const unit = match[2];\n        totalMs += value * timeUnits[unit];\n      }\n\n      return totalMs;\n    };\n\n    let resetRequestsDelayMs = 0;\n    let resetTokensDelayMs = 0;\n    const shouldRetry = true;\n    if (responseHeaders[\"x-ratelimit-reset-requests\"]) {\n      resetRequestsDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-requests\"]);\n    }\n    if (responseHeaders[\"x-ratelimit-reset-tokens\"]) {\n      resetTokensDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-tokens\"]);\n    }\n\n    // if rate limited by requests, then it's reset must be the higher of two and visa versa\n    const delayMs = Math.max(resetRequestsDelayMs, resetTokensDelayMs);\n    return { shouldRetry, delayMs };\n  }\n\n  getTokenCount(messages: MessageType[]): number {\n    return messages.reduce((acc, message) => {\n      return acc + message.content.map((content) => (content.modality === \"text\" ? content.value : \"\")).join(\" \").length;\n    }, 0);\n  }\n\n  transformModelRequest(request: OpenAIChatRequestType): {\n    modelName: string | undefined;\n    config: ConfigType;\n    messages: MessageType[];\n    tools: ToolType[] | undefined;\n  } {\n    const safeRequest = OpenAIChatRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    if (parsedRequest.tool_choice && (!parsedRequest.tools || parsedRequest.tools.length === 0)) {\n      throw new InvalidModelRequestError({\n        info: `Invalid model request for model : '${this.modelName}'`,\n        cause: new Error(\"'tools' are required when 'tool_choice' is specified\"),\n      });\n    }\n\n    const _config: ConfigType = {};\n    if (parsedRequest.response_format) {\n      _config.responseFormat = parsedRequest.response_format.type;\n      if (parsedRequest.response_format.type === \"json_schema\") {\n        _config.responseSchema = {\n          name: parsedRequest.response_format.json_schema.name,\n          description: parsedRequest.response_format.json_schema.description || \"\",\n          strict: parsedRequest.response_format.json_schema.strict,\n          schema: parsedRequest.response_format.json_schema.schema,\n        };\n      }\n    }\n\n    if (parsedRequest.tool_choice) {\n      if (typeof parsedRequest.tool_choice === \"string\") {\n        _config.toolChoice = parsedRequest.tool_choice;\n      } else {\n        _config.toolChoice = parsedRequest.tool_choice.function.name;\n      }\n    }\n\n    _config.seed = parsedRequest.seed;\n    _config.maxTokens = parsedRequest.max_completion_tokens;\n    _config.temperature = parsedRequest.temperature;\n    _config.topP = parsedRequest.top_p;\n    _config.presencePenalty = parsedRequest.presence_penalty;\n    _config.frequencyPenalty = parsedRequest.frequency_penalty;\n    _config.stop = parsedRequest.stop;\n    _config.logProbs = parsedRequest.logprobs;\n    _config.topLogProbs = parsedRequest.top_logprobs;\n\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    const messages: MessageType[] = [];\n    const toolCallMap: { [id: string]: ToolCallContentType } = {};\n    parsedRequest.messages.forEach((message) => {\n      const role = message.role;\n      switch (role) {\n        case \"system\":\n          {\n            const content = message.content as string | OpenAIChatRequestTextContentType[];\n            if (typeof content === \"string\") {\n              messages.push({\n                role: role,\n                content: [{ modality: TextModalityLiteral, value: content }],\n              });\n            } else {\n              const _content = content.map((c) => {\n                return { modality: TextModalityLiteral, value: c.text };\n              });\n              messages.push({ role: role, content: _content });\n            }\n          }\n          break;\n\n        case \"user\":\n          {\n            const content = message.content as string | (OpenAIChatRequestTextContentType | OpenAIChatRequestImageContentType)[];\n            if (typeof content === \"string\") {\n              messages.push({\n                role: role,\n                content: [{ modality: TextModalityLiteral, value: content }],\n              });\n            } else {\n              const _content = content.map((c) => {\n                if (c.type === \"text\") {\n                  return { modality: TextModalityLiteral, value: c.text };\n                } else {\n                  if (c.image_url.url.startsWith(\"data:\")) {\n                    return {\n                      modality: ImageModalityLiteral,\n                      detail: c.image_url.detail || \"auto\",\n                      value: {\n                        type: Base64ImageContentTypeLiteral,\n                        base64: c.image_url.url,\n                        mediaType: getMimeTypeFromBase64(c.image_url.url) as Base64ImageContentValueType[\"mediaType\"],\n                      },\n                    };\n                  } else {\n                    return {\n                      modality: ImageModalityLiteral,\n                      detail: c.image_url.detail || \"auto\",\n                      value: { type: UrlImageContentTypeLiteral, url: c.image_url.url },\n                    };\n                  }\n                }\n              });\n              messages.push({ role: role, content: _content });\n            }\n          }\n          break;\n\n        case \"assistant\":\n          {\n            const assistantContent: ContentType[] = [];\n\n            if (!message.content && !message.tool_calls) {\n              throw new InvalidModelRequestError({\n                info: `Invalid model request for model : '${this.modelName}'`,\n                cause: new Error(\"one of'content' or 'tool_calls' must be provided\"),\n              });\n            }\n\n            if (message.content) {\n              const content = message.content as string | OpenAIChatRequestTextContentType[];\n              if (typeof content === \"string\") {\n                assistantContent.push({ modality: TextModalityLiteral, value: content });\n              } else {\n                content.forEach((c) => {\n                  assistantContent.push({ modality: TextModalityLiteral, value: c.text });\n                });\n              }\n            }\n\n            if (message.tool_calls) {\n              const toolCalls = message.tool_calls;\n              toolCalls.forEach((toolCall, index) => {\n                const toolCallContent: ToolCallContentType = {\n                  modality: ToolCallModalityLiteral,\n                  id: toolCall.id,\n                  index: index,\n                  name: toolCall.function.name,\n                  arguments: toolCall.function.arguments,\n                };\n                assistantContent.push(toolCallContent);\n                toolCallMap[toolCallContent.id] = toolCallContent;\n              });\n            }\n            messages.push({ role: role, content: assistantContent });\n          }\n          break;\n\n        case \"tool\":\n          {\n            const toolResponse = message;\n            messages.push({\n              role: role,\n              content: [\n                {\n                  modality: ToolResponseModalityLiteral,\n                  id: toolResponse.tool_call_id,\n                  index: toolCallMap[toolResponse.tool_call_id].index,\n                  name: toolCallMap[toolResponse.tool_call_id].name,\n                  data: toolResponse.content,\n                },\n              ],\n            });\n          }\n          break;\n      }\n    });\n\n    const tools: ToolType[] = [];\n    if (parsedRequest.tools) {\n      parsedRequest.tools.forEach((tool: OpenAIChatRequestToolType) => {\n        tools.push({\n          type: \"function\",\n          definition: {\n            schema: {\n              name: tool.function.name,\n              description: tool.function.description || \"\",\n              strict: tool.function.strict,\n              parameters: tool.function.parameters,\n            },\n          },\n        });\n      });\n    }\n\n    return {\n      modelName,\n      config,\n      messages,\n      tools: tools.length > 0 ? tools : undefined,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, messages?: MessageType[], tools?: ToolType[]): ParamsType {\n    const _toolChoice = config.toolChoice;\n    delete config.toolChoice; // can have a specific tool name that is not in the model schema, validated at transformation\n\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    if (_toolChoice !== undefined) {\n      parsedConfig.toolChoice = _toolChoice;\n    }\n\n    Object.keys(parsedConfig).forEach((key) => {\n      if (!(key in this.modelSchema.config.def)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = (parsedConfig as ConfigType)[key];\n\n      if (paramKey === \"max_completion_tokens\" && def.type === \"range\" && paramValue === 0) {\n        acc[paramKey] = def.max;\n      } else {\n        acc[paramKey] = paramValue;\n      }\n\n      return acc;\n    }, {} as ParamsType);\n\n    if (transformedConfig.top_logprobs && !transformedConfig.logprobs) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelName}'`,\n        cause: new Error(\"'logprobs' must be 'true' when 'top_logprobs' is specified\"),\n      });\n    }\n\n    if (\"tool_choice\" in transformedConfig && transformedConfig.tool_choice !== undefined) {\n      const toolChoice = transformedConfig.tool_choice as string;\n      if (!tools || (tools && tools.length === 0)) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelName}'`,\n          cause: new Error(\"'tools' are required when 'toolChoice' is specified\"),\n        });\n      } else if (tools && tools.length > 0) {\n        const configToolChoice = this.modelSchema.config.def.toolChoice as SelectStringConfigItemDefType;\n        if (!configToolChoice.choices.includes(toolChoice)) {\n          if (tools.map((tool) => tool.definition.schema.name).includes(toolChoice)) {\n            transformedConfig.tool_choice = { type: \"function\", function: { name: toolChoice } };\n          } else {\n            throw new InvalidConfigError({\n              info: `Invalid config for model : '${this.modelName}'`,\n              cause: new Error(`toolChoice : '${toolChoice}' is not part of provided 'tools' names or \n                one of [${configToolChoice.choices.join(\", \")}]`),\n            });\n          }\n        }\n      }\n    }\n\n    if (\"response_format\" in transformedConfig && transformedConfig.response_format !== undefined) {\n      const responseFormat = transformedConfig.response_format as string;\n      if (responseFormat === \"json_schema\") {\n        if (!(\"response_schema\" in transformedConfig)) {\n          throw new InvalidConfigError({\n            info: `Invalid config for model : '${this.modelName}'`,\n            cause: new Error(\"'responseSchema' is required in config when 'responseFormat' is 'json_schema'\"),\n          });\n        } else {\n          transformedConfig.response_format = {\n            type: \"json_schema\",\n            json_schema: transformedConfig.response_schema,\n          };\n          delete transformedConfig.response_schema;\n        }\n      } else {\n        transformedConfig.response_format = { type: responseFormat };\n      }\n    }\n\n    return transformedConfig;\n  }\n\n  transformMessages(messages: MessageType[]): ParamsType {\n    if (!messages || (messages && messages.length === 0)) {\n      return { messages: [] };\n    }\n\n    const parsedMessages = messages.map((message) => {\n      const parsedMessage = Message().safeParse(message);\n      if (!parsedMessage.success) {\n        throw new InvalidMessagesError({ info: \"Invalid messages\", cause: parsedMessage.error });\n      }\n      return parsedMessage.data;\n    });\n\n    parsedMessages.forEach((message) => {\n      message.content.forEach((content) => {\n        if (!this.modelSchema.modalities.includes(content.modality)) {\n          throw new InvalidMessagesError({\n            info: `Invalid message content for model : '${this.modelName}'`,\n            cause: new Error(`model : '${this.modelName}' does not support modality : '${content.modality}', \n              available modalities : [${this.modelSchema.modalities.join(\", \")}]`),\n          });\n        }\n      });\n    });\n\n    parsedMessages.forEach((message) => {\n      if (!Object.keys(this.modelSchema.roles).includes(message.role)) {\n        throw new InvalidMessagesError({\n          info: `Invalid message content for model : '${this.modelName}'`,\n          cause: new Error(`model : '${this.modelName}' does not support role : '${message.role}', \n            available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedMessages = parsedMessages.map((message) => {\n      switch (message.role) {\n        case SystemRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: textContent,\n          };\n        }\n\n        case AssistantRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          const toolCalls: { id: string; type: \"function\"; function: { name: string; arguments: string } }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else if (content.modality === ToolCallModalityLiteral) {\n              toolCalls.push({\n                id: content.id,\n                type: \"function\",\n                function: { name: content.name, arguments: content.arguments },\n              });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: textContent,\n            ...(toolCalls.length > 0 ? { tool_calls: toolCalls } : {}),\n          };\n        }\n\n        case UserRoleLiteral: {\n          const textContent: { type: \"text\"; text: string }[] = [];\n          const imageContent: { type: \"image_url\"; image_url: { url: string; detail: string } }[] = [];\n          message.content.forEach((content) => {\n            if (content.modality === TextModalityLiteral) {\n              textContent.push({ type: \"text\", text: content.value });\n            } else if (content.modality === ImageModalityLiteral) {\n              imageContent.push({\n                type: \"image_url\",\n                image_url: {\n                  url: content.value.type === \"url\" ? content.value.url : content.value.base64,\n                  detail: content.detail,\n                },\n              });\n            } else {\n              throw new InvalidMessagesError({\n                info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n                cause: new Error(`role : '${message.role}' cannot have content with modality : '${content.modality}'`),\n              });\n            }\n          });\n\n          const combinedContent = [...textContent, ...imageContent];\n\n          return {\n            role: this.modelSchema.roles[message.role],\n            content: combinedContent,\n          };\n        }\n\n        case ToolRoleLiteral: {\n          if (message.content.length !== 1) {\n            throw new InvalidMessagesError({\n              info: `Invalid message for role : '${message.role}'`,\n              cause: new Error(`role : '${message.role}' must have exactly one content item`),\n            });\n          }\n\n          if (message.content[0].modality !== ToolResponseModalityLiteral) {\n            throw new InvalidMessagesError({\n              info: `Invalid message 'role' and 'modality' combination for model : ${this.modelName}`,\n              cause: new Error(`role : '${message.role}' must have content with modality : '${ToolResponseModalityLiteral}'`),\n            });\n          }\n\n          const toolResponse = message.content[0] as ToolResponseContentType;\n          return {\n            role: this.modelSchema.roles[message.role],\n            tool_call_id: toolResponse.id,\n            content: toolResponse.data,\n          };\n        }\n\n        default: {\n          throw new InvalidMessagesError({\n            info: `Invalid message 'role' for model : ${this.modelName}`,\n            cause: new Error(`role : '${message.role}' is not supported, \n              available roles : [${Object.keys(this.modelSchema.roles).join(\", \")}]`),\n          });\n        }\n      }\n    });\n\n    return { messages: transformedMessages };\n  }\n\n  transformTools(tools: ToolType[]): ParamsType {\n    if (!this.modelSchema.modalities.includes(ToolCallModalityLiteral)) {\n      throw new InvalidToolsError({\n        info: `Invalid tool 'modality' for model : ${this.modelName}`,\n        cause: new Error(`model : '${this.modelName}' does not support tool modality : '${ToolCallModalityLiteral}'`),\n      });\n    }\n\n    if (!tools || (tools && tools.length === 0)) {\n      return { tools: [] as ToolType[] };\n    }\n\n    const parsedTools = tools.map((tool) => {\n      const parsedTool = Tool().safeParse(tool);\n      if (!parsedTool.success) {\n        throw new InvalidToolsError({ info: \"Invalid tools\", cause: parsedTool.error });\n      }\n      return parsedTool.data;\n    });\n\n    const transformedTools = parsedTools.map((tool) => ({\n      type: \"function\",\n      function: tool.definition.schema,\n    }));\n\n    return { tools: transformedTools };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getCompleteChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getCompleteChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  transformCompleteChatResponse(response: any): ChatResponseType {\n    const safe = OpenAICompleteChatResponse.safeParse(response);\n    if (safe.success) {\n      if (safe.data.choices.length === 0) {\n        throw new ModelResponseError({\n          info: \"Invalid response from model\",\n          cause: new Error(`No choices in response : ${JSON.stringify(safe.data)}`),\n        });\n      }\n\n      const parsedResponse: OpenAICompleteChatResponseType = safe.data;\n      const messages: MessageType[] = [\n        {\n          role: AssistantRoleLiteral,\n          content: [],\n        },\n      ];\n      const message = parsedResponse.choices[0].message;\n      if (message.content) {\n        messages[0].content.push(createTextContent(message.content));\n      }\n\n      if (message.refusal) {\n        messages[0].content.push(createTextContent(message.refusal));\n      }\n\n      if (message.tool_calls) {\n        message.tool_calls.forEach((toolCall, index) => {\n          messages[0].content.push(createToolCallContent(index, toolCall.id, toolCall.function.name, toolCall.function.arguments));\n        });\n      }\n\n      const usage: ChatUsageType = {\n        promptTokens: parsedResponse.usage.prompt_tokens,\n        completionTokens: parsedResponse.usage.completion_tokens,\n        totalTokens: parsedResponse.usage.total_tokens,\n      };\n\n      const logProbs: ChatLogProbsType = [];\n      const _logProbs = parsedResponse.choices[0].logprobs;\n      if (_logProbs) {\n        if (_logProbs.content) {\n          logProbs.push(\n            ..._logProbs.content.map((logProb) => ({\n              token: logProb.token,\n              logProb: logProb.logprob,\n              bytes: logProb.bytes,\n              topLogProbs: logProb.top_logprobs.map((topLogProb) => ({\n                token: topLogProb.token,\n                logProb: topLogProb.logprob,\n                bytes: topLogProb.bytes,\n              })),\n            }))\n          );\n        }\n        if (_logProbs.refusal) {\n          logProbs.push(\n            ..._logProbs.refusal.map((logProb) => ({\n              token: logProb.token,\n              logProb: logProb.logprob,\n              bytes: logProb.bytes,\n              topLogProbs: logProb.top_logprobs.map((topLogProb) => ({\n                token: topLogProb.token,\n                logProb: topLogProb.logprob,\n                bytes: topLogProb.bytes,\n              })),\n            }))\n          );\n        }\n      }\n\n      return {\n        messages: messages,\n        usage: usage,\n        logProbs: logProbs,\n      };\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatUrl(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.streamChatUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getStreamChatHeaders(config?: ConfigType, messages?: MessageType[], tools?: ToolType[]): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getStreamChatData(config: ConfigType, messages: MessageType[], tools?: ToolType[]): Promise<ParamsType> {\n    const transformedConfig = this.transformConfig(config, messages, tools);\n    const transformedMessages = this.transformMessages(messages);\n    if (transformedMessages.messages && (transformedMessages.messages as MessageType[]).length === 0) {\n      throw new InvalidMessagesError({\n        info: \"Messages are required\",\n        cause: new Error(\"Messages are required\"),\n      });\n    }\n\n    const transformedTools = tools ? this.transformTools(tools) : {};\n\n    return new Promise((resolve) => {\n      resolve({\n        stream: true,\n        stream_options: { include_usage: true },\n        ...this.getDefaultParams(),\n        ...transformedConfig,\n        ...transformedMessages,\n        ...transformedTools,\n      });\n    });\n  }\n\n  async *transformStreamChatResponseChunk(\n    chunk: string,\n    buffer: string\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    const data = buffer + chunk;\n    let lines: string[] = [];\n    let newBuffer = \"\";\n\n    // Split data into complete lines and new buffer\n    let currentIndex = 0;\n    while (currentIndex < data.length) {\n      const newlineIndex = data.indexOf(\"\\n\", currentIndex);\n      if (newlineIndex === -1) {\n        newBuffer = data.substring(currentIndex);\n        break;\n      } else {\n        const line = data.substring(currentIndex, newlineIndex).trim();\n        if (line) {\n          lines.push(line);\n        }\n        currentIndex = newlineIndex + 1;\n      }\n    }\n\n    // Process each complete line\n    for (const line of lines) {\n      if (line === \"data: [DONE]\") {\n        return; // End of stream\n      }\n\n      if (line.startsWith(\"data: \")) {\n        const jsonStr = line.substring(\"data: \".length);\n        try {\n          const structuredLine = JSON.parse(jsonStr);\n          const safe = OpenAIStreamChatResponse.safeParse(structuredLine);\n          if (safe.success) {\n            const partialResponse: PartialChatResponseType = { partialMessages: [] };\n            const parsedResponse: OpenAIStreamChatResponseType = safe.data;\n            // Process message content\n            if (parsedResponse.choices.length > 0) {\n              const message = parsedResponse.choices[0].delta;\n              if (message !== undefined && Object.keys(message).length !== 0) {\n                if (\"content\" in message && message.content !== null) {\n                  partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, message.content as string));\n                } else if (\"refusal\" in message && message.refusal !== null) {\n                  partialResponse.partialMessages.push(createPartialTextMessage(AssistantRoleLiteral, message.refusal as string));\n                } else if (\"tool_calls\" in message && message.tool_calls !== undefined) {\n                  const toolCall = message.tool_calls.at(0)!;\n                  partialResponse.partialMessages.push(\n                    createPartialToolCallMessage(\n                      AssistantRoleLiteral,\n                      toolCall.index,\n                      toolCall.id,\n                      toolCall.function?.name,\n                      toolCall.function?.arguments\n                    )\n                  );\n                }\n              }\n            }\n\n            if (parsedResponse.usage) {\n              partialResponse.usage = {\n                promptTokens: parsedResponse.usage.prompt_tokens,\n                completionTokens: parsedResponse.usage.completion_tokens,\n                totalTokens: parsedResponse.usage.total_tokens,\n              };\n            }\n            yield { partialResponse: partialResponse, buffer: newBuffer };\n          } else {\n            throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n          }\n        } catch (error) {\n          throw new ModelResponseError({\n            info: `Malformed JSON received in stream: ${jsonStr}`,\n            cause: error,\n          });\n        }\n      }\n    }\n\n    // Yield the updated buffer after processing all lines\n    yield { partialResponse: { partialMessages: [] }, buffer: newBuffer };\n  }\n  async *transformProxyStreamChatResponseChunk(\n    chunk: string,\n    buffer: string,\n    data?: any,\n    headers?: Record<string, string>,\n    query?: Record<string, string>\n  ): AsyncGenerator<{ partialResponse: PartialChatResponseType; buffer: string }> {\n    // Directly delegate to transformStreamChatResponseChunk\n    yield* this.transformStreamChatResponseChunk(chunk, buffer);\n  }\n  async getProxyStreamChatUrl(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.streamChatUrl);\n    });\n  }\n  async getProxyCompleteChatUrl(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.completeChatUrl);\n    });\n  }\n\n  async getProxyCompleteChatHeaders(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<HeadersType> {\n    if (!headers) {\n      return {};\n    }\n    const sanitizedHeaders: Record<string, string> = { ...headers };\n\n    delete sanitizedHeaders.host;\n    delete sanitizedHeaders[\"content-length\"];\n    return sanitizedHeaders;\n  }\n  async getProxyStreamChatHeaders(data?: any, headers?: Record<string, string>, query?: Record<string, string>): Promise<HeadersType> {\n    // Directly delegate to getProxyCompleteChatHeaders for now\n    return await this.getProxyCompleteChatHeaders(data, headers, query);\n  }\n\n  getModelPricing(): ChatModelPriceType {\n    // Check if the modelName exists in pricingData before accessing it\n    if (!(this.modelName in pricingData)) {\n      throw new ModelResponseError({\n        info: `Invalid model pricing for model : '${this.modelName}'`,\n        cause: new Error(`No pricing configuration found for model \"${this.modelName}\"`),\n      });\n    }\n\n    const entry = pricingData[this.modelName as keyof typeof pricingData];\n    return entry as ChatModelPriceType;\n  }\n}\n\nexport { BaseChatModel, BaseChatModelOptions, type BaseChatModelOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_Turbo_0125Literal = \"gpt-3.5-turbo-0125\";\nconst GPT_3_5_Turbo_0125Description =\n  \"The latest GPT-3.5 Turbo model with higher accuracy at responding in requested formats and a fix for a bug which caused a \\\n  text encoding issue for non-English language function calls. Training data up to Sept 2021.\";\n\nconst GPT_3_5_Turbo_0125Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_Turbo_0125Literal,\n  description: GPT_3_5_Turbo_0125Description,\n  maxInputTokens: 4092,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_3_5_Turbo_0125Literal],\n});\n\nconst GPT_3_5_Turbo_0125Options = BaseChatModelOptions;\ntype GPT_3_5_Turbo_0125OptionsType = z.infer<typeof GPT_3_5_Turbo_0125Options>;\n\nclass GPT_3_5_Turbo_0125 extends BaseChatModel {\n  constructor(options: GPT_3_5_Turbo_0125OptionsType) {\n    super(GPT_3_5_Turbo_0125Schema, options);\n  }\n}\n\nexport {\n  GPT_3_5_Turbo_0125,\n  GPT_3_5_Turbo_0125Literal,\n  GPT_3_5_Turbo_0125Options,\n  GPT_3_5_Turbo_0125Schema,\n  type GPT_3_5_Turbo_0125OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_Turbo_1106Literal = \"gpt-3.5-turbo-1106\";\nconst GPT_3_5_Turbo_1106Description =\n  \"The latest GPT-3.5 Turbo model with improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more.\\\n   Returns a maximum of 4,096 output tokens. Training data up to Sept 2021.\";\n\nconst GPT_3_5_Turbo_1106Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_Turbo_1106Literal,\n  description: GPT_3_5_Turbo_1106Description,\n  maxInputTokens: 4092,\n  maxOutputTokens: 16385,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(16385, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(16385, 4).schema,\n  },\n  price: pricingData[GPT_3_5_Turbo_1106Literal], // Added price definition\n});\n\nconst GPT_3_5_Turbo_1106Options = BaseChatModelOptions;\ntype GPT_3_5_Turbo_1106OptionsType = z.infer<typeof GPT_3_5_Turbo_1106Options>;\n\nclass GPT_3_5_Turbo_1106 extends BaseChatModel {\n  constructor(options: GPT_3_5_Turbo_1106OptionsType) {\n    super(GPT_3_5_Turbo_1106Schema, options);\n  }\n}\n\nexport {\n  GPT_3_5_Turbo_1106,\n  GPT_3_5_Turbo_1106Literal,\n  GPT_3_5_Turbo_1106Options,\n  GPT_3_5_Turbo_1106Schema,\n  type GPT_3_5_Turbo_1106OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_3_5_TurboLiteral = \"gpt-3.5-turbo\";\nconst GPT_3_5_TurboDescription = \"Currently points to gpt-3.5-turbo-0125. Training data up to Sept 2021.\";\n\nconst GPT_3_5_TurboSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_3_5_TurboLiteral,\n  description: GPT_3_5_TurboDescription,\n  maxInputTokens: 4092,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_3_5_TurboLiteral],\n});\n\nconst GPT_3_5_TurboOptions = BaseChatModelOptions;\ntype GPT_3_5_TurboOptionsType = z.infer<typeof GPT_3_5_TurboOptions>;\n\nclass GPT_3_5_Turbo extends BaseChatModel {\n  constructor(options: GPT_3_5_TurboOptionsType) {\n    super(GPT_3_5_TurboSchema, options);\n  }\n}\n\nexport { GPT_3_5_Turbo, GPT_3_5_TurboLiteral, GPT_3_5_TurboOptions, GPT_3_5_TurboSchema, type GPT_3_5_TurboOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\"; // Added import\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_0125_PreviewLiteral = \"gpt-4-0125-preview\";\nconst GPT_4_0125_PreviewDescription =\n  \"The latest GPT-4 model intended to reduce cases of laziness where the model doesnt complete a task. Training data up to Apr 2023.\";\n\nconst GPT_4_0125_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_0125_PreviewLiteral,\n  description: GPT_4_0125_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_0125_PreviewLiteral], // Added price definition\n});\n\nconst GPT_4_0125_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_0125_PreviewOptionsType = z.infer<typeof GPT_4_0125_PreviewOptions>;\n\nclass GPT_4_0125_Preview extends BaseChatModel {\n  constructor(options: GPT_4_0125_PreviewOptionsType) {\n    super(GPT_4_0125_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_0125_Preview,\n  GPT_4_0125_PreviewLiteral,\n  GPT_4_0125_PreviewOptions,\n  GPT_4_0125_PreviewSchema,\n  type GPT_4_0125_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_0613Literal = \"gpt-4-0613\";\nconst GPT_4_0613Description =\n  \"Snapshot of gpt-4 from June 13th 2023 with improved function calling support. Training data up to Sept 2021.\";\n\nconst GPT_4_0613Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_0613Literal,\n  description: GPT_4_0613Description,\n  maxInputTokens: 8192,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_0613Literal], // Added price definition\n});\n\nconst GPT_4_0613Options = BaseChatModelOptions;\ntype GPT_4_0613OptionsType = z.infer<typeof GPT_4_0613Options>;\n\nclass GPT_4_0613 extends BaseChatModel {\n  constructor(options: GPT_4_0613OptionsType) {\n    super(GPT_4_0613Schema, options);\n  }\n}\n\nexport { GPT_4_0613, GPT_4_0613Literal, GPT_4_0613Options, GPT_4_0613Schema, type GPT_4_0613OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\"; // Added import\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_1106_PreviewLiteral = \"gpt-4-1106-preview\";\nconst GPT_4_1106_PreviewDescription =\n  \"GPT-4 Turbo model featuring improved instruction following, JSON mode, reproducible outputs, parallel function calling, and more. \\\n  Returns a maximum of 4,096 output tokens. This preview model is not yet suited for production traffic. Training data up to Apr 2023.\";\n\nconst GPT_4_1106_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_1106_PreviewLiteral,\n  description: GPT_4_1106_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_1106_PreviewLiteral], // Added price definition\n});\n\nconst GPT_4_1106_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_1106_PreviewOptionsType = z.infer<typeof GPT_4_1106_PreviewOptions>;\n\nclass GPT_4_1106_Preview extends BaseChatModel {\n  constructor(options: GPT_4_1106_PreviewOptionsType) {\n    super(GPT_4_1106_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_1106_Preview,\n  GPT_4_1106_PreviewLiteral,\n  GPT_4_1106_PreviewOptions,\n  GPT_4_1106_PreviewSchema,\n  type GPT_4_1106_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_1Literal = \"gpt-4.1\";\nconst GPT_4_1Description =\n  \"Flagship model for complex tasks. It is well suited for problem solving across domains. \\\n  Training data up to May 2024.\";\n\nconst GPT_4_1Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_1Literal,\n  description: GPT_4_1Description,\n  maxInputTokens: 1047576,\n  maxOutputTokens: 32768,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(32768, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(32768, 4).schema,\n  },\n  price: pricingData[GPT_4_1Literal],\n});\n\nconst GPT_4_1Options = BaseChatModelOptions;\ntype GPT_4_1OptionsType = z.infer<typeof GPT_4_1Options>;\n\nclass GPT_4_1 extends BaseChatModel {\n  constructor(options: GPT_4_1OptionsType) {\n    super(GPT_4_1Schema, options);\n  }\n}\n\nexport { GPT_4_1, GPT_4_1Literal, GPT_4_1Options, GPT_4_1Schema, type GPT_4_1OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_1_MiniLiteral = \"gpt-4.1-mini\";\nconst GPT_4_1_MiniDescription =\n  \"Provides a balance between intelligence, speed, and cost that makes it an attractive model for many use cases. \\\n  Training data up to May 2024.\";\n\nconst GPT_4_1_MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_1_MiniLiteral,\n  description: GPT_4_1_MiniDescription,\n  maxInputTokens: 1047576,\n  maxOutputTokens: 32768,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(32768, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(32768, 4).schema,\n  },\n  price: pricingData[GPT_4_1_MiniLiteral],\n});\n\nconst GPT_4_1_MiniOptions = BaseChatModelOptions;\ntype GPT_4_1_MiniOptionsType = z.infer<typeof GPT_4_1_MiniOptions>;\n\nclass GPT_4_1_Mini extends BaseChatModel {\n  constructor(options: GPT_4_1_MiniOptionsType) {\n    super(GPT_4_1_MiniSchema, options);\n  }\n}\n\nexport { GPT_4_1_Mini, GPT_4_1_MiniLiteral, GPT_4_1_MiniOptions, GPT_4_1_MiniSchema, type GPT_4_1_MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_1_NanoLiteral = \"gpt-4.1-nano\";\nconst GPT_4_1_NanoDescription =\n  \"Fastest, most cost-effective GPT-4.1 model. \\\n  Training data up to May 2024.\";\n\nconst GPT_4_1_NanoSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_1_NanoLiteral,\n  description: GPT_4_1_NanoDescription,\n  maxInputTokens: 1047576,\n  maxOutputTokens: 32768,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(32768, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(32768, 4).schema,\n  },\n  price: pricingData[GPT_4_1_NanoLiteral],\n});\n\nconst GPT_4_1_NanoOptions = BaseChatModelOptions;\ntype GPT_4_1_NanoOptionsType = z.infer<typeof GPT_4_1_NanoOptions>;\n\nclass GPT_4_1_Nano extends BaseChatModel {\n  constructor(options: GPT_4_1_NanoOptionsType) {\n    super(GPT_4_1_NanoSchema, options);\n  }\n}\n\nexport { GPT_4_1_Nano, GPT_4_1_NanoLiteral, GPT_4_1_NanoOptions, GPT_4_1_NanoSchema, type GPT_4_1_NanoOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_Turbo_2024_04_09Literal = \"gpt-4-turbo-2024-04-09\";\nconst GPT_4_Turbo_2024_04_09Description =\n  \"GPT-4 Turbo with Vision model. Vision requests can now use JSON mode and function calling. gpt-4-turbo currently points to this version. \\\n  Training data up to Dec 2023.\";\n\nconst GPT_4_Turbo_2024_04_09Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_Turbo_2024_04_09Literal,\n  description: GPT_4_Turbo_2024_04_09Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4096,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4096, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4096, 4).schema,\n  },\n  price: pricingData[GPT_4_Turbo_2024_04_09Literal],\n});\n\nconst GPT_4_Turbo_2024_04_09Options = BaseChatModelOptions;\ntype GPT_4_Turbo_2024_04_09OptionsType = z.infer<typeof GPT_4_Turbo_2024_04_09Options>;\n\nclass GPT_4_Turbo_2024_04_09 extends BaseChatModel {\n  constructor(options: GPT_4_Turbo_2024_04_09OptionsType) {\n    super(GPT_4_Turbo_2024_04_09Schema, options);\n  }\n}\n\nexport {\n  GPT_4_Turbo_2024_04_09,\n  GPT_4_Turbo_2024_04_09Literal,\n  GPT_4_Turbo_2024_04_09Options,\n  GPT_4_Turbo_2024_04_09Schema,\n  type GPT_4_Turbo_2024_04_09OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4_Turbo_PreviewLiteral = \"gpt-4-turbo-preview\";\nconst GPT_4_Turbo_PreviewDescription = \"Currently points to gpt-4-0125-preview. Training data up to Apr 2023.\";\n\nconst GPT_4_Turbo_PreviewSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4_Turbo_PreviewLiteral,\n  description: GPT_4_Turbo_PreviewDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_Turbo_PreviewLiteral],\n});\n\nconst GPT_4_Turbo_PreviewOptions = BaseChatModelOptions;\ntype GPT_4_Turbo_PreviewOptionsType = z.infer<typeof GPT_4_Turbo_PreviewOptions>;\n\nclass GPT_4_Turbo_Preview extends BaseChatModel {\n  constructor(options: GPT_4_Turbo_PreviewOptionsType) {\n    super(GPT_4_Turbo_PreviewSchema, options);\n  }\n}\n\nexport {\n  GPT_4_Turbo_Preview,\n  GPT_4_Turbo_PreviewLiteral,\n  GPT_4_Turbo_PreviewOptions,\n  GPT_4_Turbo_PreviewSchema,\n  type GPT_4_Turbo_PreviewOptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4_TurboLiteral = \"gpt-4-turbo\";\nconst GPT_4_TurboDescription =\n  \"The latest GPT-4 Turbo model with vision capabilities. Vision requests can now use JSON mode and function calling. \\\n  Currently points to gpt-4-turbo-2024-04-09. Training data up to Dec 2023.\";\n\nconst GPT_4_TurboSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4_TurboLiteral,\n  description: GPT_4_TurboDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseFormat(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseFormat(4092, 4).schema,\n  },\n  price: pricingData[GPT_4_TurboLiteral],\n});\n\nconst GPT_4_TurboOptions = BaseChatModelOptions;\ntype GPT_4_TurboOptionsType = z.infer<typeof GPT_4_TurboOptions>;\n\nclass GPT_4_Turbo extends BaseChatModel {\n  constructor(options: GPT_4_TurboOptionsType) {\n    super(GPT_4_TurboSchema, options);\n  }\n}\n\nexport { GPT_4_Turbo, GPT_4_TurboLiteral, GPT_4_TurboOptions, GPT_4_TurboSchema, type GPT_4_TurboOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\"; // Added import\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n  OpenAIChatModelTextToolModalities,\n  OpenAIChatModelTextToolModalitiesEnum,\n} from \"./types\";\n\nconst GPT_4Literal = \"gpt-4\";\nconst GPT_4Description = \"Currently points to gpt-4-0613. Training data up to Sept 2021.\";\n\nconst GPT_4Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: GPT_4Literal,\n  description: GPT_4Description,\n  maxInputTokens: 8192,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.base(4092, 4).def,\n    schema: OpenAIChatModelConfigs.base(4092, 4).schema,\n  },\n  price: pricingData[GPT_4Literal],\n});\n\nconst GPT_4Options = BaseChatModelOptions;\ntype GPT_4OptionsType = z.infer<typeof GPT_4Options>;\n\nclass GPT_4 extends BaseChatModel {\n  constructor(options: GPT_4OptionsType) {\n    super(GPT_4Schema, options);\n  }\n}\n\nexport { GPT_4, GPT_4Literal, GPT_4Options, GPT_4Schema, type GPT_4OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_2024_05_13Literal = \"gpt-4o-2024-05-13\";\nconst GPT_4o_2024_05_13Description = \"Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.\";\n\nconst GPT_4o_2024_05_13Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_2024_05_13Literal,\n  description: GPT_4o_2024_05_13Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_2024_05_13Literal],\n});\n\nconst GPT_4o_2024_05_13Options = BaseChatModelOptions;\ntype GPT_4o_2024_05_13OptionsType = z.infer<typeof GPT_4o_2024_05_13Options>;\n\nclass GPT_4o_2024_05_13 extends BaseChatModel {\n  constructor(options: GPT_4o_2024_05_13OptionsType) {\n    super(GPT_4o_2024_05_13Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_2024_05_13,\n  GPT_4o_2024_05_13Literal,\n  GPT_4o_2024_05_13Options,\n  GPT_4o_2024_05_13Schema,\n  type GPT_4o_2024_05_13OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_2024_08_06Literal = \"gpt-4o-2024-08-06\";\nconst GPT_4o_2024_08_06Description = \"Latest snapshot of gpt-4o that supports Structured Outputs. Training data up to Oct 2023.\";\n\nconst GPT_4o_2024_08_06Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_2024_08_06Literal,\n  description: GPT_4o_2024_08_06Description,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_2024_08_06Literal],\n});\n\nconst GPT_4o_2024_08_06Options = BaseChatModelOptions;\ntype GPT_4o_2024_08_06OptionsType = z.infer<typeof GPT_4o_2024_08_06Options>;\n\nclass GPT_4o_2024_08_06 extends BaseChatModel {\n  constructor(options: GPT_4o_2024_08_06OptionsType) {\n    super(GPT_4o_2024_08_06Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_2024_08_06,\n  GPT_4o_2024_08_06Literal,\n  GPT_4o_2024_08_06Options,\n  GPT_4o_2024_08_06Schema,\n  type GPT_4o_2024_08_06OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_Mini_2024_07_18Literal = \"gpt-4o-mini-2024-07-18\";\nconst GPT_4o_MiniDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4o_Mini_2024_07_18Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_Mini_2024_07_18Literal,\n  description: GPT_4o_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_Mini_2024_07_18Literal],\n});\n\nconst GPT_4o_Mini_2024_07_18Options = BaseChatModelOptions;\ntype GPT_4o_Mini_2024_07_18OptionsType = z.infer<typeof GPT_4o_Mini_2024_07_18Options>;\n\nclass GPT_4o_Mini_2024_07_18 extends BaseChatModel {\n  constructor(options: GPT_4o_Mini_2024_07_18OptionsType) {\n    super(GPT_4o_Mini_2024_07_18Schema, options);\n  }\n}\n\nexport {\n  GPT_4o_Mini_2024_07_18,\n  GPT_4o_Mini_2024_07_18Literal,\n  GPT_4o_Mini_2024_07_18Options,\n  GPT_4o_Mini_2024_07_18Schema,\n  type GPT_4o_Mini_2024_07_18OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4o_MiniLiteral = \"gpt-4o-mini\";\nconst GPT_4o_MiniDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4o_MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4o_MiniLiteral,\n  description: GPT_4o_MiniDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4o_MiniLiteral],\n});\n\nconst GPT_4o_MiniOptions = BaseChatModelOptions;\ntype GPT_4o_MiniOptionsType = z.infer<typeof GPT_4o_MiniOptions>;\n\nclass GPT_4o_Mini extends BaseChatModel {\n  constructor(options: GPT_4o_MiniOptionsType) {\n    super(GPT_4o_MiniSchema, options);\n  }\n}\n\nexport { GPT_4o_Mini, GPT_4o_MiniLiteral, GPT_4o_MiniOptions, GPT_4o_MiniSchema, type GPT_4o_MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst GPT_4oLiteral = \"gpt-4o\";\nconst GPT_4oDescription =\n  \"Most advanced, multimodal flagship model that is cheaper and faster than GPT-4 Turbo. Currently points to gpt-4o-2024-05-13. \\\n  Training data up to Oct 2023.\";\n\nconst GPT_4oSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: GPT_4oLiteral,\n  description: GPT_4oDescription,\n  maxInputTokens: 128000,\n  maxOutputTokens: 4092,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.responseSchema(4092, 4).def,\n    schema: OpenAIChatModelConfigs.responseSchema(4092, 4).schema,\n  },\n  price: pricingData[GPT_4oLiteral],\n});\n\nconst GPT_4oOptions = BaseChatModelOptions;\ntype GPT_4oOptionsType = z.infer<typeof GPT_4oOptions>;\n\nclass GPT_4o extends BaseChatModel {\n  constructor(options: GPT_4oOptionsType) {\n    super(GPT_4oSchema, options);\n  }\n}\n\nexport { GPT_4o, GPT_4oLiteral, GPT_4oOptions, GPT_4oSchema, type GPT_4oOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModel, BaseChatModelOptions } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O1_2024_12_17Literal = \"o1-2024-12-17\";\nconst O1_2024_12_17Description =\n  \"A stable release model for production use, offering robust performance and advanced features. Training data up to December 2024.\";\n\nconst O1_2024_12_17Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O1_2024_12_17Literal,\n  description: O1_2024_12_17Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n  price: pricingData[O1_2024_12_17Literal],\n});\n\nconst O1_2024_12_17Options = BaseChatModelOptions;\ntype O1_2024_12_17OptionsType = z.infer<typeof O1_2024_12_17Options>;\n\nclass O1_2024_12_17 extends BaseChatModel {\n  constructor(options: O1_2024_12_17OptionsType) {\n    super(O1_2024_12_17Schema, options);\n  }\n}\n\nexport { O1_2024_12_17, O1_2024_12_17Literal, O1_2024_12_17Options, O1_2024_12_17Schema, type O1_2024_12_17OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport pricingData from \"../pricing.json\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O1Literal = \"o1\";\nconst O1Description =\n  \"Highly capable general-purpose reasoning model with advanced capabilities in language, coding, and reasoning. Training data up to Oct 2023.\";\n\nconst O1Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O1Literal,\n  description: O1Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n  price: pricingData[O1Literal],\n});\n\nconst O1Options = BaseChatModelOptions;\ntype O1OptionsType = z.infer<typeof O1Options>;\n\nclass O1 extends BaseChatModel {\n  constructor(options: O1OptionsType) {\n    super(O1Schema, options);\n  }\n}\n\nexport { O1, O1Literal, O1Options, O1Schema, type O1OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3_2025_04_16Literal = \"o3-2025-04-16\";\nconst O3_2025_04_16Description =\n  \"A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.\";\n\nconst O3_2025_04_16Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O3_2025_04_16Literal,\n  description: O3_2025_04_16Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3_2025_04_16Options = BaseChatModelOptions;\ntype O3_2025_04_16OptionsType = z.infer<typeof O3_2025_04_16Options>;\n\nclass O3_2025_04_16 extends BaseChatModel {\n  constructor(options: O3_2025_04_16OptionsType) {\n    super(O3_2025_04_16Schema, options);\n  }\n}\n\nexport { O3_2025_04_16, O3_2025_04_16Literal, O3_2025_04_16Options, O3_2025_04_16Schema, type O3_2025_04_16OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelModalities, OpenAIChatModelModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3Literal = \"o3\";\nconst O3Description =\n  \"A new standard for math, science, coding, and visual reasoning tasks. Training data up to Jun 2024.\";\n\nconst O3Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O3Literal,\n  description: O3Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3Options = BaseChatModelOptions;\ntype O3OptionsType = z.infer<typeof O3Options>;\n\nclass O3 extends BaseChatModel {\n  constructor(options: O3OptionsType) {\n    super(O3Schema, options);\n  }\n}\n\nexport { O3, O3Literal, O3Options, O3Schema, type O3OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelTextToolModalities, OpenAIChatModelTextToolModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3MiniLiteral = \"o3-mini\";\nconst O3MiniDescription =\n  \"o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.\";\n\nconst O3MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: O3MiniLiteral,\n  description: O3MiniDescription,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3MiniOptions = BaseChatModelOptions;\ntype O3MiniOptionsType = z.infer<typeof O3MiniOptions>;\n\nclass O3Mini extends BaseChatModel {\n  constructor(options: O3MiniOptionsType) {\n    super(O3MiniSchema, options);\n  }\n}\n\nexport { O3Mini, O3MiniLiteral, O3MiniOptions, O3MiniSchema, type O3MiniOptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport { OpenAIChatModelTextToolModalities, OpenAIChatModelTextToolModalitiesEnum, OpenAIChatModelRoles, OpenAIChatModelRolesMap } from \"./types\";\n\nconst O3Mini2025_01_31Literal = \"o3-mini-2025-01-31\";\nconst O3Mini2025_01_31Description =\n  \"o3-mini is the newest small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. Training data up to Sep 2023.\";\n\nconst O3Mini2025_01_31Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelTextToolModalitiesEnum).parse({\n  name: O3Mini2025_01_31Literal,\n  description: O3Mini2025_01_31Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelTextToolModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O3Mini2025_01_31Options = BaseChatModelOptions;\ntype O3Mini2025_01_31OptionsType = z.infer<typeof O3Mini2025_01_31Options>;\n\nclass O3Mini2025_01_31 extends BaseChatModel {\n  constructor(options: O3Mini2025_01_31OptionsType) {\n    super(O3Mini2025_01_31Schema, options);\n  }\n}\n\nexport { O3Mini2025_01_31, O3Mini2025_01_31Literal, O3Mini2025_01_31Options, O3Mini2025_01_31Schema, type O3Mini2025_01_31OptionsType };\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelModalities,\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n} from \"./types\";\n\nconst O4_Mini_2025_04_16Literal = \"o4-mini-2025-04-16\";\nconst O4_Mini_2025_04_16Description =\n  \"Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.\";\n\nconst O4_Mini_2025_04_16Schema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O4_Mini_2025_04_16Literal,\n  description: O4_Mini_2025_04_16Description,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O4_Mini_2025_04_16Options = BaseChatModelOptions;\ntype O4_Mini_2025_04_16OptionsType = z.infer<typeof O4_Mini_2025_04_16Options>;\n\nclass O4_Mini_2025_04_16 extends BaseChatModel {\n  constructor(options: O4_Mini_2025_04_16OptionsType) {\n    super(O4_Mini_2025_04_16Schema, options);\n  }\n}\n\nexport { O4_Mini_2025_04_16, O4_Mini_2025_04_16Literal, O4_Mini_2025_04_16Options, O4_Mini_2025_04_16Schema, type O4_Mini_2025_04_16OptionsType };\n\n","import { z } from \"zod\";\n\nimport { ChatModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIChatModelConfigs } from \"../../configs\";\nimport { BaseChatModelOptions, BaseChatModel } from \"./base-chat-model.openai\";\nimport {\n  OpenAIChatModelModalities,\n  OpenAIChatModelModalitiesEnum,\n  OpenAIChatModelRoles,\n  OpenAIChatModelRolesMap,\n} from \"./types\";\n\nconst O4_MiniLiteral = \"o4-mini\";\nconst O4_MiniDescription =\n  \"Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Training data up to Jun 2024.\";\n\nconst O4_MiniSchema = ChatModelSchema(OpenAIChatModelRoles, OpenAIChatModelModalitiesEnum).parse({\n  name: O4_MiniLiteral,\n  description: O4_MiniDescription,\n  maxInputTokens: 200000,\n  maxOutputTokens: 100000,\n  roles: OpenAIChatModelRolesMap,\n  modalities: OpenAIChatModelModalities,\n  config: {\n    def: OpenAIChatModelConfigs.oSeries(100000, 4).def,\n    schema: OpenAIChatModelConfigs.oSeries(100000, 4).schema,\n  },\n});\n\nconst O4_MiniOptions = BaseChatModelOptions;\ntype O4_MiniOptionsType = z.infer<typeof O4_MiniOptions>;\n\nclass O4_Mini extends BaseChatModel {\n  constructor(options: O4_MiniOptionsType) {\n    super(O4_MiniSchema, options);\n  }\n}\n\nexport { O4_Mini, O4_MiniLiteral, O4_MiniOptions, O4_MiniSchema, type O4_MiniOptionsType };\n\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchemaType } from \"@adaline/provider\";\nimport { EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral } from \"@adaline/types\";\n\nconst OpenAIEmbeddingModelModalities: EmbeddingModelSchemaType[\"modalities\"] = [\n  EmbeddingTextModalityLiteral,\n  EmbeddingTokenModalityLiteral,\n];\n\nconst OpenAIEmbeddingModelModalitiesEnum = z.enum([EmbeddingTextModalityLiteral, EmbeddingTokenModalityLiteral]);\n\nexport { OpenAIEmbeddingModelModalitiesEnum, OpenAIEmbeddingModelModalities };\n","import { z } from \"zod\";\n\nconst OpenAIGetEmbeddingsResponse = z.object({\n  object: z.literal(\"list\"),\n  model: z.string(),\n  data: z.array(\n    z.object({\n      index: z.number(),\n      object: z.literal(\"embedding\"),\n      embedding: z.array(z.number()).or(z.string().base64()),\n    })\n  ),\n  usage: z.object({\n    prompt_tokens: z.number().nonnegative(),\n    total_tokens: z.number().nonnegative(),\n  }),\n});\n\nexport { OpenAIGetEmbeddingsResponse };\n","import { z } from \"zod\";\n\nconst OpenAIEmbeddingRequestInput = z\n  .string()\n  .min(1)\n  .or(z.array(z.string().min(1)).min(1))\n  .or(z.array(z.number().int().nonnegative()).min(1))\n  .or(z.array(z.array(z.number().int().nonnegative()).min(1)).min(1));\ntype OpenAIEmbeddingRequestInputType = z.infer<typeof OpenAIEmbeddingRequestInput>;\n\nconst OpenAIEmbeddingRequest = z.object({\n  model: z.string().min(1).optional(),\n  input: OpenAIEmbeddingRequestInput,\n  encoding_format: z.enum([\"float\", \"base64\"]).optional(),\n  dimensions: z.number().int().min(1).optional(),\n});\ntype OpenAIEmbeddingRequestType = z.infer<typeof OpenAIEmbeddingRequest>;\n\nexport { OpenAIEmbeddingRequest, OpenAIEmbeddingRequestInput, type OpenAIEmbeddingRequestType, type OpenAIEmbeddingRequestInputType };\n","import { z } from \"zod\";\n\nimport {\n  EmbeddingModelSchemaType,\n  EmbeddingModelV1,\n  HeadersType,\n  InvalidConfigError,\n  InvalidEmbeddingRequestsError,\n  InvalidModelRequestError,\n  ModelResponseError,\n  ParamsType,\n  removeUndefinedEntries,\n  UrlType,\n  urlWithoutTrailingSlash,\n} from \"@adaline/provider\";\n\nimport {\n  Base64EmbeddingLiteral,\n  Base64EmbeddingType,\n  Config,\n  ConfigType,\n  EmbeddingRequests,\n  EmbeddingRequestsType,\n  EmbeddingResponseType,\n  EmbeddingTextModalityLiteral,\n  EmbeddingTokenModalityLiteral,\n  FloatEmbeddingLiteral,\n  FloatEmbeddingType,\n} from \"@adaline/types\";\n\nimport { OpenAIEmbeddingRequest, OpenAIGetEmbeddingsResponse } from \"./types\";\n\nimport { OpenAI } from \"./../../provider/provider.openai\";\n\nconst BaseEmbeddingModelOptions = z.object({\n  modelName: z.string(),\n  apiKey: z.string(),\n  baseUrl: z.string().url().optional(),\n  getEmbeddingsUrl: z.string().url().optional(),\n});\ntype BaseEmbeddingModelOptionsType = z.infer<typeof BaseEmbeddingModelOptions>;\n\nclass BaseEmbeddingModel implements EmbeddingModelV1<EmbeddingModelSchemaType> {\n  readonly version = \"v1\" as const;\n  modelSchema: EmbeddingModelSchemaType;\n  modelName: string;\n\n  private readonly apiKey: string;\n  private readonly baseUrl: string;\n  private readonly getEmbeddingsUrl: string;\n\n  constructor(modelSchema: EmbeddingModelSchemaType, options: BaseEmbeddingModelOptionsType) {\n    const parsedOptions = BaseEmbeddingModelOptions.parse(options);\n    this.modelSchema = modelSchema;\n    this.modelName = parsedOptions.modelName;\n    this.apiKey = parsedOptions.apiKey;\n    this.baseUrl = urlWithoutTrailingSlash(parsedOptions.baseUrl || OpenAI.baseUrl);\n    this.getEmbeddingsUrl = urlWithoutTrailingSlash(parsedOptions.getEmbeddingsUrl || `${this.baseUrl}/embeddings`);\n  }\n\n  getDefaultBaseUrl(): UrlType {\n    return this.baseUrl;\n  }\n\n  getDefaultHeaders(): HeadersType {\n    return {\n      Authorization: `Bearer ${this.apiKey}`,\n      \"Content-Type\": \"application/json\",\n    };\n  }\n\n  getDefaultParams(): ParamsType {\n    return {\n      model: this.modelSchema.name,\n    };\n  }\n\n  // x-ratelimit-limit-requests\tThe maximum number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-limit-tokens\tThe maximum number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-requests The remaining number of requests that are permitted before exhausting the rate limit.\n  // x-ratelimit-remaining-tokens\tThe remaining number of tokens that are permitted before exhausting the rate limit.\n  // x-ratelimit-reset-requests\tThe time until the rate limit (based on requests) resets to its initial state.\n  // x-ratelimit-reset-tokens\tThe time until the rate limit (based on tokens) resets to its initial state.\n  getRetryDelay(responseHeaders: HeadersType): { shouldRetry: boolean; delayMs: number } {\n    // parse duration from header value of format \"6m0s\" or \"21s\" or \"41ms\" or \"2s81ms\" or \"5h50m30ms\" and such\n    const parseDuration = (duration: string): number => {\n      const regex = /(\\d+)(h|m|s|ms)/g;\n      const timeUnits: { [unit: string]: number } = {\n        h: 3600000, // 1 hour = 60 * 60 * 1000 ms\n        m: 60000, // 1 minute = 60 * 1000 ms\n        s: 1000, // 1 second = 1000 ms\n        ms: 1, // milliseconds\n      };\n\n      let match;\n      let totalMs = 0;\n      while ((match = regex.exec(duration)) !== null) {\n        const value = parseInt(match[1]);\n        const unit = match[2];\n        totalMs += value * timeUnits[unit];\n      }\n\n      return totalMs;\n    };\n\n    let resetRequestsDelayMs = 0;\n    let resetTokensDelayMs = 0;\n    const shouldRetry = true;\n    if (responseHeaders[\"x-ratelimit-reset-requests\"]) {\n      resetRequestsDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-requests\"]);\n    }\n    if (responseHeaders[\"x-ratelimit-reset-tokens\"]) {\n      resetTokensDelayMs = parseDuration(responseHeaders[\"x-ratelimit-reset-tokens\"]);\n    }\n\n    // if rate limited by requests, then it's reset must be the higher of two and visa versa\n    const delayMs = Math.max(resetRequestsDelayMs, resetTokensDelayMs);\n    return { shouldRetry, delayMs };\n  }\n\n  getTokenCount(requests: EmbeddingRequestsType): number {\n    return requests.requests.reduce((acc, request) => acc + request.length, 0);\n  }\n\n  transformModelRequest(request: any): {\n    modelName: string | undefined;\n    config: ConfigType;\n    embeddingRequests: EmbeddingRequestsType;\n  } {\n    const safeRequest = OpenAIEmbeddingRequest.safeParse(request);\n    if (!safeRequest.success) {\n      throw new InvalidModelRequestError({ info: \"Invalid model request\", cause: safeRequest.error });\n    }\n\n    const parsedRequest = safeRequest.data;\n\n    const modelName = parsedRequest.model;\n\n    const _config = {\n      encodingFormat: parsedRequest.encoding_format,\n      dimensions: parsedRequest.dimensions,\n    };\n    const config = Config().parse(removeUndefinedEntries(_config));\n\n    let embeddingRequests: EmbeddingRequestsType;\n    let embeddingFormat: typeof EmbeddingTextModalityLiteral | typeof EmbeddingTokenModalityLiteral;\n    if (typeof parsedRequest.input === \"string\") {\n      embeddingFormat = EmbeddingTextModalityLiteral;\n    } else {\n      if (typeof parsedRequest.input[0] === \"string\") {\n        embeddingFormat = EmbeddingTextModalityLiteral;\n      } else {\n        embeddingFormat = EmbeddingTokenModalityLiteral;\n      }\n    }\n\n    if (embeddingFormat === EmbeddingTextModalityLiteral) {\n      if (typeof parsedRequest.input === \"string\") {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: [parsedRequest.input],\n        };\n      } else {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: parsedRequest.input as string[],\n        };\n      }\n    } else {\n      if (typeof parsedRequest.input[0] === \"number\") {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: [parsedRequest.input as number[]],\n        };\n      } else {\n        embeddingRequests = {\n          modality: embeddingFormat,\n          requests: parsedRequest.input as number[][],\n        };\n      }\n    }\n\n    return {\n      modelName,\n      config,\n      embeddingRequests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  transformConfig(config: ConfigType, requests?: EmbeddingRequestsType): ParamsType {\n    const _parsedConfig = this.modelSchema.config.schema.safeParse(config);\n    if (!_parsedConfig.success) {\n      throw new InvalidConfigError({\n        info: `Invalid config for model : '${this.modelSchema.name}'`,\n        cause: _parsedConfig.error,\n      });\n    }\n\n    const parsedConfig = _parsedConfig.data as ConfigType;\n    Object.keys(parsedConfig as ConfigType).forEach((key) => {\n      if (!this.modelSchema.config.def[key]) {\n        throw new InvalidConfigError({\n          info: `Invalid config for model : '${this.modelSchema.name}'`,\n          cause: new Error(`Invalid config key : '${key}', \n            available keys : [${Object.keys(this.modelSchema.config.def).join(\", \")}]`),\n        });\n      }\n    });\n\n    const transformedConfig = Object.keys(parsedConfig).reduce((acc, key) => {\n      const def = this.modelSchema.config.def[key];\n      const paramKey = def.param;\n      const paramValue = parsedConfig[key];\n      acc[paramKey] = paramValue;\n      return acc;\n    }, {} as ParamsType);\n\n    return transformedConfig;\n  }\n\n  transformEmbeddingRequests(requests: EmbeddingRequestsType): ParamsType {\n    const _parsedRequests = EmbeddingRequests().safeParse(requests);\n    if (!_parsedRequests.success) {\n      throw new InvalidEmbeddingRequestsError({ info: \"Invalid embedding requests\", cause: _parsedRequests.error });\n    }\n\n    // Note from OpenAI API Reference:\n    // The input must not exceed the max input tokens for the model (8192 tokens for text-embedding-ada-002),\n    // cannot be an empty string, and any array must be 2048 dimensions or less.\n    // TODO: add max tokens check in requests based on model schema when token calculation is accurate\n\n    const parsedRequests = _parsedRequests.data as EmbeddingRequestsType;\n    return {\n      input: parsedRequests.requests,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsUrl(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<UrlType> {\n    return new Promise((resolve) => {\n      resolve(this.getEmbeddingsUrl);\n    });\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async getGetEmbeddingsHeaders(config?: ConfigType, requests?: EmbeddingRequestsType): Promise<HeadersType> {\n    return new Promise((resolve) => {\n      resolve(this.getDefaultHeaders());\n    });\n  }\n\n  async getGetEmbeddingsData(config: ConfigType, requests: EmbeddingRequestsType): Promise<ParamsType> {\n    return new Promise((resolve) => {\n      resolve({\n        ...this.getDefaultParams(),\n        ...this.transformConfig(config, requests),\n        ...this.transformEmbeddingRequests(requests),\n      });\n    });\n  }\n\n  transformGetEmbeddingsResponse(response: any): EmbeddingResponseType {\n    let encodingFormat: typeof Base64EmbeddingLiteral | typeof FloatEmbeddingLiteral;\n    const safe = OpenAIGetEmbeddingsResponse.safeParse(response);\n    if (safe.success) {\n      const parsedResponse = safe.data;\n      encodingFormat = typeof parsedResponse.data[0].embedding === \"string\" ? Base64EmbeddingLiteral : FloatEmbeddingLiteral;\n      const embeddings = parsedResponse.data.map((item) => {\n        if (typeof item.embedding === \"string\") {\n          return {\n            index: item.index,\n            embedding: item.embedding,\n          } as Base64EmbeddingType;\n        } else {\n          return {\n            index: item.index,\n            embedding: item.embedding,\n          } as FloatEmbeddingType;\n        }\n      });\n\n      return {\n        encodingFormat: encodingFormat,\n        embeddings: embeddings,\n        usage: {\n          totalTokens: parsedResponse.usage.total_tokens,\n        },\n      } as EmbeddingResponseType;\n    }\n\n    throw new ModelResponseError({ info: \"Invalid response from model\", cause: safe.error });\n  }\n}\n\nexport { BaseEmbeddingModel, BaseEmbeddingModelOptions, type BaseEmbeddingModelOptionsType };\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_Ada002Literal = \"text-embedding-ada-002\";\nconst Text_Embedding_Ada002Description = \"Most capable 2nd generation embedding model, replacing 16 first generation models\";\n\nconst Text_Embedding_Ada002Schema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_Ada002Literal,\n  description: Text_Embedding_Ada002Description,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 1536,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.base().def,\n    schema: OpenAIEmbeddingModelConfigs.base().schema,\n  },\n});\n\nconst Text_Embedding_Ada002_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_Ada002_OptionsType = z.infer<typeof Text_Embedding_Ada002_Options>;\n\nclass Text_Embedding_Ada002 extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_Ada002_OptionsType) {\n    super(Text_Embedding_Ada002Schema, options);\n  }\n}\n\nexport {\n  Text_Embedding_Ada002,\n  Text_Embedding_Ada002_Options,\n  Text_Embedding_Ada002Schema,\n  Text_Embedding_Ada002Literal,\n  type Text_Embedding_Ada002_OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_3_SmallLiteral = \"text-embedding-3-small\";\nconst Text_Embedding_3_SmallDescription = \"Increased performance over 2nd generation ada embedding model\";\n\nconst Text_Embedding_3_SmallSchema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_3_SmallLiteral,\n  description: Text_Embedding_3_SmallDescription,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 1536,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.dimensions(1536).def,\n    schema: OpenAIEmbeddingModelConfigs.dimensions(1536).schema,\n  },\n});\n\nconst Text_Embedding_3_Small_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_3_Small_OptionsType = z.infer<typeof Text_Embedding_3_Small_Options>;\n\nclass Text_Embedding_3_Small extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_3_Small_OptionsType) {\n    super(Text_Embedding_3_SmallSchema, options);\n  }\n}\n\nexport {\n  Text_Embedding_3_Small,\n  Text_Embedding_3_Small_Options,\n  Text_Embedding_3_SmallSchema,\n  Text_Embedding_3_SmallLiteral,\n  type Text_Embedding_3_Small_OptionsType,\n};\n","import { z } from \"zod\";\n\nimport { EmbeddingModelSchema } from \"@adaline/provider\";\n\nimport { OpenAIEmbeddingModelConfigs } from \"../../configs\";\nimport { BaseEmbeddingModel, BaseEmbeddingModelOptions } from \"./base-embedding-model.openai\";\nimport { OpenAIEmbeddingModelModalities, OpenAIEmbeddingModelModalitiesEnum } from \"./types\";\n\nconst Text_Embedding_3_LargeLiteral = \"text-embedding-3-large\";\nconst Text_Embedding_3_LargeDescription = \"Most capable embedding model for both english and non-english tasks\";\n\nconst Text_Embedding_3_LargeSchema = EmbeddingModelSchema(OpenAIEmbeddingModelModalitiesEnum).parse({\n  name: Text_Embedding_3_LargeLiteral,\n  description: Text_Embedding_3_LargeDescription,\n  modalities: OpenAIEmbeddingModelModalities,\n  maxInputTokens: 8192,\n  maxOutputTokens: 3072,\n  config: {\n    def: OpenAIEmbeddingModelConfigs.dimensions(3072).def,\n    schema: OpenAIEmbeddingModelConfigs.dimensions(3072).schema,\n  },\n});\n\nconst Text_Embedding_3_Large_Options = BaseEmbeddingModelOptions;\ntype Text_Embedding_3_Large_OptionsType = z.infer<typeof Text_Embedding_3_Large_Options>;\n\nclass Text_Embedding_3_Large extends BaseEmbeddingModel {\n  constructor(options: Text_Embedding_3_Large_OptionsType) {\n    super(Text_Embedding_3_LargeSchema, options);\n  }\n}\n\nexport {\n  Text_Embedding_3_Large,\n  Text_Embedding_3_Large_Options,\n  Text_Embedding_3_LargeSchema,\n  Text_Embedding_3_LargeLiteral,\n  type Text_Embedding_3_Large_OptionsType,\n};\n"]}